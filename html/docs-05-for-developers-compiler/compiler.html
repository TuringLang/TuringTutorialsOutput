<!DOCTYPE html>
<HTML lang = "en">
<HEAD>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Turing Compiler Design</title>
  

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      TeX: { equationNumbers: { autoNumber: "AMS" } }
    });
  </script>

  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>

  
<style>
pre.hljl {
    border: 1px solid #ccc;
    margin: 5px;
    padding: 5px;
    overflow-x: auto;
    color: rgb(68,68,68); background-color: rgb(251,251,251); }
pre.hljl > span.hljl-t { }
pre.hljl > span.hljl-w { }
pre.hljl > span.hljl-e { }
pre.hljl > span.hljl-eB { }
pre.hljl > span.hljl-o { }
pre.hljl > span.hljl-k { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kc { color: rgb(59,151,46); font-style: italic; }
pre.hljl > span.hljl-kd { color: rgb(214,102,97); font-style: italic; }
pre.hljl > span.hljl-kn { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kp { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kr { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kt { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-n { }
pre.hljl > span.hljl-na { }
pre.hljl > span.hljl-nb { }
pre.hljl > span.hljl-nbp { }
pre.hljl > span.hljl-nc { }
pre.hljl > span.hljl-ncB { }
pre.hljl > span.hljl-nd { color: rgb(214,102,97); }
pre.hljl > span.hljl-ne { }
pre.hljl > span.hljl-neB { }
pre.hljl > span.hljl-nf { color: rgb(66,102,213); }
pre.hljl > span.hljl-nfm { color: rgb(66,102,213); }
pre.hljl > span.hljl-np { }
pre.hljl > span.hljl-nl { }
pre.hljl > span.hljl-nn { }
pre.hljl > span.hljl-no { }
pre.hljl > span.hljl-nt { }
pre.hljl > span.hljl-nv { }
pre.hljl > span.hljl-nvc { }
pre.hljl > span.hljl-nvg { }
pre.hljl > span.hljl-nvi { }
pre.hljl > span.hljl-nvm { }
pre.hljl > span.hljl-l { }
pre.hljl > span.hljl-ld { color: rgb(148,91,176); font-style: italic; }
pre.hljl > span.hljl-s { color: rgb(201,61,57); }
pre.hljl > span.hljl-sa { color: rgb(201,61,57); }
pre.hljl > span.hljl-sb { color: rgb(201,61,57); }
pre.hljl > span.hljl-sc { color: rgb(201,61,57); }
pre.hljl > span.hljl-sd { color: rgb(201,61,57); }
pre.hljl > span.hljl-sdB { color: rgb(201,61,57); }
pre.hljl > span.hljl-sdC { color: rgb(201,61,57); }
pre.hljl > span.hljl-se { color: rgb(59,151,46); }
pre.hljl > span.hljl-sh { color: rgb(201,61,57); }
pre.hljl > span.hljl-si { }
pre.hljl > span.hljl-so { color: rgb(201,61,57); }
pre.hljl > span.hljl-sr { color: rgb(201,61,57); }
pre.hljl > span.hljl-ss { color: rgb(201,61,57); }
pre.hljl > span.hljl-ssB { color: rgb(201,61,57); }
pre.hljl > span.hljl-nB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nbB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nfB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nh { color: rgb(59,151,46); }
pre.hljl > span.hljl-ni { color: rgb(59,151,46); }
pre.hljl > span.hljl-nil { color: rgb(59,151,46); }
pre.hljl > span.hljl-noB { color: rgb(59,151,46); }
pre.hljl > span.hljl-oB { color: rgb(102,102,102); font-weight: bold; }
pre.hljl > span.hljl-ow { color: rgb(102,102,102); font-weight: bold; }
pre.hljl > span.hljl-p { }
pre.hljl > span.hljl-c { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-ch { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cm { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cp { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cpB { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cs { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-csB { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-g { }
pre.hljl > span.hljl-gd { }
pre.hljl > span.hljl-ge { }
pre.hljl > span.hljl-geB { }
pre.hljl > span.hljl-gh { }
pre.hljl > span.hljl-gi { }
pre.hljl > span.hljl-go { }
pre.hljl > span.hljl-gp { }
pre.hljl > span.hljl-gs { }
pre.hljl > span.hljl-gsB { }
pre.hljl > span.hljl-gt { }
</style>



  <style type="text/css">
  @font-face {
  font-style: normal;
  font-weight: 300;
}
@font-face {
  font-style: normal;
  font-weight: 400;
}
@font-face {
  font-style: normal;
  font-weight: 600;
}
html {
  font-family: sans-serif; /* 1 */
  -ms-text-size-adjust: 100%; /* 2 */
  -webkit-text-size-adjust: 100%; /* 2 */
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block; /* 1 */
  vertical-align: baseline; /* 2 */
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 70%;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit; /* 1 */
  font: inherit; /* 2 */
  margin: 0; /* 3 */
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button; /* 2 */
  cursor: pointer; /* 3 */
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box; /* 1 */
  padding: 0; /* 2 */
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield; /* 1 */
  -moz-box-sizing: content-box;
  -webkit-box-sizing: content-box; /* 2 */
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0; /* 1 */
  padding: 0; /* 2 */
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  font-family: monospace, monospace;
  font-size : 0.8em;
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
thead th {
    border-bottom: 1px solid black;
    background-color: white;
}
tr:nth-child(odd){
  background-color: rgb(248,248,248);
}


/*
* Skeleton V2.0.4
* Copyright 2014, Dave Gamache
* www.getskeleton.com
* Free to use under the MIT license.
* http://www.opensource.org/licenses/mit-license.php
* 12/29/2014
*/
.container {
  position: relative;
  width: 100%;
  max-width: 960px;
  margin: 0 auto;
  padding: 0 20px;
  box-sizing: border-box; }
.column,
.columns {
  width: 100%;
  float: left;
  box-sizing: border-box; }
@media (min-width: 400px) {
  .container {
    width: 85%;
    padding: 0; }
}
@media (min-width: 550px) {
  .container {
    width: 80%; }
  .column,
  .columns {
    margin-left: 4%; }
  .column:first-child,
  .columns:first-child {
    margin-left: 0; }

  .one.column,
  .one.columns                    { width: 4.66666666667%; }
  .two.columns                    { width: 13.3333333333%; }
  .three.columns                  { width: 22%;            }
  .four.columns                   { width: 30.6666666667%; }
  .five.columns                   { width: 39.3333333333%; }
  .six.columns                    { width: 48%;            }
  .seven.columns                  { width: 56.6666666667%; }
  .eight.columns                  { width: 65.3333333333%; }
  .nine.columns                   { width: 74.0%;          }
  .ten.columns                    { width: 82.6666666667%; }
  .eleven.columns                 { width: 91.3333333333%; }
  .twelve.columns                 { width: 100%; margin-left: 0; }

  .one-third.column               { width: 30.6666666667%; }
  .two-thirds.column              { width: 65.3333333333%; }

  .one-half.column                { width: 48%; }

  /* Offsets */
  .offset-by-one.column,
  .offset-by-one.columns          { margin-left: 8.66666666667%; }
  .offset-by-two.column,
  .offset-by-two.columns          { margin-left: 17.3333333333%; }
  .offset-by-three.column,
  .offset-by-three.columns        { margin-left: 26%;            }
  .offset-by-four.column,
  .offset-by-four.columns         { margin-left: 34.6666666667%; }
  .offset-by-five.column,
  .offset-by-five.columns         { margin-left: 43.3333333333%; }
  .offset-by-six.column,
  .offset-by-six.columns          { margin-left: 52%;            }
  .offset-by-seven.column,
  .offset-by-seven.columns        { margin-left: 60.6666666667%; }
  .offset-by-eight.column,
  .offset-by-eight.columns        { margin-left: 69.3333333333%; }
  .offset-by-nine.column,
  .offset-by-nine.columns         { margin-left: 78.0%;          }
  .offset-by-ten.column,
  .offset-by-ten.columns          { margin-left: 86.6666666667%; }
  .offset-by-eleven.column,
  .offset-by-eleven.columns       { margin-left: 95.3333333333%; }

  .offset-by-one-third.column,
  .offset-by-one-third.columns    { margin-left: 34.6666666667%; }
  .offset-by-two-thirds.column,
  .offset-by-two-thirds.columns   { margin-left: 69.3333333333%; }

  .offset-by-one-half.column,
  .offset-by-one-half.columns     { margin-left: 52%; }

}
html {
  font-size: 62.5%; }
body {
  font-size: 1.5em; /* currently ems cause chrome bug misinterpreting rems on body element */
  line-height: 1.6;
  font-weight: 400;
  font-family: "Raleway", "HelveticaNeue", "Helvetica Neue", Helvetica, Arial, sans-serif;
  color: #222; }
h1, h2, h3, h4, h5, h6 {
  margin-top: 0;
  margin-bottom: 2rem;
  font-weight: 300; }
h1 { font-size: 3.6rem; line-height: 1.2;  letter-spacing: -.1rem;}
h2 { font-size: 3.4rem; line-height: 1.25; letter-spacing: -.1rem; }
h3 { font-size: 3.2rem; line-height: 1.3;  letter-spacing: -.1rem; }
h4 { font-size: 2.8rem; line-height: 1.35; letter-spacing: -.08rem; }
h5 { font-size: 2.4rem; line-height: 1.5;  letter-spacing: -.05rem; }
h6 { font-size: 1.5rem; line-height: 1.6;  letter-spacing: 0; }

p {
  margin-top: 0; }
a {
  color: #1EAEDB; }
a:hover {
  color: #0FA0CE; }
.button,
button,
input[type="submit"],
input[type="reset"],
input[type="button"] {
  display: inline-block;
  height: 38px;
  padding: 0 30px;
  color: #555;
  text-align: center;
  font-size: 11px;
  font-weight: 600;
  line-height: 38px;
  letter-spacing: .1rem;
  text-transform: uppercase;
  text-decoration: none;
  white-space: nowrap;
  background-color: transparent;
  border-radius: 4px;
  border: 1px solid #bbb;
  cursor: pointer;
  box-sizing: border-box; }
.button:hover,
button:hover,
input[type="submit"]:hover,
input[type="reset"]:hover,
input[type="button"]:hover,
.button:focus,
button:focus,
input[type="submit"]:focus,
input[type="reset"]:focus,
input[type="button"]:focus {
  color: #333;
  border-color: #888;
  outline: 0; }
.button.button-primary,
button.button-primary,
input[type="submit"].button-primary,
input[type="reset"].button-primary,
input[type="button"].button-primary {
  color: #FFF;
  background-color: #33C3F0;
  border-color: #33C3F0; }
.button.button-primary:hover,
button.button-primary:hover,
input[type="submit"].button-primary:hover,
input[type="reset"].button-primary:hover,
input[type="button"].button-primary:hover,
.button.button-primary:focus,
button.button-primary:focus,
input[type="submit"].button-primary:focus,
input[type="reset"].button-primary:focus,
input[type="button"].button-primary:focus {
  color: #FFF;
  background-color: #1EAEDB;
  border-color: #1EAEDB; }
input[type="email"],
input[type="number"],
input[type="search"],
input[type="text"],
input[type="tel"],
input[type="url"],
input[type="password"],
textarea,
select {
  height: 38px;
  padding: 6px 10px; /* The 6px vertically centers text on FF, ignored by Webkit */
  background-color: #fff;
  border: 1px solid #D1D1D1;
  border-radius: 4px;
  box-shadow: none;
  box-sizing: border-box; }
/* Removes awkward default styles on some inputs for iOS */
input[type="email"],
input[type="number"],
input[type="search"],
input[type="text"],
input[type="tel"],
input[type="url"],
input[type="password"],
textarea {
  -webkit-appearance: none;
     -moz-appearance: none;
          appearance: none; }
textarea {
  min-height: 65px;
  padding-top: 6px;
  padding-bottom: 6px; }
input[type="email"]:focus,
input[type="number"]:focus,
input[type="search"]:focus,
input[type="text"]:focus,
input[type="tel"]:focus,
input[type="url"]:focus,
input[type="password"]:focus,
textarea:focus,
select:focus {
  border: 1px solid #33C3F0;
  outline: 0; }
label,
legend {
  display: block;
  margin-bottom: .5rem;
  font-weight: 600; }
fieldset {
  padding: 0;
  border-width: 0; }
input[type="checkbox"],
input[type="radio"] {
  display: inline; }
label > .label-body {
  display: inline-block;
  margin-left: .5rem;
  font-weight: normal; }
ul {
  list-style: circle; }
ol {
  list-style: decimal; }
ul ul,
ul ol,
ol ol,
ol ul {
  margin: 1.5rem 0 1.5rem 3rem;
  font-size: 90%; }
li > p {margin : 0;}
th,
td {
  padding: 12px 15px;
  text-align: left;
  border-bottom: 1px solid #E1E1E1; }
th:first-child,
td:first-child {
  padding-left: 0; }
th:last-child,
td:last-child {
  padding-right: 0; }
button,
.button {
  margin-bottom: 1rem; }
input,
textarea,
select,
fieldset {
  margin-bottom: 1.5rem; }
pre,
blockquote,
dl,
figure,
table,
p,
ul,
ol,
form {
  margin-bottom: 1.0rem; }
.u-full-width {
  width: 100%;
  box-sizing: border-box; }
.u-max-full-width {
  max-width: 100%;
  box-sizing: border-box; }
.u-pull-right {
  float: right; }
.u-pull-left {
  float: left; }
hr {
  margin-top: 3rem;
  margin-bottom: 3.5rem;
  border-width: 0;
  border-top: 1px solid #E1E1E1; }
.container:after,
.row:after,
.u-cf {
  content: "";
  display: table;
  clear: both; }

pre {
  display: block;
  padding: 9.5px;
  margin: 0 0 10px;
  font-size: 13px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre.hljl {
  margin: 0 0 10px;
  display: block;
  background: #f5f5f5;
  border-radius: 4px;
  padding : 5px;
}

pre.output {
  background: #ffffff;
}

pre.code {
  background: #ffffff;
}

pre.julia-error {
  color : red
}

code,
kbd,
pre,
samp {
  font-family: Menlo, Monaco, Consolas, "Courier New", monospace;
  font-size: 13px;
}


@media (min-width: 400px) {}
@media (min-width: 550px) {}
@media (min-width: 750px) {}
@media (min-width: 1000px) {}
@media (min-width: 1200px) {}

h1.title {margin-top : 20px}
img {max-width : 100%}
div.title {text-align: center;}

  </style>
</HEAD>

<BODY>
  <div class ="container">
    <div class = "row">
      <div class = "col-md-12 twelve columns">
        <div class="title">
          <h1 class="title">Turing Compiler Design</h1>
          
          
        </div>

        <p>In this section, the current design of Turing&#39;s model &quot;compiler&quot; is described which enables Turing to perform various types of Bayesian inference without changing the model definition. The &quot;compiler&quot; is essentially just a macro that rewrites the user&#39;s model definition to a function that generates a <code>Model</code> struct that Julia&#39;s dispatch can operate on and that Julia&#39;s compiler can successfully do type inference on for efficient machine code generation.</p>
<h1>Overview</h1>
<p>The following terminology will be used in this section:</p>
<ul>
<li><p><code>D</code>: observed data variables conditioned upon in the posterior,</p>
</li>
<li><p><code>P</code>: parameter variables distributed according to the prior distributions, these will also be referred to as random variables,</p>
</li>
<li><p><code>Model</code>: a fully defined probabilistic model with input data</p>
</li>
</ul>
<p><code>Turing</code>&#39;s <code>@model</code> macro rewrites the user-provided function definition such that it can be used to instantiate a <code>Model</code> by passing in the observed data <code>D</code>.</p>
<p>The following are the main jobs of the <code>@model</code> macro:</p>
<ol>
<li><p>Parse <code>~</code> and <code>.~</code> lines, e.g. <code>y .~ Normal.&#40;c*x, 1.0&#41;</code></p>
</li>
<li><p>Figure out if a variable belongs to the data <code>D</code> and or to the parameters <code>P</code></p>
</li>
<li><p>Enable the handling of missing data variables in <code>D</code> when defining a <code>Model</code> and treating them as parameter variables in <code>P</code> instead</p>
</li>
<li><p>Enable the tracking of random variables using the data structures <code>VarName</code> and <code>VarInfo</code></p>
</li>
<li><p>Change <code>~</code>/<code>.~</code> lines with a variable in <code>P</code> on the LHS to a call to <code>tilde_assume</code> or <code>dot_tilde_assume</code></p>
</li>
<li><p>Change <code>~</code>/<code>.~</code> lines with a variable in <code>D</code> on the LHS to a call to <code>tilde_observe</code> or <code>dot_tilde_observe</code></p>
</li>
<li><p>Enable type stable automatic differentiation of the model using type parameters</p>
</li>
</ol>
<h2>The model</h2>
<p>A <code>model::Model</code> is a callable struct that one can sample from by calling</p>


<pre class='hljl'>
<span class='hljl-p'>(</span><span class='hljl-n'>model</span><span class='hljl-oB'>::</span><span class='hljl-n'>Model</span><span class='hljl-p'>)([</span><span class='hljl-n'>rng</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>varinfo</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>sampler</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>context</span><span class='hljl-p'>])</span>
</pre>


<p>where <code>rng</code> is a random number generator &#40;default: <code>Random.default_rng&#40;&#41;</code>&#41;, <code>varinfo</code> is a data structure that stores information about the random variables &#40;default: <code>DynamicPPL.VarInfo&#40;&#41;</code>&#41;, <code>sampler</code> is a sampling algorithm &#40;default: <code>DynamicPPL.SampleFromPrior&#40;&#41;</code>&#41;, and <code>context</code> is a sampling context that can, e.g., modify how the log probability is accumulated &#40;default: <code>DynamicPPL.DefaultContext&#40;&#41;</code>&#41;.</p>
<p>Sampling resets the log joint probability of <code>varinfo</code> and increases the evaluation counter of <code>sampler</code>. If <code>context</code> is a <code>LikelihoodContext</code>, only the log likelihood will be accumulated. With the <code>DefaultContext</code> the log joint probability of <code>P</code> and <code>D</code> is accumulated.</p>
<p>The <code>Model</code> struct contains the three internal fields <code>f</code>, <code>args</code> and <code>defaults</code>. When <code>model::Model</code> is called, then the internal function <code>model.f</code> is called as <code>model.f&#40;rng, varinfo, sampler, context, model.args...&#41;</code> &#40;for multithreaded sampling, instead of <code>varinfo</code> a threadsafe wrapper is passed to <code>model.f</code>&#41;. The positional and keyword arguments that were passed to the user-defined model function when the model was created are saved as a <code>NamedTuple</code> in <code>model.args</code>. The default values of the positional and keyword arguments of the user-defined model functions, if any, are saved as a <code>NamedTuple</code> in <code>model.defaults</code>. They are used for constructing model instances with different arguments by the <code>logprob</code> and <code>prob</code> string macros.</p>
<h1>Example</h1>
<p>Let&#39;s take the following model as an example:</p>


<pre class='hljl'>
<span class='hljl-nd'>@model</span><span class='hljl-t'> </span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>gauss</span><span class='hljl-p'>(</span><span class='hljl-t'>
    </span><span class='hljl-n'>x</span><span class='hljl-oB'>=</span><span class='hljl-n'>missing</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-oB'>=</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>::</span><span class='hljl-nf'>Type</span><span class='hljl-p'>{</span><span class='hljl-n'>TV</span><span class='hljl-p'>}</span><span class='hljl-oB'>=</span><span class='hljl-nf'>Vector</span><span class='hljl-p'>{</span><span class='hljl-n'>Float64</span><span class='hljl-p'>}</span><span class='hljl-t'>
</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-kp'>where</span><span class='hljl-t'> </span><span class='hljl-p'>{</span><span class='hljl-n'>TV</span><span class='hljl-oB'>&lt;:</span><span class='hljl-n'>AbstractVector</span><span class='hljl-p'>}</span><span class='hljl-t'>
    </span><span class='hljl-k'>if</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>===</span><span class='hljl-t'> </span><span class='hljl-n'>missing</span><span class='hljl-t'>
        </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>TV</span><span class='hljl-p'>(</span><span class='hljl-n'>undef</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>end</span><span class='hljl-t'>
    </span><span class='hljl-n'>p</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>TV</span><span class='hljl-p'>(</span><span class='hljl-n'>undef</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>p</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>InverseGamma</span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>p</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(</span><span class='hljl-ni'>0</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>)</span><span class='hljl-t'>
    @</span><span class='hljl-oB'>.</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(</span><span class='hljl-n'>p</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-nf'>sqrt</span><span class='hljl-p'>(</span><span class='hljl-n'>p</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]))</span><span class='hljl-t'>
    </span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>3</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Normal</span><span class='hljl-p'>()</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(</span><span class='hljl-n'>p</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-nf'>sqrt</span><span class='hljl-p'>(</span><span class='hljl-n'>p</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]))</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre>


<p>The above call of the <code>@model</code> macro defines the function <code>gauss</code> with positional arguments <code>x</code>, <code>y</code>, and <code>::Type&#123;TV&#125;</code>, rewritten in such a way that every call of it returns a <code>model::Model</code>. Note that only the function body is modified by the <code>@model</code> macro, and the function signature is left untouched. It is also possible to implement models with keyword arguments such as</p>


<pre class='hljl'>
<span class='hljl-nd'>@model</span><span class='hljl-t'> </span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>gauss</span><span class='hljl-p'>(</span><span class='hljl-t'>
    </span><span class='hljl-oB'>::</span><span class='hljl-nf'>Type</span><span class='hljl-p'>{</span><span class='hljl-n'>TV</span><span class='hljl-p'>}</span><span class='hljl-oB'>=</span><span class='hljl-nf'>Vector</span><span class='hljl-p'>{</span><span class='hljl-n'>Float64</span><span class='hljl-p'>};</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-oB'>=</span><span class='hljl-n'>missing</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-oB'>=</span><span class='hljl-nfB'>1.0</span><span class='hljl-t'>
</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-kp'>where</span><span class='hljl-t'> </span><span class='hljl-p'>{</span><span class='hljl-n'>TV</span><span class='hljl-oB'>&lt;:</span><span class='hljl-n'>AbstractVector</span><span class='hljl-p'>}</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-oB'>...</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre>


<p>This would allow us to generate a model by calling <code>gauss&#40;; x &#61; rand&#40;3&#41;&#41;</code>.</p>
<p>If an argument has a default value <code>missing</code>, it is treated as a random variable. For variables which require an initialization because we need to loop or broadcast over its elements, such as <code>x</code> above, the following needs to be done:</p>


<pre class='hljl'>
<span class='hljl-k'>if</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>===</span><span class='hljl-t'> </span><span class='hljl-n'>missing</span><span class='hljl-t'>
    </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-oB'>...</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre>


<p>Note that since <code>gauss</code> behaves like a regular function it is possible to define additional dispatches in a second step as well. For instance, we could achieve the same behaviour by</p>


<pre class='hljl'>
<span class='hljl-nd'>@model</span><span class='hljl-t'> </span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>gauss</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-oB'>=</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>::</span><span class='hljl-nf'>Type</span><span class='hljl-p'>{</span><span class='hljl-n'>TV</span><span class='hljl-p'>}</span><span class='hljl-oB'>=</span><span class='hljl-nf'>Vector</span><span class='hljl-p'>{</span><span class='hljl-n'>Float64</span><span class='hljl-p'>})</span><span class='hljl-t'> </span><span class='hljl-kp'>where</span><span class='hljl-t'> </span><span class='hljl-p'>{</span><span class='hljl-n'>TV</span><span class='hljl-oB'>&lt;:</span><span class='hljl-n'>AbstractVector</span><span class='hljl-p'>}</span><span class='hljl-t'>
    </span><span class='hljl-n'>p</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>TV</span><span class='hljl-p'>(</span><span class='hljl-n'>undef</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-oB'>...</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>

</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>gauss</span><span class='hljl-p'>(</span><span class='hljl-oB'>::</span><span class='hljl-n'>Missing</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-oB'>=</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>::</span><span class='hljl-nf'>Type</span><span class='hljl-p'>{</span><span class='hljl-n'>TV</span><span class='hljl-p'>}</span><span class='hljl-oB'>=</span><span class='hljl-nf'>Vector</span><span class='hljl-p'>{</span><span class='hljl-n'>Float64</span><span class='hljl-p'>})</span><span class='hljl-t'> </span><span class='hljl-kp'>where</span><span class='hljl-t'> </span><span class='hljl-p'>{</span><span class='hljl-n'>TV</span><span class='hljl-oB'>&lt;:</span><span class='hljl-n'>AbstractVector</span><span class='hljl-p'>}</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-nf'>gauss</span><span class='hljl-p'>(</span><span class='hljl-nf'>TV</span><span class='hljl-p'>(</span><span class='hljl-n'>undef</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>TV</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre>


<p>If <code>x</code> is sampled as a whole from a distribution and not indexed, e.g., <code>x ~ Normal&#40;...&#41;</code> or <code>x ~ MvNormal&#40;...&#41;</code>, there is no need to initialize it in an <code>if</code>-block.</p>
<h2>Step 1: Break up the model definition</h2>
<p>First, the <code>@model</code> macro breaks up the user-provided function definition using <code>DynamicPPL.build_model_info</code>. This function returns a dictionary consisting of:</p>
<ul>
<li><p><code>allargs_exprs</code>: The expressions of the positional and keyword arguments, without default values.</p>
</li>
<li><p><code>allargs_syms</code>: The names of the positional and keyword arguments, e.g., <code>&#91;:x, :y, :TV&#93;</code> above.</p>
</li>
<li><p><code>allargs_namedtuple</code>: An expression that constructs a <code>NamedTuple</code> of the positional and keyword arguments, e.g., <code>:&#40;&#40;x &#61; x, y &#61; y, TV &#61; TV&#41;&#41;</code> above.</p>
</li>
<li><p><code>defaults_namedtuple</code>: An expression that constructs a <code>NamedTuple</code> of the default positional and keyword arguments, if any, e.g., <code>:&#40;&#40;x &#61; missing, y &#61; 1, TV &#61; Vector&#123;Float64&#125;&#41;&#41;</code> above.</p>
</li>
<li><p><code>modeldef</code>: A dictionary with the name, arguments, and function body of the model definition, as returned by <code>MacroTools.splitdef</code>.</p>
</li>
</ul>
<h2>Step 2: Generate the body of the internal model function</h2>
<p>In a second step, <code>DynamicPPL.generate_mainbody</code> generates the main part of the transformed function body using the user-provided function body and the provided function arguments, without default values, for figuring out if a variable denotes an observation or a random variable. Hereby the function <code>DynamicPPL.generate_tilde</code> replaces the <code>L ~ R</code> lines in the model and the function <code>DynamicPPL.generate_dot_tilde</code> replaces the <code>@. L ~ R</code> and <code>L .~ R</code> lines in the model.</p>
<p>In the above example, <code>p&#91;1&#93; ~ InverseGamma&#40;2, 3&#41;</code> is replaced with something similar to</p>


<pre class='hljl'>
<span class='hljl-cm'>#= REPL[25]:6 =#</span><span class='hljl-t'>
</span><span class='hljl-k'>begin</span><span class='hljl-t'>
    </span><span class='hljl-so'>var&quot;##tmpright#323&quot;</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>InverseGamma</span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-so'>var&quot;##tmpright#323&quot;</span><span class='hljl-t'> </span><span class='hljl-n'>isa</span><span class='hljl-t'> </span><span class='hljl-nf'>Union</span><span class='hljl-p'>{</span><span class='hljl-n'>Distribution</span><span class='hljl-p'>,</span><span class='hljl-nf'>AbstractVector</span><span class='hljl-p'>{</span><span class='hljl-oB'>&lt;:</span><span class='hljl-n'>Distribution</span><span class='hljl-p'>}}</span><span class='hljl-t'> </span><span class='hljl-oB'>||</span><span class='hljl-t'> </span><span class='hljl-nf'>throw</span><span class='hljl-p'>(</span><span class='hljl-t'>
        </span><span class='hljl-nf'>ArgumentError</span><span class='hljl-p'>(</span><span class='hljl-t'>
            </span><span class='hljl-s'>&quot;Right-hand side of a ~ must be subtype of Distribution or a vector of Distributions.&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'>
        </span><span class='hljl-p'>),</span><span class='hljl-t'>
    </span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-so'>var&quot;##vn#325&quot;</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>DynamicPPL</span><span class='hljl-oB'>.</span><span class='hljl-n'>VarName</span><span class='hljl-p'>)(</span><span class='hljl-sc'>:p</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-p'>((</span><span class='hljl-ni'>1</span><span class='hljl-p'>,),))</span><span class='hljl-t'>
    </span><span class='hljl-so'>var&quot;##inds#326&quot;</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>((</span><span class='hljl-ni'>1</span><span class='hljl-p'>,),)</span><span class='hljl-t'>
    </span><span class='hljl-n'>p</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>DynamicPPL</span><span class='hljl-oB'>.</span><span class='hljl-n'>tilde_assume</span><span class='hljl-p'>)(</span><span class='hljl-t'>
        </span><span class='hljl-n'>_rng</span><span class='hljl-p'>,</span><span class='hljl-t'>
        </span><span class='hljl-n'>_context</span><span class='hljl-p'>,</span><span class='hljl-t'>
        </span><span class='hljl-n'>_sampler</span><span class='hljl-p'>,</span><span class='hljl-t'>
        </span><span class='hljl-so'>var&quot;##tmpright#323&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'>
        </span><span class='hljl-so'>var&quot;##vn#325&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'>
        </span><span class='hljl-so'>var&quot;##inds#326&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'>
        </span><span class='hljl-n'>_varinfo</span><span class='hljl-p'>,</span><span class='hljl-t'>
    </span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre>


<p>Here the first line is a so-called line number node that enables more helpful error messages by providing users with the exact location of the error in their model definition. Then the right hand side &#40;RHS&#41; of the <code>~</code> is assigned to a variable &#40;with an automatically generated name&#41;. We check that the RHS is a distribution or an array of distributions, otherwise an error is thrown. Next we extract a compact representation of the variable with its name and index &#40;or indices&#41;. Finally, the <code>~</code> expression is replaced with a call to <code>DynamicPPL.tilde_assume</code> since the compiler figured out that <code>p&#91;1&#93;</code> is a random variable using the following heuristic:</p>
<ol>
<li><p>If the symbol on the LHS of <code>~</code>, <code>:p</code> in this case, is not among the arguments to the model, <code>&#40;:x, :y, :T&#41;</code> in this case, it is a random variable.</p>
</li>
<li><p>If the symbol on the LHS of <code>~</code>, <code>:p</code> in this case, is among the arguments to the model but has a value of <code>missing</code>, it is a random variable.</p>
</li>
<li><p>If the value of the LHS of <code>~</code>, <code>p&#91;1&#93;</code> in this case, is <code>missing</code>, then it is a random variable.</p>
</li>
<li><p>Otherwise, it is treated as an observation.</p>
</li>
</ol>
<p>The <code>DynamicPPL.tilde_assume</code> function takes care of sampling the random variable, if needed, and updating its value and the accumulated log joint probability in the <code>_varinfo</code> object. If <code>L ~ R</code> is an observation, <code>DynamicPPL.tilde_observe</code> is called with the same arguments except the random number generator <code>_rng</code> &#40;since observations are never sampled&#41;.</p>
<p>A similar transformation is performed for expressions of the form <code>@. L ~ R</code> and <code>L .~ R</code>. For instance, <code>@. x&#91;1:2&#93; ~ Normal&#40;p&#91;2&#93;, sqrt&#40;p&#91;1&#93;&#41;&#41;</code> is replaced with</p>


<pre class='hljl'>
<span class='hljl-cm'>#= REPL[25]:8 =#</span><span class='hljl-t'>
</span><span class='hljl-k'>begin</span><span class='hljl-t'>
    </span><span class='hljl-so'>var&quot;##tmpright#331&quot;</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>Normal</span><span class='hljl-oB'>.</span><span class='hljl-p'>(</span><span class='hljl-n'>p</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>sqrt</span><span class='hljl-oB'>.</span><span class='hljl-p'>(</span><span class='hljl-n'>p</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]))</span><span class='hljl-t'>
    </span><span class='hljl-so'>var&quot;##tmpright#331&quot;</span><span class='hljl-t'> </span><span class='hljl-n'>isa</span><span class='hljl-t'> </span><span class='hljl-nf'>Union</span><span class='hljl-p'>{</span><span class='hljl-n'>Distribution</span><span class='hljl-p'>,</span><span class='hljl-nf'>AbstractVector</span><span class='hljl-p'>{</span><span class='hljl-oB'>&lt;:</span><span class='hljl-n'>Distribution</span><span class='hljl-p'>}}</span><span class='hljl-t'> </span><span class='hljl-oB'>||</span><span class='hljl-t'> </span><span class='hljl-nf'>throw</span><span class='hljl-p'>(</span><span class='hljl-t'>
        </span><span class='hljl-nf'>ArgumentError</span><span class='hljl-p'>(</span><span class='hljl-t'>
            </span><span class='hljl-s'>&quot;Right-hand side of a ~ must be subtype of Distribution or a vector of Distributions.&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'>
        </span><span class='hljl-p'>),</span><span class='hljl-t'>
    </span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-so'>var&quot;##vn#333&quot;</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>DynamicPPL</span><span class='hljl-oB'>.</span><span class='hljl-n'>VarName</span><span class='hljl-p'>)(</span><span class='hljl-sc'>:x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-p'>((</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>2</span><span class='hljl-p'>,),))</span><span class='hljl-t'>
    </span><span class='hljl-so'>var&quot;##inds#334&quot;</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>((</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>2</span><span class='hljl-p'>,),)</span><span class='hljl-t'>
    </span><span class='hljl-so'>var&quot;##isassumption#335&quot;</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-k'>begin</span><span class='hljl-t'>
        </span><span class='hljl-k'>let</span><span class='hljl-t'> </span><span class='hljl-so'>var&quot;##vn#336&quot;</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>DynamicPPL</span><span class='hljl-oB'>.</span><span class='hljl-n'>VarName</span><span class='hljl-p'>)(</span><span class='hljl-sc'>:x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-p'>((</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>2</span><span class='hljl-p'>,),))</span><span class='hljl-t'>
            </span><span class='hljl-k'>if</span><span class='hljl-t'> </span><span class='hljl-oB'>!</span><span class='hljl-p'>((</span><span class='hljl-n'>DynamicPPL</span><span class='hljl-oB'>.</span><span class='hljl-n'>inargnames</span><span class='hljl-p'>)(</span><span class='hljl-so'>var&quot;##vn#336&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>_model</span><span class='hljl-p'>))</span><span class='hljl-t'> </span><span class='hljl-oB'>||</span><span class='hljl-t'>
                </span><span class='hljl-p'>(</span><span class='hljl-n'>DynamicPPL</span><span class='hljl-oB'>.</span><span class='hljl-n'>inmissings</span><span class='hljl-p'>)(</span><span class='hljl-so'>var&quot;##vn#336&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>_model</span><span class='hljl-p'>)</span><span class='hljl-t'>
                </span><span class='hljl-kc'>true</span><span class='hljl-t'>
            </span><span class='hljl-k'>else</span><span class='hljl-t'>
                </span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>===</span><span class='hljl-t'> </span><span class='hljl-n'>missing</span><span class='hljl-t'>
            </span><span class='hljl-k'>end</span><span class='hljl-t'>
        </span><span class='hljl-k'>end</span><span class='hljl-t'>
    </span><span class='hljl-k'>end</span><span class='hljl-t'>
    </span><span class='hljl-k'>if</span><span class='hljl-t'> </span><span class='hljl-so'>var&quot;##isassumption#335&quot;</span><span class='hljl-t'>
        </span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>.=</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>DynamicPPL</span><span class='hljl-oB'>.</span><span class='hljl-n'>dot_tilde_assume</span><span class='hljl-p'>)(</span><span class='hljl-t'>
            </span><span class='hljl-n'>_rng</span><span class='hljl-p'>,</span><span class='hljl-t'>
            </span><span class='hljl-n'>_context</span><span class='hljl-p'>,</span><span class='hljl-t'>
            </span><span class='hljl-n'>_sampler</span><span class='hljl-p'>,</span><span class='hljl-t'>
            </span><span class='hljl-so'>var&quot;##tmpright#331&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'>
            </span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-t'>
            </span><span class='hljl-so'>var&quot;##vn#333&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'>
            </span><span class='hljl-so'>var&quot;##inds#334&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'>
            </span><span class='hljl-n'>_varinfo</span><span class='hljl-p'>,</span><span class='hljl-t'>
        </span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>else</span><span class='hljl-t'>
        </span><span class='hljl-p'>(</span><span class='hljl-n'>DynamicPPL</span><span class='hljl-oB'>.</span><span class='hljl-n'>dot_tilde_observe</span><span class='hljl-p'>)(</span><span class='hljl-t'>
            </span><span class='hljl-n'>_context</span><span class='hljl-p'>,</span><span class='hljl-t'>
            </span><span class='hljl-n'>_sampler</span><span class='hljl-p'>,</span><span class='hljl-t'>
            </span><span class='hljl-so'>var&quot;##tmpright#331&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'>
            </span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-t'>
            </span><span class='hljl-so'>var&quot;##vn#333&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'>
            </span><span class='hljl-so'>var&quot;##inds#334&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'>
            </span><span class='hljl-n'>_varinfo</span><span class='hljl-p'>,</span><span class='hljl-t'>
        </span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre>


<p>The main difference in the expanded code between <code>L ~ R</code> and <code>@. L ~ R</code> is that the former doesn&#39;t assume <code>L</code> to be defined, it can be a new Julia variable in the scope, while the latter assumes <code>L</code> already exists. Moreover, <code>DynamicPPL.dot_tilde_assume</code> and <code>DynamicPPL.dot_tilde_observe</code> are called instead of <code>DynamicPPL.tilde_assume</code> and <code>DynamicPPL.tilde_observe</code>.</p>
<h2>Step 3: Replace the user-provided function body</h2>
<p>Finally, we replace the user-provided function body using <code>DynamicPPL.build_output</code>. This function uses <code>MacroTools.combinedef</code> to reassemble the user-provided function with a new function body. In the modified function body an anonymous function is created whose function body was generated in step 2 above and whose arguments are</p>
<ul>
<li><p>a random number generator <code>_rng</code>,</p>
</li>
<li><p>a model <code>_model</code>,</p>
</li>
<li><p>a datastructure <code>_varinfo</code>,</p>
</li>
<li><p>a sampler <code>_sampler</code>,</p>
</li>
<li><p>a sampling context <code>_context</code>,</p>
</li>
<li><p>and all positional and keyword arguments of the user-provided model function as positional arguments without any default values. Finally, in the new function body a <code>model::Model</code> with this anonymous function as internal function is returned.</p>
</li>
</ul>
<h1><code>VarName</code></h1>
<p>In order to track random variables in the sampling process, <code>Turing</code> uses the <code>VarName</code> struct which acts as a random variable identifier generated at runtime. The <code>VarName</code> of a random variable is generated from the expression on the LHS of a <code>~</code> statement when the symbol on the LHS is in the set <code>P</code> of unobserved random variables. Every <code>VarName</code> instance has a type parameter <code>sym</code> which is the symbol of the Julia variable in the model that the random variable belongs to. For example, <code>x&#91;1&#93; ~ Normal&#40;&#41;</code> will generate an instance of <code>VarName&#123;:x&#125;</code> assuming <code>x</code> is an unobserved random variable. Every <code>VarName</code> also has a field <code>indexing</code>, which stores the indices required to access the random variable from the Julia variable indicated by <code>sym</code> as a tuple of tuples.  Each element of the tuple thereby contains the indices of one indexing operation &#40;<code>VarName</code> also supports hierarchical arrays and range indexing&#41;. Some examples:</p>
<ul>
<li><p><code>x ~ Normal&#40;&#41;</code> will generate a <code>VarName&#40;:x, &#40;&#41;&#41;</code>.</p>
</li>
<li><p><code>x&#91;1&#93; ~ Normal&#40;&#41;</code> will generate a <code>VarName&#40;:x, &#40;&#40;1,&#41;,&#41;&#41;</code>.</p>
</li>
<li><p><code>x&#91;:,1&#93; ~ MvNormal&#40;zeros&#40;2&#41;, I&#41;</code> will generate a <code>VarName&#40;:x, &#40;&#40;Colon&#40;&#41;, 1&#41;,&#41;&#41;</code>.</p>
</li>
<li><p><code>x&#91;:,1&#93;&#91;1&#43;1&#93; ~ Normal&#40;&#41;</code> will generate a <code>VarName&#40;:x, &#40;&#40;Colon&#40;&#41;, 1&#41;, &#40;2,&#41;&#41;&#41;</code>.</p>
</li>
</ul>
<p>The easiest way to manually construct a <code>VarName</code> is to use the <code>@varname</code> macro on an indexing expression, which will take the <code>sym</code> value from the actual variable name, and put the index values appropriately into the constructor.</p>
<h1><code>VarInfo</code></h1>
<h2>Overview</h2>
<p><code>VarInfo</code> is the data structure in <code>Turing</code> that facilitates tracking random variables and certain metadata about them that are required for sampling. For instance, the distribution of every random variable is stored in <code>VarInfo</code> because we need to know the support of every random variable when sampling using HMC for example. Random variables whose distributions have a constrained support are transformed using a bijector from <a href="https://github.com/TuringLang/Bijectors.jl">Bijectors.jl</a> so that the sampling happens in the unconstrained space. Different samplers require different metadata about the random variables.</p>
<p>The definition of <code>VarInfo</code> in <code>Turing</code> is:</p>


<pre class='hljl'>
<span class='hljl-k'>struct</span><span class='hljl-t'> </span><span class='hljl-nf'>VarInfo</span><span class='hljl-p'>{</span><span class='hljl-n'>Tmeta</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Tlogp</span><span class='hljl-p'>}</span><span class='hljl-t'> </span><span class='hljl-oB'>&lt;:</span><span class='hljl-t'> </span><span class='hljl-n'>AbstractVarInfo</span><span class='hljl-t'>
    </span><span class='hljl-n'>metadata</span><span class='hljl-oB'>::</span><span class='hljl-n'>Tmeta</span><span class='hljl-t'>
    </span><span class='hljl-n'>logp</span><span class='hljl-oB'>::</span><span class='hljl-n'>Base</span><span class='hljl-oB'>.</span><span class='hljl-nf'>RefValue</span><span class='hljl-p'>{</span><span class='hljl-n'>Tlogp</span><span class='hljl-p'>}</span><span class='hljl-t'>
    </span><span class='hljl-n'>num_produce</span><span class='hljl-oB'>::</span><span class='hljl-n'>Base</span><span class='hljl-oB'>.</span><span class='hljl-nf'>RefValue</span><span class='hljl-p'>{</span><span class='hljl-n'>Int</span><span class='hljl-p'>}</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre>


<p>Based on the type of <code>metadata</code>, the <code>VarInfo</code> is either aliased <code>UntypedVarInfo</code> or <code>TypedVarInfo</code>. <code>metadata</code> can be either a subtype of the union type <code>Metadata</code> or a <code>NamedTuple</code> of multiple such subtypes. Let <code>vi</code> be an instance of <code>VarInfo</code>. If <code>vi isa VarInfo&#123;&lt;:Metadata&#125;</code>, then it is called an <code>UntypedVarInfo</code>. If <code>vi isa VarInfo&#123;&lt;:NamedTuple&#125;</code>, then <code>vi.metadata</code> would be a <code>NamedTuple</code> mapping each symbol in <code>P</code> to an instance of <code>Metadata</code>. <code>vi</code> would then be called a <code>TypedVarInfo</code>. The other fields of <code>VarInfo</code> include <code>logp</code> which is used to accumulate the log probability or log probability density of the variables in <code>P</code> and <code>D</code>. <code>num_produce</code> keeps track of how many observations have been made in the model so far. This is incremented when running a <code>~</code> statement when the symbol on the LHS is in <code>D</code>.</p>
<h2><code>Metadata</code></h2>
<p>The <code>Metadata</code> struct stores some metadata about the random variables sampled. This helps query certain information about a variable such as: its distribution, which samplers sample this variable, its value and whether this value is transformed to real space or not. Let <code>md</code> be an instance of <code>Metadata</code>:</p>
<ul>
<li><p><code>md.vns</code> is the vector of all <code>VarName</code> instances. Let <code>vn</code> be an arbitrary element of <code>md.vns</code></p>
</li>
<li><p><code>md.idcs</code> is the dictionary that maps each <code>VarName</code> instance to its index in <code>md.vns</code>, <code>md.ranges</code>, <code>md.dists</code>, <code>md.orders</code> and <code>md.flags</code>.</p>
</li>
<li><p><code>md.vns&#91;md.idcs&#91;vn&#93;&#93; &#61;&#61; vn</code>.</p>
</li>
<li><p><code>md.dists&#91;md.idcs&#91;vn&#93;&#93;</code> is the distribution of <code>vn</code>.</p>
</li>
<li><p><code>md.gids&#91;md.idcs&#91;vn&#93;&#93;</code> is the set of algorithms used to sample <code>vn</code>. This is used in the Gibbs sampling process.</p>
</li>
<li><p><code>md.orders&#91;md.idcs&#91;vn&#93;&#93;</code> is the number of <code>observe</code> statements before <code>vn</code> is sampled.</p>
</li>
<li><p><code>md.ranges&#91;md.idcs&#91;vn&#93;&#93;</code> is the index range of <code>vn</code> in <code>md.vals</code>.</p>
</li>
<li><p><code>md.vals&#91;md.ranges&#91;md.idcs&#91;vn&#93;&#93;&#93;</code> is the linearized vector of values of corresponding to <code>vn</code>.</p>
</li>
<li><p><code>md.flags</code> is a dictionary of true/false flags. <code>md.flags&#91;flag&#93;&#91;md.idcs&#91;vn&#93;&#93;</code> is the value of <code>flag</code> corresponding to <code>vn</code>.</p>
</li>
</ul>
<p>Note that in order to make <code>md::Metadata</code> type stable, all the <code>md.vns</code> must have the same symbol and distribution type. However, one can have a single Julia variable, e.g. <code>x</code>, that is a matrix or a hierarchical array sampled in partitions, e.g. <code>x&#91;1&#93;&#91;:&#93; ~ MvNormal&#40;zeros&#40;2&#41;, I&#41;; x&#91;2&#93;&#91;:&#93; ~ MvNormal&#40;ones&#40;2&#41;, I&#41;</code>. The symbol <code>x</code> can still be managed by a single <code>md::Metadata</code> without hurting the type stability since all the distributions on the RHS of <code>~</code> are of the same type.</p>
<p>However, in <code>Turing</code> models one cannot have this restriction, so we must use a type unstable <code>Metadata</code> if we want to use one <code>Metadata</code> instance for the whole model. This is what <code>UntypedVarInfo</code> does. A type unstable <code>Metadata</code> will still work but will have inferior performance.</p>
<p>To strike a balance between flexibility and performance when constructing the <code>spl::Sampler</code> instance, the model is first run by sampling the parameters in <code>P</code> from their priors using an <code>UntypedVarInfo</code>, i.e. a type unstable <code>Metadata</code> is used for all the variables. Then once all the symbols and distribution types have been identified, a <code>vi::TypedVarInfo</code> is constructed where <code>vi.metadata</code> is a <code>NamedTuple</code> mapping each symbol in <code>P</code> to a specialized instance of <code>Metadata</code>. So as long as each symbol in <code>P</code> is sampled from only one type of distributions, <code>vi::TypedVarInfo</code> will have fully concretely typed fields which brings out the peak performance of Julia.</p>


        <HR/>
        <div class="footer">
          <p>
            Published from <a href="compiler.jmd">compiler.jmd</a>
            using <a href="http://github.com/JunoLab/Weave.jl">Weave.jl</a> v0.10.12 on 2023-08-12.
          </p>
        </div>
      </div>
    </div>
  </div>
</BODY>

</HTML>
