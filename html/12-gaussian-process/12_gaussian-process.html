<!DOCTYPE html>
<HTML lang = "en">
<HEAD>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Gaussian Process Latent Variable Model</title>
  

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      TeX: { equationNumbers: { autoNumber: "AMS" } }
    });
  </script>

  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>

  
<style>
pre.hljl {
    border: 1px solid #ccc;
    margin: 5px;
    padding: 5px;
    overflow-x: auto;
    color: rgb(68,68,68); background-color: rgb(251,251,251); }
pre.hljl > span.hljl-t { }
pre.hljl > span.hljl-w { }
pre.hljl > span.hljl-e { }
pre.hljl > span.hljl-eB { }
pre.hljl > span.hljl-o { }
pre.hljl > span.hljl-k { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kc { color: rgb(59,151,46); font-style: italic; }
pre.hljl > span.hljl-kd { color: rgb(214,102,97); font-style: italic; }
pre.hljl > span.hljl-kn { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kp { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kr { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kt { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-n { }
pre.hljl > span.hljl-na { }
pre.hljl > span.hljl-nb { }
pre.hljl > span.hljl-nbp { }
pre.hljl > span.hljl-nc { }
pre.hljl > span.hljl-ncB { }
pre.hljl > span.hljl-nd { color: rgb(214,102,97); }
pre.hljl > span.hljl-ne { }
pre.hljl > span.hljl-neB { }
pre.hljl > span.hljl-nf { color: rgb(66,102,213); }
pre.hljl > span.hljl-nfm { color: rgb(66,102,213); }
pre.hljl > span.hljl-np { }
pre.hljl > span.hljl-nl { }
pre.hljl > span.hljl-nn { }
pre.hljl > span.hljl-no { }
pre.hljl > span.hljl-nt { }
pre.hljl > span.hljl-nv { }
pre.hljl > span.hljl-nvc { }
pre.hljl > span.hljl-nvg { }
pre.hljl > span.hljl-nvi { }
pre.hljl > span.hljl-nvm { }
pre.hljl > span.hljl-l { }
pre.hljl > span.hljl-ld { color: rgb(148,91,176); font-style: italic; }
pre.hljl > span.hljl-s { color: rgb(201,61,57); }
pre.hljl > span.hljl-sa { color: rgb(201,61,57); }
pre.hljl > span.hljl-sb { color: rgb(201,61,57); }
pre.hljl > span.hljl-sc { color: rgb(201,61,57); }
pre.hljl > span.hljl-sd { color: rgb(201,61,57); }
pre.hljl > span.hljl-sdB { color: rgb(201,61,57); }
pre.hljl > span.hljl-sdC { color: rgb(201,61,57); }
pre.hljl > span.hljl-se { color: rgb(59,151,46); }
pre.hljl > span.hljl-sh { color: rgb(201,61,57); }
pre.hljl > span.hljl-si { }
pre.hljl > span.hljl-so { color: rgb(201,61,57); }
pre.hljl > span.hljl-sr { color: rgb(201,61,57); }
pre.hljl > span.hljl-ss { color: rgb(201,61,57); }
pre.hljl > span.hljl-ssB { color: rgb(201,61,57); }
pre.hljl > span.hljl-nB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nbB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nfB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nh { color: rgb(59,151,46); }
pre.hljl > span.hljl-ni { color: rgb(59,151,46); }
pre.hljl > span.hljl-nil { color: rgb(59,151,46); }
pre.hljl > span.hljl-noB { color: rgb(59,151,46); }
pre.hljl > span.hljl-oB { color: rgb(102,102,102); font-weight: bold; }
pre.hljl > span.hljl-ow { color: rgb(102,102,102); font-weight: bold; }
pre.hljl > span.hljl-p { }
pre.hljl > span.hljl-c { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-ch { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cm { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cp { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cpB { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cs { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-csB { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-g { }
pre.hljl > span.hljl-gd { }
pre.hljl > span.hljl-ge { }
pre.hljl > span.hljl-geB { }
pre.hljl > span.hljl-gh { }
pre.hljl > span.hljl-gi { }
pre.hljl > span.hljl-go { }
pre.hljl > span.hljl-gp { }
pre.hljl > span.hljl-gs { }
pre.hljl > span.hljl-gsB { }
pre.hljl > span.hljl-gt { }
</style>



  <style type="text/css">
  @font-face {
  font-style: normal;
  font-weight: 300;
}
@font-face {
  font-style: normal;
  font-weight: 400;
}
@font-face {
  font-style: normal;
  font-weight: 600;
}
html {
  font-family: sans-serif; /* 1 */
  -ms-text-size-adjust: 100%; /* 2 */
  -webkit-text-size-adjust: 100%; /* 2 */
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block; /* 1 */
  vertical-align: baseline; /* 2 */
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 70%;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit; /* 1 */
  font: inherit; /* 2 */
  margin: 0; /* 3 */
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button; /* 2 */
  cursor: pointer; /* 3 */
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box; /* 1 */
  padding: 0; /* 2 */
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield; /* 1 */
  -moz-box-sizing: content-box;
  -webkit-box-sizing: content-box; /* 2 */
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0; /* 1 */
  padding: 0; /* 2 */
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  font-family: monospace, monospace;
  font-size : 0.8em;
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
thead th {
    border-bottom: 1px solid black;
    background-color: white;
}
tr:nth-child(odd){
  background-color: rgb(248,248,248);
}


/*
* Skeleton V2.0.4
* Copyright 2014, Dave Gamache
* www.getskeleton.com
* Free to use under the MIT license.
* http://www.opensource.org/licenses/mit-license.php
* 12/29/2014
*/
.container {
  position: relative;
  width: 100%;
  max-width: 960px;
  margin: 0 auto;
  padding: 0 20px;
  box-sizing: border-box; }
.column,
.columns {
  width: 100%;
  float: left;
  box-sizing: border-box; }
@media (min-width: 400px) {
  .container {
    width: 85%;
    padding: 0; }
}
@media (min-width: 550px) {
  .container {
    width: 80%; }
  .column,
  .columns {
    margin-left: 4%; }
  .column:first-child,
  .columns:first-child {
    margin-left: 0; }

  .one.column,
  .one.columns                    { width: 4.66666666667%; }
  .two.columns                    { width: 13.3333333333%; }
  .three.columns                  { width: 22%;            }
  .four.columns                   { width: 30.6666666667%; }
  .five.columns                   { width: 39.3333333333%; }
  .six.columns                    { width: 48%;            }
  .seven.columns                  { width: 56.6666666667%; }
  .eight.columns                  { width: 65.3333333333%; }
  .nine.columns                   { width: 74.0%;          }
  .ten.columns                    { width: 82.6666666667%; }
  .eleven.columns                 { width: 91.3333333333%; }
  .twelve.columns                 { width: 100%; margin-left: 0; }

  .one-third.column               { width: 30.6666666667%; }
  .two-thirds.column              { width: 65.3333333333%; }

  .one-half.column                { width: 48%; }

  /* Offsets */
  .offset-by-one.column,
  .offset-by-one.columns          { margin-left: 8.66666666667%; }
  .offset-by-two.column,
  .offset-by-two.columns          { margin-left: 17.3333333333%; }
  .offset-by-three.column,
  .offset-by-three.columns        { margin-left: 26%;            }
  .offset-by-four.column,
  .offset-by-four.columns         { margin-left: 34.6666666667%; }
  .offset-by-five.column,
  .offset-by-five.columns         { margin-left: 43.3333333333%; }
  .offset-by-six.column,
  .offset-by-six.columns          { margin-left: 52%;            }
  .offset-by-seven.column,
  .offset-by-seven.columns        { margin-left: 60.6666666667%; }
  .offset-by-eight.column,
  .offset-by-eight.columns        { margin-left: 69.3333333333%; }
  .offset-by-nine.column,
  .offset-by-nine.columns         { margin-left: 78.0%;          }
  .offset-by-ten.column,
  .offset-by-ten.columns          { margin-left: 86.6666666667%; }
  .offset-by-eleven.column,
  .offset-by-eleven.columns       { margin-left: 95.3333333333%; }

  .offset-by-one-third.column,
  .offset-by-one-third.columns    { margin-left: 34.6666666667%; }
  .offset-by-two-thirds.column,
  .offset-by-two-thirds.columns   { margin-left: 69.3333333333%; }

  .offset-by-one-half.column,
  .offset-by-one-half.columns     { margin-left: 52%; }

}
html {
  font-size: 62.5%; }
body {
  font-size: 1.5em; /* currently ems cause chrome bug misinterpreting rems on body element */
  line-height: 1.6;
  font-weight: 400;
  font-family: "Raleway", "HelveticaNeue", "Helvetica Neue", Helvetica, Arial, sans-serif;
  color: #222; }
h1, h2, h3, h4, h5, h6 {
  margin-top: 0;
  margin-bottom: 2rem;
  font-weight: 300; }
h1 { font-size: 3.6rem; line-height: 1.2;  letter-spacing: -.1rem;}
h2 { font-size: 3.4rem; line-height: 1.25; letter-spacing: -.1rem; }
h3 { font-size: 3.2rem; line-height: 1.3;  letter-spacing: -.1rem; }
h4 { font-size: 2.8rem; line-height: 1.35; letter-spacing: -.08rem; }
h5 { font-size: 2.4rem; line-height: 1.5;  letter-spacing: -.05rem; }
h6 { font-size: 1.5rem; line-height: 1.6;  letter-spacing: 0; }

p {
  margin-top: 0; }
a {
  color: #1EAEDB; }
a:hover {
  color: #0FA0CE; }
.button,
button,
input[type="submit"],
input[type="reset"],
input[type="button"] {
  display: inline-block;
  height: 38px;
  padding: 0 30px;
  color: #555;
  text-align: center;
  font-size: 11px;
  font-weight: 600;
  line-height: 38px;
  letter-spacing: .1rem;
  text-transform: uppercase;
  text-decoration: none;
  white-space: nowrap;
  background-color: transparent;
  border-radius: 4px;
  border: 1px solid #bbb;
  cursor: pointer;
  box-sizing: border-box; }
.button:hover,
button:hover,
input[type="submit"]:hover,
input[type="reset"]:hover,
input[type="button"]:hover,
.button:focus,
button:focus,
input[type="submit"]:focus,
input[type="reset"]:focus,
input[type="button"]:focus {
  color: #333;
  border-color: #888;
  outline: 0; }
.button.button-primary,
button.button-primary,
input[type="submit"].button-primary,
input[type="reset"].button-primary,
input[type="button"].button-primary {
  color: #FFF;
  background-color: #33C3F0;
  border-color: #33C3F0; }
.button.button-primary:hover,
button.button-primary:hover,
input[type="submit"].button-primary:hover,
input[type="reset"].button-primary:hover,
input[type="button"].button-primary:hover,
.button.button-primary:focus,
button.button-primary:focus,
input[type="submit"].button-primary:focus,
input[type="reset"].button-primary:focus,
input[type="button"].button-primary:focus {
  color: #FFF;
  background-color: #1EAEDB;
  border-color: #1EAEDB; }
input[type="email"],
input[type="number"],
input[type="search"],
input[type="text"],
input[type="tel"],
input[type="url"],
input[type="password"],
textarea,
select {
  height: 38px;
  padding: 6px 10px; /* The 6px vertically centers text on FF, ignored by Webkit */
  background-color: #fff;
  border: 1px solid #D1D1D1;
  border-radius: 4px;
  box-shadow: none;
  box-sizing: border-box; }
/* Removes awkward default styles on some inputs for iOS */
input[type="email"],
input[type="number"],
input[type="search"],
input[type="text"],
input[type="tel"],
input[type="url"],
input[type="password"],
textarea {
  -webkit-appearance: none;
     -moz-appearance: none;
          appearance: none; }
textarea {
  min-height: 65px;
  padding-top: 6px;
  padding-bottom: 6px; }
input[type="email"]:focus,
input[type="number"]:focus,
input[type="search"]:focus,
input[type="text"]:focus,
input[type="tel"]:focus,
input[type="url"]:focus,
input[type="password"]:focus,
textarea:focus,
select:focus {
  border: 1px solid #33C3F0;
  outline: 0; }
label,
legend {
  display: block;
  margin-bottom: .5rem;
  font-weight: 600; }
fieldset {
  padding: 0;
  border-width: 0; }
input[type="checkbox"],
input[type="radio"] {
  display: inline; }
label > .label-body {
  display: inline-block;
  margin-left: .5rem;
  font-weight: normal; }
ul {
  list-style: circle; }
ol {
  list-style: decimal; }
ul ul,
ul ol,
ol ol,
ol ul {
  margin: 1.5rem 0 1.5rem 3rem;
  font-size: 90%; }
li > p {margin : 0;}
th,
td {
  padding: 12px 15px;
  text-align: left;
  border-bottom: 1px solid #E1E1E1; }
th:first-child,
td:first-child {
  padding-left: 0; }
th:last-child,
td:last-child {
  padding-right: 0; }
button,
.button {
  margin-bottom: 1rem; }
input,
textarea,
select,
fieldset {
  margin-bottom: 1.5rem; }
pre,
blockquote,
dl,
figure,
table,
p,
ul,
ol,
form {
  margin-bottom: 1.0rem; }
.u-full-width {
  width: 100%;
  box-sizing: border-box; }
.u-max-full-width {
  max-width: 100%;
  box-sizing: border-box; }
.u-pull-right {
  float: right; }
.u-pull-left {
  float: left; }
hr {
  margin-top: 3rem;
  margin-bottom: 3.5rem;
  border-width: 0;
  border-top: 1px solid #E1E1E1; }
.container:after,
.row:after,
.u-cf {
  content: "";
  display: table;
  clear: both; }

pre {
  display: block;
  padding: 9.5px;
  margin: 0 0 10px;
  font-size: 13px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre.hljl {
  margin: 0 0 10px;
  display: block;
  background: #f5f5f5;
  border-radius: 4px;
  padding : 5px;
}

pre.output {
  background: #ffffff;
}

pre.code {
  background: #ffffff;
}

pre.julia-error {
  color : red
}

code,
kbd,
pre,
samp {
  font-family: Menlo, Monaco, Consolas, "Courier New", monospace;
  font-size: 13px;
}


@media (min-width: 400px) {}
@media (min-width: 550px) {}
@media (min-width: 750px) {}
@media (min-width: 1000px) {}
@media (min-width: 1200px) {}

h1.title {margin-top : 20px}
img {max-width : 100%}
div.title {text-align: center;}

  </style>
</HEAD>

<BODY>
  <div class ="container">
    <div class = "row">
      <div class = "col-md-12 twelve columns">
        <div class="title">
          <h1 class="title">Gaussian Process Latent Variable Model</h1>
          
          
        </div>

        <h1>Gaussian Process Latent Variable Model</h1>
<p>In a previous tutorial, we have discussed latent variable models, in particular probabilistic principal component analysis &#40;pPCA&#41;. Here, we show how we can extend the mapping provided by pPCA to non-linear mappings between input and output. For more details about the Gaussian Process Latent Variable Model &#40;GPLVM&#41;, we refer the reader to the <a href="https://jmlr.org/papers/v6/lawrence05a.html">original publication</a> and a <a href="http://proceedings.mlr.press/v9/titsias10a/titsias10a.pdf">further extension</a>.</p>
<p>In short, the GPVLM is a dimensionality reduction technique that allows us to embed a high-dimensional dataset in a lower-dimensional embedding. Importantly, it provides the advantage that the linear mappings from the embedded space can be non-linearised through the use of Gaussian Processes.</p>
<p>Let&#39;s start by loading some dependencies.</p>


<pre class='hljl'>
<span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>Turing</span><span class='hljl-t'>
</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>AbstractGPs</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>KernelFunctions</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Random</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Plots</span><span class='hljl-t'>

</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>LinearAlgebra</span><span class='hljl-t'>
</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>VegaLite</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>DataFrames</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>StatsPlots</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>StatsBase</span><span class='hljl-t'>
</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>RDatasets</span><span class='hljl-t'>

</span><span class='hljl-n'>Random</span><span class='hljl-oB'>.</span><span class='hljl-nf'>seed!</span><span class='hljl-p'>(</span><span class='hljl-ni'>1789</span><span class='hljl-p'>);</span>
</pre>


<pre class="julia-error">
ERROR: Failed to precompile RDatasets &#91;ce6b1742-4840-55fa-b093-852dadbb1d8b&#93; to /cache/julia-buildkite-plugin/depots/7aa0085e-79a4-45f3-a5bd-9743c91cf3da/compiled/v1.6/RDatasets/jl_Iu0vq0.
</pre>


<p>We demonstrate the GPLVM with a very small dataset: <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">Fisher&#39;s Iris data set</a>. This is mostly for reasons of run time, so the tutorial can be run quickly. As you will see, one of the major drawbacks of using GPs is their speed, although this is an active area of research. We will briefly touch on some ways to speed things up at the end of this tutorial. We transform the original data with non-linear operations in order to demonstrate the power of GPs to work on non-linear relationships, while keeping the problem reasonably small.</p>


<pre class='hljl'>
<span class='hljl-n'>data</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>dataset</span><span class='hljl-p'>(</span><span class='hljl-s'>&quot;datasets&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-s'>&quot;iris&quot;</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>species</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>data</span><span class='hljl-p'>[</span><span class='hljl-oB'>!</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-s'>&quot;Species&quot;</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>index</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>shuffle</span><span class='hljl-p'>(</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>150</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-cs'># we extract the four measured quantities,</span><span class='hljl-t'>
</span><span class='hljl-cs'># so the dimension of the data is only d=4 for this toy example</span><span class='hljl-t'>
</span><span class='hljl-n'>dat</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Matrix</span><span class='hljl-p'>(</span><span class='hljl-n'>data</span><span class='hljl-p'>[</span><span class='hljl-n'>index</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>4</span><span class='hljl-p'>])</span><span class='hljl-t'>
</span><span class='hljl-n'>labels</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>data</span><span class='hljl-p'>[</span><span class='hljl-n'>index</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-s'>&quot;Species&quot;</span><span class='hljl-p'>]</span><span class='hljl-t'>

</span><span class='hljl-cs'># non-linearize data to demonstrate ability of GPs to deal with non-linearity</span><span class='hljl-t'>
</span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.5</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>.^</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.1</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>.^</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-t'>
</span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>.^</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.2</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>.^</span><span class='hljl-t'> </span><span class='hljl-ni'>4</span><span class='hljl-t'>
</span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.1</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-n'>exp</span><span class='hljl-oB'>.</span><span class='hljl-p'>(</span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-p'>])</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.2</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>.^</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-t'>
</span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>4</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.5</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-n'>log</span><span class='hljl-oB'>.</span><span class='hljl-p'>(</span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>4</span><span class='hljl-p'>])</span><span class='hljl-t'> </span><span class='hljl-oB'>.^</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.01</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>.^</span><span class='hljl-t'> </span><span class='hljl-ni'>5</span><span class='hljl-t'>

</span><span class='hljl-cs'># normalize data</span><span class='hljl-t'>
</span><span class='hljl-n'>dt</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>fit</span><span class='hljl-p'>(</span><span class='hljl-n'>ZScoreTransform</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>dat</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>dims</span><span class='hljl-oB'>=</span><span class='hljl-ni'>1</span><span class='hljl-p'>);</span><span class='hljl-t'>
</span><span class='hljl-n'>StatsBase</span><span class='hljl-oB'>.</span><span class='hljl-nf'>transform!</span><span class='hljl-p'>(</span><span class='hljl-n'>dt</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>dat</span><span class='hljl-p'>);</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: dataset not defined
</pre>


<p>We will start out by demonstrating the basic similarity between pPCA &#40;see the tutorial on this topic&#41; and the GPLVM model. Indeed, pPCA is basically equivalent to running the GPLVM model with an automatic relevance determination &#40;ARD&#41; linear kernel.</p>
<p>First, we re-introduce the pPCA model &#40;see the tutorial on pPCA for details&#41;</p>


<pre class='hljl'>
<span class='hljl-nd'>@model</span><span class='hljl-t'> </span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>pPCA</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>::</span><span class='hljl-nf'>Type</span><span class='hljl-p'>{</span><span class='hljl-n'>TV</span><span class='hljl-p'>}</span><span class='hljl-oB'>=</span><span class='hljl-nf'>Array</span><span class='hljl-p'>{</span><span class='hljl-n'>Float64</span><span class='hljl-p'>})</span><span class='hljl-t'> </span><span class='hljl-n'>where</span><span class='hljl-t'> </span><span class='hljl-p'>{</span><span class='hljl-n'>TV</span><span class='hljl-p'>}</span><span class='hljl-t'>
    </span><span class='hljl-cs'># Dimensionality of the problem.</span><span class='hljl-t'>
    </span><span class='hljl-n'>N</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>D</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>size</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-cs'># latent variable z</span><span class='hljl-t'>
    </span><span class='hljl-n'>z</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>filldist</span><span class='hljl-p'>(</span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(),</span><span class='hljl-t'> </span><span class='hljl-n'>D</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>N</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-cs'># weights/loadings W</span><span class='hljl-t'>
    </span><span class='hljl-n'>w</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>filldist</span><span class='hljl-p'>(</span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(),</span><span class='hljl-t'> </span><span class='hljl-n'>D</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>D</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>mu</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>w</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-n'>z</span><span class='hljl-p'>)</span><span class='hljl-oB'>&#39;</span><span class='hljl-t'>
    </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>d</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>D</span><span class='hljl-t'>
        </span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>d</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>MvNormal</span><span class='hljl-p'>(</span><span class='hljl-n'>mu</span><span class='hljl-p'>[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>d</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>I</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-p'>;</span>
</pre>



<p>We define two different kernels, a simple linear kernel with an Automatic Relevance Determination transform and a squared exponential kernel.</p>


<pre class='hljl'>
<span class='hljl-nf'>linear_kernel</span><span class='hljl-p'>(</span><span class='hljl-n'>α</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>LinearKernel</span><span class='hljl-p'>()</span><span class='hljl-t'> </span><span class='hljl-oB'>∘</span><span class='hljl-t'> </span><span class='hljl-nf'>ARDTransform</span><span class='hljl-p'>(</span><span class='hljl-n'>α</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nf'>sekernel</span><span class='hljl-p'>(</span><span class='hljl-n'>α</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>σ</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>σ</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nf'>SqExponentialKernel</span><span class='hljl-p'>()</span><span class='hljl-t'> </span><span class='hljl-oB'>∘</span><span class='hljl-t'> </span><span class='hljl-nf'>ARDTransform</span><span class='hljl-p'>(</span><span class='hljl-n'>α</span><span class='hljl-p'>);</span>
</pre>



<p>And here is the GPLVM model. We create separate models for the two types of kernel.</p>


<pre class='hljl'>
<span class='hljl-nd'>@model</span><span class='hljl-t'> </span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>GPLVM_linear</span><span class='hljl-p'>(</span><span class='hljl-n'>Y</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>K</span><span class='hljl-oB'>=</span><span class='hljl-ni'>4</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>::</span><span class='hljl-nf'>Type</span><span class='hljl-p'>{</span><span class='hljl-n'>T</span><span class='hljl-p'>}</span><span class='hljl-oB'>=</span><span class='hljl-n'>Float64</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-n'>where</span><span class='hljl-t'> </span><span class='hljl-p'>{</span><span class='hljl-n'>T</span><span class='hljl-p'>}</span><span class='hljl-t'>

    </span><span class='hljl-cs'># Dimensionality of the problem.</span><span class='hljl-t'>
    </span><span class='hljl-n'>N</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>D</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>size</span><span class='hljl-p'>(</span><span class='hljl-n'>Y</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-cs'># K is the dimension of the latent space</span><span class='hljl-t'>
    </span><span class='hljl-nd'>@assert</span><span class='hljl-t'> </span><span class='hljl-n'>K</span><span class='hljl-t'> </span><span class='hljl-oB'>&lt;=</span><span class='hljl-t'> </span><span class='hljl-n'>D</span><span class='hljl-t'>
    </span><span class='hljl-n'>noise</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>1e-3</span><span class='hljl-t'>

    </span><span class='hljl-cs'># Priors</span><span class='hljl-t'>
    </span><span class='hljl-n'>α</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>MvLogNormal</span><span class='hljl-p'>(</span><span class='hljl-nf'>MvNormal</span><span class='hljl-p'>(</span><span class='hljl-nf'>zeros</span><span class='hljl-p'>(</span><span class='hljl-n'>K</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>I</span><span class='hljl-p'>))</span><span class='hljl-t'>
    </span><span class='hljl-n'>Z</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>filldist</span><span class='hljl-p'>(</span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(),</span><span class='hljl-t'> </span><span class='hljl-n'>K</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>N</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>mu</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>filldist</span><span class='hljl-p'>(</span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(),</span><span class='hljl-t'> </span><span class='hljl-n'>N</span><span class='hljl-p'>)</span><span class='hljl-t'>

    </span><span class='hljl-n'>kernel</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>linear_kernel</span><span class='hljl-p'>(</span><span class='hljl-n'>α</span><span class='hljl-p'>)</span><span class='hljl-t'>

    </span><span class='hljl-n'>gp</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>GP</span><span class='hljl-p'>(</span><span class='hljl-n'>mu</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>kernel</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>cv</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>cov</span><span class='hljl-p'>(</span><span class='hljl-nf'>gp</span><span class='hljl-p'>(</span><span class='hljl-nf'>ColVecs</span><span class='hljl-p'>(</span><span class='hljl-n'>Z</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>noise</span><span class='hljl-p'>))</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>Y</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>filldist</span><span class='hljl-p'>(</span><span class='hljl-nf'>MvNormal</span><span class='hljl-p'>(</span><span class='hljl-n'>mu</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>cv</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>D</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-p'>;</span><span class='hljl-t'>

</span><span class='hljl-nd'>@model</span><span class='hljl-t'> </span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>GPLVM</span><span class='hljl-p'>(</span><span class='hljl-n'>Y</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>K</span><span class='hljl-oB'>=</span><span class='hljl-ni'>4</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>::</span><span class='hljl-nf'>Type</span><span class='hljl-p'>{</span><span class='hljl-n'>T</span><span class='hljl-p'>}</span><span class='hljl-oB'>=</span><span class='hljl-n'>Float64</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-n'>where</span><span class='hljl-t'> </span><span class='hljl-p'>{</span><span class='hljl-n'>T</span><span class='hljl-p'>}</span><span class='hljl-t'>

    </span><span class='hljl-cs'># Dimensionality of the problem.</span><span class='hljl-t'>
    </span><span class='hljl-n'>N</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>D</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>size</span><span class='hljl-p'>(</span><span class='hljl-n'>Y</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-cs'># K is the dimension of the latent space</span><span class='hljl-t'>
    </span><span class='hljl-nd'>@assert</span><span class='hljl-t'> </span><span class='hljl-n'>K</span><span class='hljl-t'> </span><span class='hljl-oB'>&lt;=</span><span class='hljl-t'> </span><span class='hljl-n'>D</span><span class='hljl-t'>
    </span><span class='hljl-n'>noise</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>1e-3</span><span class='hljl-t'>

    </span><span class='hljl-cs'># Priors</span><span class='hljl-t'>
    </span><span class='hljl-n'>α</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>MvLogNormal</span><span class='hljl-p'>(</span><span class='hljl-nf'>MvNormal</span><span class='hljl-p'>(</span><span class='hljl-nf'>zeros</span><span class='hljl-p'>(</span><span class='hljl-n'>K</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>I</span><span class='hljl-p'>))</span><span class='hljl-t'>
    </span><span class='hljl-n'>σ</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>LogNormal</span><span class='hljl-p'>(</span><span class='hljl-nfB'>0.0</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>Z</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>filldist</span><span class='hljl-p'>(</span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(),</span><span class='hljl-t'> </span><span class='hljl-n'>K</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>N</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>mu</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>filldist</span><span class='hljl-p'>(</span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(),</span><span class='hljl-t'> </span><span class='hljl-n'>N</span><span class='hljl-p'>)</span><span class='hljl-t'>

    </span><span class='hljl-n'>kernel</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sekernel</span><span class='hljl-p'>(</span><span class='hljl-n'>α</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>σ</span><span class='hljl-p'>)</span><span class='hljl-t'>

    </span><span class='hljl-n'>gp</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>GP</span><span class='hljl-p'>(</span><span class='hljl-n'>mu</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>kernel</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>cv</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>cov</span><span class='hljl-p'>(</span><span class='hljl-nf'>gp</span><span class='hljl-p'>(</span><span class='hljl-nf'>ColVecs</span><span class='hljl-p'>(</span><span class='hljl-n'>Z</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>noise</span><span class='hljl-p'>))</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>Y</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>filldist</span><span class='hljl-p'>(</span><span class='hljl-nf'>MvNormal</span><span class='hljl-p'>(</span><span class='hljl-n'>mu</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>cv</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>D</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-p'>;</span>
</pre>




<pre class='hljl'>
<span class='hljl-cs'># Standard GPs don&#39;t scale very well in n, so we use a small subsample for the purpose of this tutorial</span><span class='hljl-t'>
</span><span class='hljl-n'>n_data</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>40</span><span class='hljl-t'>
</span><span class='hljl-cs'># number of features to use from dataset</span><span class='hljl-t'>
</span><span class='hljl-n'>n_features</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>4</span><span class='hljl-t'>
</span><span class='hljl-cs'># latent dimension for GP case</span><span class='hljl-t'>
</span><span class='hljl-n'>ndim</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>4</span><span class='hljl-p'>;</span>
</pre>




<pre class='hljl'>
<span class='hljl-n'>ppca</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>pPCA</span><span class='hljl-p'>(</span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_data</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_features</span><span class='hljl-p'>])</span><span class='hljl-t'>
</span><span class='hljl-n'>chain_ppca</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sample</span><span class='hljl-p'>(</span><span class='hljl-n'>ppca</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>NUTS</span><span class='hljl-p'>(),</span><span class='hljl-t'> </span><span class='hljl-ni'>1000</span><span class='hljl-p'>);</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: dat not defined
</pre>



<pre class='hljl'>
<span class='hljl-cs'># we extract the posterior mean estimates of the parameters from the chain</span><span class='hljl-t'>
</span><span class='hljl-n'>w</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>reshape</span><span class='hljl-p'>(</span><span class='hljl-nf'>mean</span><span class='hljl-p'>(</span><span class='hljl-nf'>group</span><span class='hljl-p'>(</span><span class='hljl-n'>chain_ppca</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:w</span><span class='hljl-p'>))[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>n_features</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>n_features</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>z</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>reshape</span><span class='hljl-p'>(</span><span class='hljl-nf'>mean</span><span class='hljl-p'>(</span><span class='hljl-nf'>group</span><span class='hljl-p'>(</span><span class='hljl-n'>chain_ppca</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:z</span><span class='hljl-p'>))[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>n_features</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>n_data</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>X</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>w</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-n'>z</span><span class='hljl-t'>

</span><span class='hljl-n'>df_pre</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>DataFrame</span><span class='hljl-p'>(</span><span class='hljl-n'>z</span><span class='hljl-oB'>&#39;</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:auto</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nf'>rename!</span><span class='hljl-p'>(</span><span class='hljl-n'>df_pre</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Symbol</span><span class='hljl-oB'>.</span><span class='hljl-p'>([</span><span class='hljl-s'>&quot;z&quot;</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nf'>string</span><span class='hljl-p'>(</span><span class='hljl-n'>i</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_features</span><span class='hljl-p'>)]))</span><span class='hljl-t'>
</span><span class='hljl-n'>df_pre</span><span class='hljl-p'>[</span><span class='hljl-oB'>!</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:type</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>labels</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_data</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>p_ppca</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nd'>@vlplot</span><span class='hljl-p'>(</span><span class='hljl-sc'>:point</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-sc'>:z1</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-sc'>:z2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>color</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-s'>&quot;type:n&quot;</span><span class='hljl-p'>)(</span><span class='hljl-n'>df_pre</span><span class='hljl-p'>)</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: chain_ppca not defined
</pre>


<p>We can see that the pPCA fails to distinguish the groups. In particular, the <code>setosa</code> species is not clearly separated from <code>versicolor</code> and <code>virginica</code>. This is due to the non-linearities that we introduced, as without them the two groups can be clearly distinguished using pPCA &#40;see the pPCA tutorial&#41;.</p>
<p>Let&#39;s try the same with our linear kernel GPLVM model.</p>


<pre class='hljl'>
<span class='hljl-n'>gplvm_linear</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>GPLVM_linear</span><span class='hljl-p'>(</span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_data</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_features</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>ndim</span><span class='hljl-p'>)</span><span class='hljl-t'>

</span><span class='hljl-n'>chain_linear</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sample</span><span class='hljl-p'>(</span><span class='hljl-n'>gplvm_linear</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>NUTS</span><span class='hljl-p'>(),</span><span class='hljl-t'> </span><span class='hljl-ni'>500</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-cs'># we extract the posterior mean estimates of the parameters from the chain</span><span class='hljl-t'>
</span><span class='hljl-n'>z_mean</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>reshape</span><span class='hljl-p'>(</span><span class='hljl-nf'>mean</span><span class='hljl-p'>(</span><span class='hljl-nf'>group</span><span class='hljl-p'>(</span><span class='hljl-n'>chain_linear</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:Z</span><span class='hljl-p'>))[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>n_features</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>n_data</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>alpha_mean</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>mean</span><span class='hljl-p'>(</span><span class='hljl-nf'>group</span><span class='hljl-p'>(</span><span class='hljl-n'>chain_linear</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:α</span><span class='hljl-p'>))[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: dat not defined
</pre>



<pre class='hljl'>
<span class='hljl-n'>df_gplvm_linear</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>DataFrame</span><span class='hljl-p'>(</span><span class='hljl-n'>z_mean</span><span class='hljl-oB'>&#39;</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:auto</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nf'>rename!</span><span class='hljl-p'>(</span><span class='hljl-n'>df_gplvm_linear</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Symbol</span><span class='hljl-oB'>.</span><span class='hljl-p'>([</span><span class='hljl-s'>&quot;z&quot;</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nf'>string</span><span class='hljl-p'>(</span><span class='hljl-n'>i</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>ndim</span><span class='hljl-p'>)]))</span><span class='hljl-t'>
</span><span class='hljl-n'>df_gplvm_linear</span><span class='hljl-p'>[</span><span class='hljl-oB'>!</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:sample</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_data</span><span class='hljl-t'>
</span><span class='hljl-n'>df_gplvm_linear</span><span class='hljl-p'>[</span><span class='hljl-oB'>!</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:labels</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>labels</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_data</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>alpha_indices</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sortperm</span><span class='hljl-p'>(</span><span class='hljl-n'>alpha_mean</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>rev</span><span class='hljl-oB'>=</span><span class='hljl-kc'>true</span><span class='hljl-p'>)[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-nf'>println</span><span class='hljl-p'>(</span><span class='hljl-n'>alpha_indices</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>df_gplvm_linear</span><span class='hljl-p'>[</span><span class='hljl-oB'>!</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:ard1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>z_mean</span><span class='hljl-p'>[</span><span class='hljl-n'>alpha_indices</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-oB'>:</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>df_gplvm_linear</span><span class='hljl-p'>[</span><span class='hljl-oB'>!</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:ard2</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>z_mean</span><span class='hljl-p'>[</span><span class='hljl-n'>alpha_indices</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-oB'>:</span><span class='hljl-p'>]</span><span class='hljl-t'>

</span><span class='hljl-n'>p_linear</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nd'>@vlplot</span><span class='hljl-p'>(</span><span class='hljl-sc'>:point</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-sc'>:ard1</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-sc'>:ard2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>color</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-s'>&quot;labels:n&quot;</span><span class='hljl-p'>)(</span><span class='hljl-n'>df_gplvm_linear</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>p_linear</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: z_mean not defined
</pre>


<p>We can see that similar to the pPCA case, the linear kernel GPLVM fails to distinguish between the two groups &#40;<code>setosa</code> on the one hand, and <code>virginica</code> and <code>verticolor</code> on the other&#41;.</p>
<p>Finally, we demonstrate that by changing the kernel to a non-linear function, we are able to separate the data again.</p>


<pre class='hljl'>
<span class='hljl-n'>gplvm</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>GPLVM</span><span class='hljl-p'>(</span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_data</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_features</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>ndim</span><span class='hljl-p'>)</span><span class='hljl-t'>

</span><span class='hljl-n'>chain_gplvm</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sample</span><span class='hljl-p'>(</span><span class='hljl-n'>gplvm</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>NUTS</span><span class='hljl-p'>(),</span><span class='hljl-t'> </span><span class='hljl-ni'>500</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-cs'># we extract the posterior mean estimates of the parameters from the chain</span><span class='hljl-t'>
</span><span class='hljl-n'>z_mean</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>reshape</span><span class='hljl-p'>(</span><span class='hljl-nf'>mean</span><span class='hljl-p'>(</span><span class='hljl-nf'>group</span><span class='hljl-p'>(</span><span class='hljl-n'>chain_gplvm</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:Z</span><span class='hljl-p'>))[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>ndim</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>n_data</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>alpha_mean</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>mean</span><span class='hljl-p'>(</span><span class='hljl-nf'>group</span><span class='hljl-p'>(</span><span class='hljl-n'>chain_gplvm</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:α</span><span class='hljl-p'>))[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: dat not defined
</pre>



<pre class='hljl'>
<span class='hljl-n'>df_gplvm</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>DataFrame</span><span class='hljl-p'>(</span><span class='hljl-n'>z_mean</span><span class='hljl-oB'>&#39;</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:auto</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nf'>rename!</span><span class='hljl-p'>(</span><span class='hljl-n'>df_gplvm</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Symbol</span><span class='hljl-oB'>.</span><span class='hljl-p'>([</span><span class='hljl-s'>&quot;z&quot;</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nf'>string</span><span class='hljl-p'>(</span><span class='hljl-n'>i</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>ndim</span><span class='hljl-p'>)]))</span><span class='hljl-t'>
</span><span class='hljl-n'>df_gplvm</span><span class='hljl-p'>[</span><span class='hljl-oB'>!</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:sample</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_data</span><span class='hljl-t'>
</span><span class='hljl-n'>df_gplvm</span><span class='hljl-p'>[</span><span class='hljl-oB'>!</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:labels</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>labels</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_data</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>alpha_indices</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sortperm</span><span class='hljl-p'>(</span><span class='hljl-n'>alpha_mean</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>rev</span><span class='hljl-oB'>=</span><span class='hljl-kc'>true</span><span class='hljl-p'>)[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-nf'>println</span><span class='hljl-p'>(</span><span class='hljl-n'>alpha_indices</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>df_gplvm</span><span class='hljl-p'>[</span><span class='hljl-oB'>!</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:ard1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>z_mean</span><span class='hljl-p'>[</span><span class='hljl-n'>alpha_indices</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-oB'>:</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>df_gplvm</span><span class='hljl-p'>[</span><span class='hljl-oB'>!</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:ard2</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>z_mean</span><span class='hljl-p'>[</span><span class='hljl-n'>alpha_indices</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-oB'>:</span><span class='hljl-p'>]</span><span class='hljl-t'>

</span><span class='hljl-n'>p_gplvm</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nd'>@vlplot</span><span class='hljl-p'>(</span><span class='hljl-sc'>:point</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-sc'>:ard1</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-sc'>:ard2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>color</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-s'>&quot;labels:n&quot;</span><span class='hljl-p'>)(</span><span class='hljl-n'>df_gplvm</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>p_gplvm</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: z_mean not defined
</pre>


<pre class="julia-error">
ERROR: UndefVarError: alpha_indices not defined
</pre>


<p>Now, the split between the two groups is visible again.</p>
<h3>Speeding up inference</h3>
<p>Gaussian processes tend to be slow, as they naively require operations in the order of <span class="math">$O(n^3)$</span>. Here, we demonstrate a simple speedup using the Stheno library. Speeding up Gaussian process inference is an active area of research.</p>


<pre class='hljl'>
<span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>Stheno</span><span class='hljl-t'>
</span><span class='hljl-nd'>@model</span><span class='hljl-t'> </span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>GPLVM_sparse</span><span class='hljl-p'>(</span><span class='hljl-n'>Y</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>K</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>::</span><span class='hljl-nf'>Type</span><span class='hljl-p'>{</span><span class='hljl-n'>T</span><span class='hljl-p'>}</span><span class='hljl-oB'>=</span><span class='hljl-n'>Float64</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-n'>where</span><span class='hljl-t'> </span><span class='hljl-p'>{</span><span class='hljl-n'>T</span><span class='hljl-p'>}</span><span class='hljl-t'>

    </span><span class='hljl-cs'># Dimensionality of the problem.</span><span class='hljl-t'>
    </span><span class='hljl-n'>N</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>D</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>size</span><span class='hljl-p'>(</span><span class='hljl-n'>Y</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-cs'># dimension of latent space</span><span class='hljl-t'>
    </span><span class='hljl-nd'>@assert</span><span class='hljl-t'> </span><span class='hljl-n'>K</span><span class='hljl-t'> </span><span class='hljl-oB'>&lt;=</span><span class='hljl-t'> </span><span class='hljl-n'>D</span><span class='hljl-t'>
    </span><span class='hljl-cs'># number of inducing points</span><span class='hljl-t'>
    </span><span class='hljl-n'>n_inducing</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>25</span><span class='hljl-t'>
    </span><span class='hljl-n'>noise</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>1e-3</span><span class='hljl-t'>

    </span><span class='hljl-cs'># Priors</span><span class='hljl-t'>
    </span><span class='hljl-n'>α</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>MvLogNormal</span><span class='hljl-p'>(</span><span class='hljl-nf'>MvNormal</span><span class='hljl-p'>(</span><span class='hljl-nf'>zeros</span><span class='hljl-p'>(</span><span class='hljl-n'>K</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>I</span><span class='hljl-p'>))</span><span class='hljl-t'>
    </span><span class='hljl-n'>σ</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>LogNormal</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>Z</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>filldist</span><span class='hljl-p'>(</span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(),</span><span class='hljl-t'> </span><span class='hljl-n'>K</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>N</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>mu</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>filldist</span><span class='hljl-p'>(</span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(),</span><span class='hljl-t'> </span><span class='hljl-n'>N</span><span class='hljl-p'>)</span><span class='hljl-t'>

    </span><span class='hljl-n'>kernel</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>σ</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nf'>SqExponentialKernel</span><span class='hljl-p'>()</span><span class='hljl-t'> </span><span class='hljl-oB'>∘</span><span class='hljl-t'> </span><span class='hljl-nf'>ARDTransform</span><span class='hljl-p'>(</span><span class='hljl-n'>α</span><span class='hljl-p'>)</span><span class='hljl-t'>

    </span><span class='hljl-cs'>## Standard</span><span class='hljl-t'>
    </span><span class='hljl-cs'># gpc = GPC()</span><span class='hljl-t'>
    </span><span class='hljl-cs'># f = Stheno.wrap(GP(kernel), gpc)</span><span class='hljl-t'>
    </span><span class='hljl-cs'># gp = f(ColVecs(Z), noise)</span><span class='hljl-t'>
    </span><span class='hljl-cs'># Y ~ filldist(gp, D)</span><span class='hljl-t'>

    </span><span class='hljl-cs'>## SPARSE GP</span><span class='hljl-t'>
    </span><span class='hljl-cs'>#  xu = reshape(repeat(locations, K), :, K) # inducing points</span><span class='hljl-t'>
    </span><span class='hljl-cs'>#  xu = reshape(repeat(collect(range(-2.0, 2.0; length=20)), K), :, K) # inducing points</span><span class='hljl-t'>
    </span><span class='hljl-n'>lbound</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>minimum</span><span class='hljl-p'>(</span><span class='hljl-n'>Y</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-nfB'>1e-6</span><span class='hljl-t'>
    </span><span class='hljl-n'>ubound</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>maximum</span><span class='hljl-p'>(</span><span class='hljl-n'>Y</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-t'> </span><span class='hljl-nfB'>1e-6</span><span class='hljl-t'>
    </span><span class='hljl-cs'>#  locations ~ filldist(Uniform(lbound, ubound), n_inducing)</span><span class='hljl-t'>
    </span><span class='hljl-cs'>#  locations = [-2., -1.5 -1., -0.5, -0.25, 0.25, 0.5, 1., 2.]</span><span class='hljl-t'>
    </span><span class='hljl-cs'>#  locations = collect(LinRange(lbound, ubound, n_inducing))</span><span class='hljl-t'>
    </span><span class='hljl-n'>locations</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>quantile</span><span class='hljl-p'>(</span><span class='hljl-nf'>vec</span><span class='hljl-p'>(</span><span class='hljl-n'>Y</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-nf'>LinRange</span><span class='hljl-p'>(</span><span class='hljl-nfB'>0.01</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.99</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>n_inducing</span><span class='hljl-p'>))</span><span class='hljl-t'>
    </span><span class='hljl-n'>xu</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>reshape</span><span class='hljl-p'>(</span><span class='hljl-n'>locations</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>:</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>gp</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>Stheno</span><span class='hljl-oB'>.</span><span class='hljl-nf'>wrap</span><span class='hljl-p'>(</span><span class='hljl-nf'>GP</span><span class='hljl-p'>(</span><span class='hljl-n'>kernel</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-nf'>GPC</span><span class='hljl-p'>())</span><span class='hljl-t'>
    </span><span class='hljl-n'>fobs</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>gp</span><span class='hljl-p'>(</span><span class='hljl-nf'>ColVecs</span><span class='hljl-p'>(</span><span class='hljl-n'>Z</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>noise</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>finducing</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>gp</span><span class='hljl-p'>(</span><span class='hljl-n'>xu</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>1e-12</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>sfgp</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>SparseFiniteGP</span><span class='hljl-p'>(</span><span class='hljl-n'>fobs</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>finducing</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>cv</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>cov</span><span class='hljl-p'>(</span><span class='hljl-n'>sfgp</span><span class='hljl-oB'>.</span><span class='hljl-n'>fobs</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>Y</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>filldist</span><span class='hljl-p'>(</span><span class='hljl-nf'>MvNormal</span><span class='hljl-p'>(</span><span class='hljl-n'>mu</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>cv</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>D</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre>


<pre class="output">
GPLVM_sparse &#40;generic function with 3 methods&#41;
</pre>



<pre class='hljl'>
<span class='hljl-n'>n_data</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>50</span><span class='hljl-t'>
</span><span class='hljl-n'>gplvm_sparse</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>GPLVM_sparse</span><span class='hljl-p'>(</span><span class='hljl-n'>dat</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_data</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>:</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>ndim</span><span class='hljl-p'>)</span><span class='hljl-t'>

</span><span class='hljl-n'>chain_gplvm_sparse</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sample</span><span class='hljl-p'>(</span><span class='hljl-n'>gplvm_sparse</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>NUTS</span><span class='hljl-p'>(),</span><span class='hljl-t'> </span><span class='hljl-ni'>500</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-cs'># we extract the posterior mean estimates of the parameters from the chain</span><span class='hljl-t'>
</span><span class='hljl-n'>z_mean</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>reshape</span><span class='hljl-p'>(</span><span class='hljl-nf'>mean</span><span class='hljl-p'>(</span><span class='hljl-nf'>group</span><span class='hljl-p'>(</span><span class='hljl-n'>chain_gplvm_sparse</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:Z</span><span class='hljl-p'>))[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>ndim</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>n_data</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>alpha_mean</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>mean</span><span class='hljl-p'>(</span><span class='hljl-nf'>group</span><span class='hljl-p'>(</span><span class='hljl-n'>chain_gplvm_sparse</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:α</span><span class='hljl-p'>))[</span><span class='hljl-oB'>:</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: dat not defined
</pre>



<pre class='hljl'>
<span class='hljl-n'>df_gplvm_sparse</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>DataFrame</span><span class='hljl-p'>(</span><span class='hljl-n'>z_mean</span><span class='hljl-oB'>&#39;</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:auto</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nf'>rename!</span><span class='hljl-p'>(</span><span class='hljl-n'>df_gplvm_sparse</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Symbol</span><span class='hljl-oB'>.</span><span class='hljl-p'>([</span><span class='hljl-s'>&quot;z&quot;</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nf'>string</span><span class='hljl-p'>(</span><span class='hljl-n'>i</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>ndim</span><span class='hljl-p'>)]))</span><span class='hljl-t'>
</span><span class='hljl-n'>df_gplvm_sparse</span><span class='hljl-p'>[</span><span class='hljl-oB'>!</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:sample</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_data</span><span class='hljl-t'>
</span><span class='hljl-n'>df_gplvm_sparse</span><span class='hljl-p'>[</span><span class='hljl-oB'>!</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:labels</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>labels</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_data</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>alpha_indices</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sortperm</span><span class='hljl-p'>(</span><span class='hljl-n'>alpha_mean</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>rev</span><span class='hljl-oB'>=</span><span class='hljl-kc'>true</span><span class='hljl-p'>)[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>df_gplvm_sparse</span><span class='hljl-p'>[</span><span class='hljl-oB'>!</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:ard1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>z_mean</span><span class='hljl-p'>[</span><span class='hljl-n'>alpha_indices</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-oB'>:</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>df_gplvm_sparse</span><span class='hljl-p'>[</span><span class='hljl-oB'>!</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:ard2</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>z_mean</span><span class='hljl-p'>[</span><span class='hljl-n'>alpha_indices</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-oB'>:</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>p_sparse</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nd'>@vlplot</span><span class='hljl-p'>(</span><span class='hljl-sc'>:point</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-sc'>:ard1</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-sc'>:ard2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>color</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-s'>&quot;labels:n&quot;</span><span class='hljl-p'>)(</span><span class='hljl-n'>df_gplvm_sparse</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>p_sparse</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: z_mean not defined
</pre>


<p>Comparing the runtime, between the two versions, we can observe a clear speed-up with the sparse version.</p>

<pre class="julia-error">
ERROR: UndefVarError: alpha_indices not defined
</pre>



<div class="markdown"><h2>Appendix</h2>
<p>These tutorials are a part of the TuringTutorials repository, found at: <a href="https://github.com/TuringLang/TuringTutorials">https://github.com/TuringLang/TuringTutorials</a>.</p>
</div>
<div class="markdown"><p>To locally run this tutorial, do the following commands:</p>
<pre><code>using TuringTutorials
TuringTutorials.weave&#40;&quot;12-gaussian-process&quot;, &quot;12_gaussian-process.jmd&quot;&#41;</code></pre>
</div>
<div class="markdown"><p>Computer Information:</p>
</div>
<div class="markdown"><pre><code>Julia Version 1.6.5
Commit 9058264a69 &#40;2021-12-19 12:30 UTC&#41;
Platform Info:
  OS: Linux &#40;x86_64-pc-linux-gnu&#41;
  CPU: AMD EPYC 7502 32-Core Processor
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-11.0.1 &#40;ORCJIT, znver2&#41;
Environment:
  JULIA_CPU_THREADS &#61; 16
  BUILDKITE_PLUGIN_JULIA_CACHE_DIR &#61; /cache/julia-buildkite-plugin
  JULIA_DEPOT_PATH &#61; /cache/julia-buildkite-plugin/depots/7aa0085e-79a4-45f3-a5bd-9743c91cf3da
</code></pre>
</div>
<div class="markdown"><p>Package Information:</p>
</div>
<div class="markdown"><pre><code>      Status &#96;/cache/build/dockerized-amdci4-9/julialang/turingtutorials/tutorials/12-gaussian-process/Project.toml&#96;
  &#91;99985d1d&#93; AbstractGPs v0.3.9
  &#91;336ed68f&#93; CSV v0.8.5
  &#91;a93c6f00&#93; DataFrames v1.2.2
  &#91;31c24e10&#93; Distributions v0.25.14
  &#91;ec8451be&#93; KernelFunctions v0.10.13
  &#91;91a5bcdd&#93; Plots v1.21.3
  &#91;ce6b1742&#93; RDatasets v0.7.5
  &#91;2913bbd2&#93; StatsBase v0.33.10
  &#91;f3b207a7&#93; StatsPlots v0.14.27
  &#91;8188c328&#93; Stheno v0.7.12
  &#91;fce5fe82&#93; Turing v0.18.0
  &#91;112f6efa&#93; VegaLite v2.6.0
  &#91;44d3d7a6&#93; Weave v0.10.10
  &#91;37e2e46d&#93; LinearAlgebra
  &#91;9a3f8284&#93; Random</code></pre>
<p>And the full manifest:</p>
<pre><code>      Status &#96;/cache/build/dockerized-amdci4-9/julialang/turingtutorials/tutorials/12-gaussian-process/Manifest.toml&#96;
  &#91;621f4979&#93; AbstractFFTs v1.0.1
  &#91;99985d1d&#93; AbstractGPs v0.3.9
  &#91;80f14c24&#93; AbstractMCMC v3.2.1
  &#91;7a57a42e&#93; AbstractPPL v0.2.0
  &#91;1520ce14&#93; AbstractTrees v0.3.4
  &#91;79e6a3ab&#93; Adapt v3.3.1
  &#91;0bf59076&#93; AdvancedHMC v0.3.1
  &#91;5b7e9947&#93; AdvancedMH v0.6.5
  &#91;576499cb&#93; AdvancedPS v0.2.4
  &#91;b5ca4192&#93; AdvancedVI v0.1.3
  &#91;dce04be8&#93; ArgCheck v2.1.0
  &#91;7d9fca2a&#93; Arpack v0.4.0
  &#91;4fba245c&#93; ArrayInterface v3.1.32
  &#91;4c555306&#93; ArrayLayouts v0.7.4
  &#91;13072b0f&#93; AxisAlgorithms v1.0.0
  &#91;39de3d68&#93; AxisArrays v0.4.4
  &#91;198e06fe&#93; BangBang v0.3.31
  &#91;9718e550&#93; Baselet v0.1.1
  &#91;76274a88&#93; Bijectors v0.9.7
  &#91;62783981&#93; BitTwiddlingConvenienceFunctions v0.1.0
  &#91;8e7c35d0&#93; BlockArrays v0.16.5
  &#91;2a0fbf3d&#93; CPUSummary v0.1.3
  &#91;336ed68f&#93; CSV v0.8.5
  &#91;324d7699&#93; CategoricalArrays v0.10.0
  &#91;082447d4&#93; ChainRules v0.8.24
  &#91;d360d2e6&#93; ChainRulesCore v0.10.13
  &#91;fb6a15b2&#93; CloseOpenIntervals v0.1.2
  &#91;aaaa29a8&#93; Clustering v0.14.2
  &#91;944b1d66&#93; CodecZlib v0.7.0
  &#91;35d6a980&#93; ColorSchemes v3.14.0
  &#91;3da002f7&#93; ColorTypes v0.11.0
  &#91;5ae59095&#93; Colors v0.12.8
  &#91;861a8166&#93; Combinatorics v1.0.2
  &#91;38540f10&#93; CommonSolve v0.2.0
  &#91;bbf7d656&#93; CommonSubexpressions v0.3.0
  &#91;34da2185&#93; Compat v3.37.0
  &#91;a33af91c&#93; CompositionsBase v0.1.1
  &#91;88cd18e8&#93; ConsoleProgressMonitor v0.1.2
  &#91;187b0558&#93; ConstructionBase v1.3.0
  &#91;d38c429a&#93; Contour v0.5.7
  &#91;a8cc5b0e&#93; Crayons v4.0.4
  &#91;9a962f9c&#93; DataAPI v1.8.0
  &#91;a93c6f00&#93; DataFrames v1.2.2
  &#91;864edb3b&#93; DataStructures v0.18.10
  &#91;e2d170a0&#93; DataValueInterfaces v1.0.0
  &#91;e7dc6d0d&#93; DataValues v0.4.13
  &#91;244e2a9f&#93; DefineSingletons v0.1.1
  &#91;163ba53b&#93; DiffResults v1.0.3
  &#91;b552c78f&#93; DiffRules v1.3.0
  &#91;b4f34e82&#93; Distances v0.10.4
  &#91;31c24e10&#93; Distributions v0.25.14
  &#91;ced4e74d&#93; DistributionsAD v0.6.29
  &#91;ffbed154&#93; DocStringExtensions v0.8.5
  &#91;366bfd00&#93; DynamicPPL v0.15.1
  &#91;da5c29d0&#93; EllipsisNotation v1.1.0
  &#91;cad2338a&#93; EllipticalSliceSampling v0.4.4
  &#91;e2ba6199&#93; ExprTools v0.1.6
  &#91;c87230d0&#93; FFMPEG v0.4.1
  &#91;7a1cc6ca&#93; FFTW v1.4.4
  &#91;5789e2e9&#93; FileIO v1.11.1
  &#91;8fc22ac5&#93; FilePaths v0.8.3
  &#91;48062228&#93; FilePathsBase v0.9.10
  &#91;1a297f60&#93; FillArrays v0.11.9
  &#91;6a86dc24&#93; FiniteDiff v2.8.1
  &#91;53c48c17&#93; FixedPointNumbers v0.8.4
  &#91;59287772&#93; Formatting v0.4.2
  &#91;f6369f11&#93; ForwardDiff v0.10.19
  &#91;d9f16b24&#93; Functors v0.2.5
  &#91;28b8d3ca&#93; GR v0.58.1
  &#91;5c1252a2&#93; GeometryBasics v0.4.1
  &#91;42e2da0e&#93; Grisu v1.0.2
  &#91;cd3eb016&#93; HTTP v0.9.14
  &#91;eafb193a&#93; Highlights v0.4.5
  &#91;3e5b6fbb&#93; HostCPUFeatures v0.1.3
  &#91;0e44f5e4&#93; Hwloc v2.0.0
  &#91;7869d1d1&#93; IRTools v0.4.3
  &#91;615f187c&#93; IfElse v0.1.0
  &#91;83e8ac13&#93; IniFile v0.5.0
  &#91;22cec73e&#93; InitialValues v0.2.10
  &#91;505f98c9&#93; InplaceOps v0.3.0
  &#91;a98d9a8b&#93; Interpolations v0.13.4
  &#91;8197267c&#93; IntervalSets v0.5.3
  &#91;41ab1584&#93; InvertedIndices v1.1.0
  &#91;92d709cd&#93; IrrationalConstants v0.1.0
  &#91;c8e1da08&#93; IterTools v1.3.0
  &#91;42fd0dbc&#93; IterativeSolvers v0.9.1
  &#91;82899510&#93; IteratorInterfaceExtensions v1.0.0
  &#91;692b3bcd&#93; JLLWrappers v1.3.0
  &#91;682c06a0&#93; JSON v0.21.2
  &#91;7d188eb4&#93; JSONSchema v0.3.4
  &#91;5ab0869b&#93; KernelDensity v0.6.3
  &#91;ec8451be&#93; KernelFunctions v0.10.13
  &#91;b964fa9f&#93; LaTeXStrings v1.2.1
  &#91;23fbe1c1&#93; Latexify v0.15.6
  &#91;10f19ff3&#93; LayoutPointers v0.1.3
  &#91;1d6d02ad&#93; LeftChildRightSiblingTrees v0.1.2
  &#91;6f1fad26&#93; Libtask v0.5.3
  &#91;2ab3a3ac&#93; LogExpFunctions v0.3.0
  &#91;e6f89c97&#93; LoggingExtras v0.4.7
  &#91;bdcacae8&#93; LoopVectorization v0.12.73
  &#91;c7f686f2&#93; MCMCChains v5.0.1
  &#91;be115224&#93; MCMCDiagnosticTools v0.1.0
  &#91;e80e1ace&#93; MLJModelInterface v1.3.0
  &#91;1914dd2f&#93; MacroTools v0.5.8
  &#91;d125e4d3&#93; ManualMemory v0.1.6
  &#91;dbb5928d&#93; MappedArrays v0.4.1
  &#91;739be429&#93; MbedTLS v1.0.3
  &#91;442fdcdd&#93; Measures v0.3.1
  &#91;128add7d&#93; MicroCollections v0.1.0
  &#91;e1d29d7a&#93; Missings v1.0.1
  &#91;78c3b35d&#93; Mocking v0.7.2
  &#91;6f286f6a&#93; MultivariateStats v0.8.0
  &#91;ffc61752&#93; Mustache v1.0.10
  &#91;872c559c&#93; NNlib v0.7.29
  &#91;77ba4419&#93; NaNMath v0.3.5
  &#91;86f7a689&#93; NamedArrays v0.9.6
  &#91;c020b1a1&#93; NaturalSort v1.0.0
  &#91;b8a86587&#93; NearestNeighbors v0.4.9
  &#91;2bd173c7&#93; NodeJS v1.3.0
  &#91;8913a72c&#93; NonlinearSolve v0.3.10
  &#91;510215fc&#93; Observables v0.4.0
  &#91;6fe1bfb0&#93; OffsetArrays v1.10.6
  &#91;bac558e1&#93; OrderedCollections v1.4.1
  &#91;90014a1f&#93; PDMats v0.11.1
  &#91;69de0a69&#93; Parsers v1.1.2
  &#91;ccf2f8ad&#93; PlotThemes v2.0.1
  &#91;995b91a9&#93; PlotUtils v1.0.13
  &#91;91a5bcdd&#93; Plots v1.21.3
  &#91;f517fe37&#93; Polyester v0.4.4
  &#91;1d0040c9&#93; PolyesterWeave v0.1.0
  &#91;2dfb63ee&#93; PooledArrays v1.3.0
  &#91;21216c6a&#93; Preferences v1.2.2
  &#91;08abe8d2&#93; PrettyTables v1.1.0
  &#91;33c8b6b6&#93; ProgressLogging v0.1.4
  &#91;92933f4c&#93; ProgressMeter v1.7.1
  &#91;1fd47b50&#93; QuadGK v2.4.1
  &#91;df47a6cb&#93; RData v0.8.3
  &#91;ce6b1742&#93; RDatasets v0.7.5
  &#91;b3c3ace0&#93; RangeArrays v0.3.2
  &#91;c84ed2f1&#93; Ratios v0.4.1
  &#91;3cdcf5f2&#93; RecipesBase v1.1.2
  &#91;01d81517&#93; RecipesPipeline v0.4.0
  &#91;731186ca&#93; RecursiveArrayTools v2.17.2
  &#91;f2c3362d&#93; RecursiveFactorization v0.2.3
  &#91;189a3867&#93; Reexport v1.2.2
  &#91;05181044&#93; RelocatableFolders v0.1.0
  &#91;ae029012&#93; Requires v1.1.3
  &#91;79098fc4&#93; Rmath v0.7.0
  &#91;94e857df&#93; SIMDTypes v0.1.0
  &#91;476501e8&#93; SLEEFPirates v0.6.26
  &#91;0bca4576&#93; SciMLBase v1.18.7
  &#91;30f210dd&#93; ScientificTypesBase v2.2.0
  &#91;6c6a2e73&#93; Scratch v1.1.0
  &#91;91c51154&#93; SentinelArrays v1.3.7
  &#91;efcf1570&#93; Setfield v0.7.1
  &#91;992d4aef&#93; Showoff v1.0.3
  &#91;a2af1166&#93; SortingAlgorithms v1.0.1
  &#91;276daf66&#93; SpecialFunctions v1.6.1
  &#91;171d559e&#93; SplittablesBase v0.1.13
  &#91;aedffcd0&#93; Static v0.3.3
  &#91;90137ffa&#93; StaticArrays v1.2.12
  &#91;64bff920&#93; StatisticalTraits v2.1.0
  &#91;82ae8749&#93; StatsAPI v1.0.0
  &#91;2913bbd2&#93; StatsBase v0.33.10
  &#91;4c63d2b9&#93; StatsFuns v0.9.9
  &#91;f3b207a7&#93; StatsPlots v0.14.27
  &#91;8188c328&#93; Stheno v0.7.12
  &#91;7792a7ef&#93; StrideArraysCore v0.2.4
  &#91;69024149&#93; StringEncodings v0.3.5
  &#91;09ab397b&#93; StructArrays v0.6.2
  &#91;856f2bd8&#93; StructTypes v1.7.3
  &#91;ab02a1b2&#93; TableOperations v1.1.0
  &#91;3783bdb8&#93; TableTraits v1.0.1
  &#91;382cd787&#93; TableTraitsUtils v1.0.2
  &#91;bd369af6&#93; Tables v1.5.1
  &#91;62fd8b95&#93; TensorCore v0.1.1
  &#91;5d786b92&#93; TerminalLoggers v0.1.4
  &#91;8290d209&#93; ThreadingUtilities v0.4.6
  &#91;f269a46b&#93; TimeZones v1.5.7
  &#91;9f7883ad&#93; Tracker v0.2.16
  &#91;3bb67fe8&#93; TranscodingStreams v0.9.6
  &#91;28d57a85&#93; Transducers v0.4.65
  &#91;a2a6695c&#93; TreeViews v0.3.0
  &#91;d5829a12&#93; TriangularSolve v0.1.5
  &#91;fce5fe82&#93; Turing v0.18.0
  &#91;30578b45&#93; URIParser v0.4.1
  &#91;5c2747f8&#93; URIs v1.3.0
  &#91;3a884ed6&#93; UnPack v1.0.2
  &#91;3d5dd08c&#93; VectorizationBase v0.21.6
  &#91;239c3e63&#93; Vega v2.3.0
  &#91;112f6efa&#93; VegaLite v2.6.0
  &#91;44d3d7a6&#93; Weave v0.10.10
  &#91;cc8bc4a8&#93; Widgets v0.6.3
  &#91;efce3f68&#93; WoodburyMatrices v0.5.3
  &#91;ddb6d928&#93; YAML v0.4.7
  &#91;e88e6eb3&#93; Zygote v0.6.17
  &#91;700de1a5&#93; ZygoteRules v0.2.1
  &#91;68821587&#93; Arpack_jll v3.5.0&#43;3
  &#91;6e34b625&#93; Bzip2_jll v1.0.8&#43;0
  &#91;83423d85&#93; Cairo_jll v1.16.1&#43;0
  &#91;5ae413db&#93; EarCut_jll v2.2.3&#43;0
  &#91;2e619515&#93; Expat_jll v2.2.10&#43;0
  &#91;b22a6f82&#93; FFMPEG_jll v4.4.0&#43;0
  &#91;f5851436&#93; FFTW_jll v3.3.9&#43;8
  &#91;a3f928ae&#93; Fontconfig_jll v2.13.93&#43;0
  &#91;d7e528f0&#93; FreeType2_jll v2.10.4&#43;0
  &#91;559328eb&#93; FriBidi_jll v1.0.10&#43;0
  &#91;0656b61e&#93; GLFW_jll v3.3.5&#43;0
  &#91;d2c73de3&#93; GR_jll v0.59.0&#43;0
  &#91;78b55507&#93; Gettext_jll v0.21.0&#43;0
  &#91;7746bdde&#93; Glib_jll v2.68.3&#43;0
  &#91;3b182d85&#93; Graphite2_jll v1.3.14&#43;0
  &#91;2e76f6c2&#93; HarfBuzz_jll v2.8.1&#43;0
  &#91;e33a78d0&#93; Hwloc_jll v2.5.0&#43;0
  &#91;1d5cc7b8&#93; IntelOpenMP_jll v2018.0.3&#43;2
  &#91;aacddb02&#93; JpegTurbo_jll v2.1.0&#43;0
  &#91;c1c5ebd0&#93; LAME_jll v3.100.1&#43;0
  &#91;dd4b983a&#93; LZO_jll v2.10.1&#43;0
  &#91;e9f186c6&#93; Libffi_jll v3.2.2&#43;0
  &#91;d4300ac3&#93; Libgcrypt_jll v1.8.7&#43;0
  &#91;7e76a0d4&#93; Libglvnd_jll v1.3.0&#43;3
  &#91;7add5ba3&#93; Libgpg_error_jll v1.42.0&#43;0
  &#91;94ce4f54&#93; Libiconv_jll v1.16.1&#43;1
  &#91;4b2f31a3&#93; Libmount_jll v2.35.0&#43;0
  &#91;3ae2931a&#93; Libtask_jll v0.4.3&#43;0
  &#91;89763e89&#93; Libtiff_jll v4.3.0&#43;0
  &#91;38a345b3&#93; Libuuid_jll v2.36.0&#43;0
  &#91;856f044c&#93; MKL_jll v2021.1.1&#43;1
  &#91;e7412a2a&#93; Ogg_jll v1.3.5&#43;0
  &#91;458c3c95&#93; OpenSSL_jll v1.1.10&#43;0
  &#91;efe28fd5&#93; OpenSpecFun_jll v0.5.5&#43;0
  &#91;91d4177d&#93; Opus_jll v1.3.2&#43;0
  &#91;2f80f16e&#93; PCRE_jll v8.44.0&#43;0
  &#91;30392449&#93; Pixman_jll v0.40.1&#43;0
  &#91;ea2cea3b&#93; Qt5Base_jll v5.15.3&#43;0
  &#91;f50d1b31&#93; Rmath_jll v0.3.0&#43;0
  &#91;a2964d1f&#93; Wayland_jll v1.19.0&#43;0
  &#91;2381bf8a&#93; Wayland_protocols_jll v1.18.0&#43;4
  &#91;02c8fc9c&#93; XML2_jll v2.9.12&#43;0
  &#91;aed1982a&#93; XSLT_jll v1.1.34&#43;0
  &#91;4f6342f7&#93; Xorg_libX11_jll v1.6.9&#43;4
  &#91;0c0b7dd1&#93; Xorg_libXau_jll v1.0.9&#43;4
  &#91;935fb764&#93; Xorg_libXcursor_jll v1.2.0&#43;4
  &#91;a3789734&#93; Xorg_libXdmcp_jll v1.1.3&#43;4
  &#91;1082639a&#93; Xorg_libXext_jll v1.3.4&#43;4
  &#91;d091e8ba&#93; Xorg_libXfixes_jll v5.0.3&#43;4
  &#91;a51aa0fd&#93; Xorg_libXi_jll v1.7.10&#43;4
  &#91;d1454406&#93; Xorg_libXinerama_jll v1.1.4&#43;4
  &#91;ec84b674&#93; Xorg_libXrandr_jll v1.5.2&#43;4
  &#91;ea2f1a96&#93; Xorg_libXrender_jll v0.9.10&#43;4
  &#91;14d82f49&#93; Xorg_libpthread_stubs_jll v0.1.0&#43;3
  &#91;c7cfdc94&#93; Xorg_libxcb_jll v1.13.0&#43;3
  &#91;cc61e674&#93; Xorg_libxkbfile_jll v1.1.0&#43;4
  &#91;12413925&#93; Xorg_xcb_util_image_jll v0.4.0&#43;1
  &#91;2def613f&#93; Xorg_xcb_util_jll v0.4.0&#43;1
  &#91;975044d2&#93; Xorg_xcb_util_keysyms_jll v0.4.0&#43;1
  &#91;0d47668e&#93; Xorg_xcb_util_renderutil_jll v0.3.9&#43;1
  &#91;c22f9ab0&#93; Xorg_xcb_util_wm_jll v0.4.1&#43;1
  &#91;35661453&#93; Xorg_xkbcomp_jll v1.4.2&#43;4
  &#91;33bec58e&#93; Xorg_xkeyboard_config_jll v2.27.0&#43;4
  &#91;c5fb5394&#93; Xorg_xtrans_jll v1.4.0&#43;3
  &#91;3161d3a3&#93; Zstd_jll v1.5.0&#43;0
  &#91;0ac62f75&#93; libass_jll v0.15.1&#43;0
  &#91;f638f0a6&#93; libfdk_aac_jll v2.0.2&#43;0
  &#91;b53b4c65&#93; libpng_jll v1.6.38&#43;0
  &#91;f27f6e37&#93; libvorbis_jll v1.3.7&#43;0
  &#91;1270edf5&#93; x264_jll v2021.5.5&#43;0
  &#91;dfaa095f&#93; x265_jll v3.5.0&#43;0
  &#91;d8fb68d0&#93; xkbcommon_jll v0.9.1&#43;5
  &#91;0dad84c5&#93; ArgTools
  &#91;56f22d72&#93; Artifacts
  &#91;2a0f44e3&#93; Base64
  &#91;ade2ca70&#93; Dates
  &#91;8bb1440f&#93; DelimitedFiles
  &#91;8ba89e20&#93; Distributed
  &#91;f43a241f&#93; Downloads
  &#91;9fa8497b&#93; Future
  &#91;b77e0a4c&#93; InteractiveUtils
  &#91;4af54fe1&#93; LazyArtifacts
  &#91;b27032c2&#93; LibCURL
  &#91;76f85450&#93; LibGit2
  &#91;8f399da3&#93; Libdl
  &#91;37e2e46d&#93; LinearAlgebra
  &#91;56ddb016&#93; Logging
  &#91;d6f4376e&#93; Markdown
  &#91;a63ad114&#93; Mmap
  &#91;ca575930&#93; NetworkOptions
  &#91;44cfe95a&#93; Pkg
  &#91;de0858da&#93; Printf
  &#91;3fa0cd96&#93; REPL
  &#91;9a3f8284&#93; Random
  &#91;ea8e919c&#93; SHA
  &#91;9e88b42a&#93; Serialization
  &#91;1a1011a3&#93; SharedArrays
  &#91;6462fe0b&#93; Sockets
  &#91;2f01184e&#93; SparseArrays
  &#91;10745b16&#93; Statistics
  &#91;4607b0f0&#93; SuiteSparse
  &#91;fa267f1f&#93; TOML
  &#91;a4e569a6&#93; Tar
  &#91;8dfed614&#93; Test
  &#91;cf7118a7&#93; UUIDs
  &#91;4ec0a83e&#93; Unicode
  &#91;e66e0078&#93; CompilerSupportLibraries_jll
  &#91;deac9b47&#93; LibCURL_jll
  &#91;29816b5a&#93; LibSSH2_jll
  &#91;c8ffd9c3&#93; MbedTLS_jll
  &#91;14a3606d&#93; MozillaCACerts_jll
  &#91;4536629a&#93; OpenBLAS_jll
  &#91;83775a58&#93; Zlib_jll
  &#91;8e850ede&#93; nghttp2_jll
  &#91;3f19e933&#93; p7zip_jll</code></pre>
</div>


        <HR/>
        <div class="footer">
          <p>
            Published from <a href="12_gaussian-process.jmd">12_gaussian-process.jmd</a>
            using <a href="http://github.com/JunoLab/Weave.jl">Weave.jl</a> v0.10.10 on 2022-03-03.
          </p>
        </div>
      </div>
    </div>
  </div>
</BODY>

</HTML>
