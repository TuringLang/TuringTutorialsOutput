<!DOCTYPE html>
<HTML lang = "en">
<HEAD>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Using External Sampler</title>
  

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      TeX: { equationNumbers: { autoNumber: "AMS" } }
    });
  </script>

  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>

  
<style>
pre.hljl {
    border: 1px solid #ccc;
    margin: 5px;
    padding: 5px;
    overflow-x: auto;
    color: rgb(68,68,68); background-color: rgb(251,251,251); }
pre.hljl > span.hljl-t { }
pre.hljl > span.hljl-w { }
pre.hljl > span.hljl-e { }
pre.hljl > span.hljl-eB { }
pre.hljl > span.hljl-o { }
pre.hljl > span.hljl-k { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kc { color: rgb(59,151,46); font-style: italic; }
pre.hljl > span.hljl-kd { color: rgb(214,102,97); font-style: italic; }
pre.hljl > span.hljl-kn { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kp { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kr { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kt { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-n { }
pre.hljl > span.hljl-na { }
pre.hljl > span.hljl-nb { }
pre.hljl > span.hljl-nbp { }
pre.hljl > span.hljl-nc { }
pre.hljl > span.hljl-ncB { }
pre.hljl > span.hljl-nd { color: rgb(214,102,97); }
pre.hljl > span.hljl-ne { }
pre.hljl > span.hljl-neB { }
pre.hljl > span.hljl-nf { color: rgb(66,102,213); }
pre.hljl > span.hljl-nfm { color: rgb(66,102,213); }
pre.hljl > span.hljl-np { }
pre.hljl > span.hljl-nl { }
pre.hljl > span.hljl-nn { }
pre.hljl > span.hljl-no { }
pre.hljl > span.hljl-nt { }
pre.hljl > span.hljl-nv { }
pre.hljl > span.hljl-nvc { }
pre.hljl > span.hljl-nvg { }
pre.hljl > span.hljl-nvi { }
pre.hljl > span.hljl-nvm { }
pre.hljl > span.hljl-l { }
pre.hljl > span.hljl-ld { color: rgb(148,91,176); font-style: italic; }
pre.hljl > span.hljl-s { color: rgb(201,61,57); }
pre.hljl > span.hljl-sa { color: rgb(201,61,57); }
pre.hljl > span.hljl-sb { color: rgb(201,61,57); }
pre.hljl > span.hljl-sc { color: rgb(201,61,57); }
pre.hljl > span.hljl-sd { color: rgb(201,61,57); }
pre.hljl > span.hljl-sdB { color: rgb(201,61,57); }
pre.hljl > span.hljl-sdC { color: rgb(201,61,57); }
pre.hljl > span.hljl-se { color: rgb(59,151,46); }
pre.hljl > span.hljl-sh { color: rgb(201,61,57); }
pre.hljl > span.hljl-si { }
pre.hljl > span.hljl-so { color: rgb(201,61,57); }
pre.hljl > span.hljl-sr { color: rgb(201,61,57); }
pre.hljl > span.hljl-ss { color: rgb(201,61,57); }
pre.hljl > span.hljl-ssB { color: rgb(201,61,57); }
pre.hljl > span.hljl-nB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nbB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nfB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nh { color: rgb(59,151,46); }
pre.hljl > span.hljl-ni { color: rgb(59,151,46); }
pre.hljl > span.hljl-nil { color: rgb(59,151,46); }
pre.hljl > span.hljl-noB { color: rgb(59,151,46); }
pre.hljl > span.hljl-oB { color: rgb(102,102,102); font-weight: bold; }
pre.hljl > span.hljl-ow { color: rgb(102,102,102); font-weight: bold; }
pre.hljl > span.hljl-p { }
pre.hljl > span.hljl-c { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-ch { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cm { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cp { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cpB { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cs { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-csB { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-g { }
pre.hljl > span.hljl-gd { }
pre.hljl > span.hljl-ge { }
pre.hljl > span.hljl-geB { }
pre.hljl > span.hljl-gh { }
pre.hljl > span.hljl-gi { }
pre.hljl > span.hljl-go { }
pre.hljl > span.hljl-gp { }
pre.hljl > span.hljl-gs { }
pre.hljl > span.hljl-gsB { }
pre.hljl > span.hljl-gt { }
</style>



  <style type="text/css">
  @font-face {
  font-style: normal;
  font-weight: 300;
}
@font-face {
  font-style: normal;
  font-weight: 400;
}
@font-face {
  font-style: normal;
  font-weight: 600;
}
html {
  font-family: sans-serif; /* 1 */
  -ms-text-size-adjust: 100%; /* 2 */
  -webkit-text-size-adjust: 100%; /* 2 */
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block; /* 1 */
  vertical-align: baseline; /* 2 */
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 70%;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit; /* 1 */
  font: inherit; /* 2 */
  margin: 0; /* 3 */
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button; /* 2 */
  cursor: pointer; /* 3 */
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box; /* 1 */
  padding: 0; /* 2 */
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield; /* 1 */
  -moz-box-sizing: content-box;
  -webkit-box-sizing: content-box; /* 2 */
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0; /* 1 */
  padding: 0; /* 2 */
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  font-family: monospace, monospace;
  font-size : 0.8em;
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
thead th {
    border-bottom: 1px solid black;
    background-color: white;
}
tr:nth-child(odd){
  background-color: rgb(248,248,248);
}


/*
* Skeleton V2.0.4
* Copyright 2014, Dave Gamache
* www.getskeleton.com
* Free to use under the MIT license.
* http://www.opensource.org/licenses/mit-license.php
* 12/29/2014
*/
.container {
  position: relative;
  width: 100%;
  max-width: 960px;
  margin: 0 auto;
  padding: 0 20px;
  box-sizing: border-box; }
.column,
.columns {
  width: 100%;
  float: left;
  box-sizing: border-box; }
@media (min-width: 400px) {
  .container {
    width: 85%;
    padding: 0; }
}
@media (min-width: 550px) {
  .container {
    width: 80%; }
  .column,
  .columns {
    margin-left: 4%; }
  .column:first-child,
  .columns:first-child {
    margin-left: 0; }

  .one.column,
  .one.columns                    { width: 4.66666666667%; }
  .two.columns                    { width: 13.3333333333%; }
  .three.columns                  { width: 22%;            }
  .four.columns                   { width: 30.6666666667%; }
  .five.columns                   { width: 39.3333333333%; }
  .six.columns                    { width: 48%;            }
  .seven.columns                  { width: 56.6666666667%; }
  .eight.columns                  { width: 65.3333333333%; }
  .nine.columns                   { width: 74.0%;          }
  .ten.columns                    { width: 82.6666666667%; }
  .eleven.columns                 { width: 91.3333333333%; }
  .twelve.columns                 { width: 100%; margin-left: 0; }

  .one-third.column               { width: 30.6666666667%; }
  .two-thirds.column              { width: 65.3333333333%; }

  .one-half.column                { width: 48%; }

  /* Offsets */
  .offset-by-one.column,
  .offset-by-one.columns          { margin-left: 8.66666666667%; }
  .offset-by-two.column,
  .offset-by-two.columns          { margin-left: 17.3333333333%; }
  .offset-by-three.column,
  .offset-by-three.columns        { margin-left: 26%;            }
  .offset-by-four.column,
  .offset-by-four.columns         { margin-left: 34.6666666667%; }
  .offset-by-five.column,
  .offset-by-five.columns         { margin-left: 43.3333333333%; }
  .offset-by-six.column,
  .offset-by-six.columns          { margin-left: 52%;            }
  .offset-by-seven.column,
  .offset-by-seven.columns        { margin-left: 60.6666666667%; }
  .offset-by-eight.column,
  .offset-by-eight.columns        { margin-left: 69.3333333333%; }
  .offset-by-nine.column,
  .offset-by-nine.columns         { margin-left: 78.0%;          }
  .offset-by-ten.column,
  .offset-by-ten.columns          { margin-left: 86.6666666667%; }
  .offset-by-eleven.column,
  .offset-by-eleven.columns       { margin-left: 95.3333333333%; }

  .offset-by-one-third.column,
  .offset-by-one-third.columns    { margin-left: 34.6666666667%; }
  .offset-by-two-thirds.column,
  .offset-by-two-thirds.columns   { margin-left: 69.3333333333%; }

  .offset-by-one-half.column,
  .offset-by-one-half.columns     { margin-left: 52%; }

}
html {
  font-size: 62.5%; }
body {
  font-size: 1.5em; /* currently ems cause chrome bug misinterpreting rems on body element */
  line-height: 1.6;
  font-weight: 400;
  font-family: "Raleway", "HelveticaNeue", "Helvetica Neue", Helvetica, Arial, sans-serif;
  color: #222; }
h1, h2, h3, h4, h5, h6 {
  margin-top: 0;
  margin-bottom: 2rem;
  font-weight: 300; }
h1 { font-size: 3.6rem; line-height: 1.2;  letter-spacing: -.1rem;}
h2 { font-size: 3.4rem; line-height: 1.25; letter-spacing: -.1rem; }
h3 { font-size: 3.2rem; line-height: 1.3;  letter-spacing: -.1rem; }
h4 { font-size: 2.8rem; line-height: 1.35; letter-spacing: -.08rem; }
h5 { font-size: 2.4rem; line-height: 1.5;  letter-spacing: -.05rem; }
h6 { font-size: 1.5rem; line-height: 1.6;  letter-spacing: 0; }

p {
  margin-top: 0; }
a {
  color: #1EAEDB; }
a:hover {
  color: #0FA0CE; }
.button,
button,
input[type="submit"],
input[type="reset"],
input[type="button"] {
  display: inline-block;
  height: 38px;
  padding: 0 30px;
  color: #555;
  text-align: center;
  font-size: 11px;
  font-weight: 600;
  line-height: 38px;
  letter-spacing: .1rem;
  text-transform: uppercase;
  text-decoration: none;
  white-space: nowrap;
  background-color: transparent;
  border-radius: 4px;
  border: 1px solid #bbb;
  cursor: pointer;
  box-sizing: border-box; }
.button:hover,
button:hover,
input[type="submit"]:hover,
input[type="reset"]:hover,
input[type="button"]:hover,
.button:focus,
button:focus,
input[type="submit"]:focus,
input[type="reset"]:focus,
input[type="button"]:focus {
  color: #333;
  border-color: #888;
  outline: 0; }
.button.button-primary,
button.button-primary,
input[type="submit"].button-primary,
input[type="reset"].button-primary,
input[type="button"].button-primary {
  color: #FFF;
  background-color: #33C3F0;
  border-color: #33C3F0; }
.button.button-primary:hover,
button.button-primary:hover,
input[type="submit"].button-primary:hover,
input[type="reset"].button-primary:hover,
input[type="button"].button-primary:hover,
.button.button-primary:focus,
button.button-primary:focus,
input[type="submit"].button-primary:focus,
input[type="reset"].button-primary:focus,
input[type="button"].button-primary:focus {
  color: #FFF;
  background-color: #1EAEDB;
  border-color: #1EAEDB; }
input[type="email"],
input[type="number"],
input[type="search"],
input[type="text"],
input[type="tel"],
input[type="url"],
input[type="password"],
textarea,
select {
  height: 38px;
  padding: 6px 10px; /* The 6px vertically centers text on FF, ignored by Webkit */
  background-color: #fff;
  border: 1px solid #D1D1D1;
  border-radius: 4px;
  box-shadow: none;
  box-sizing: border-box; }
/* Removes awkward default styles on some inputs for iOS */
input[type="email"],
input[type="number"],
input[type="search"],
input[type="text"],
input[type="tel"],
input[type="url"],
input[type="password"],
textarea {
  -webkit-appearance: none;
     -moz-appearance: none;
          appearance: none; }
textarea {
  min-height: 65px;
  padding-top: 6px;
  padding-bottom: 6px; }
input[type="email"]:focus,
input[type="number"]:focus,
input[type="search"]:focus,
input[type="text"]:focus,
input[type="tel"]:focus,
input[type="url"]:focus,
input[type="password"]:focus,
textarea:focus,
select:focus {
  border: 1px solid #33C3F0;
  outline: 0; }
label,
legend {
  display: block;
  margin-bottom: .5rem;
  font-weight: 600; }
fieldset {
  padding: 0;
  border-width: 0; }
input[type="checkbox"],
input[type="radio"] {
  display: inline; }
label > .label-body {
  display: inline-block;
  margin-left: .5rem;
  font-weight: normal; }
ul {
  list-style: circle; }
ol {
  list-style: decimal; }
ul ul,
ul ol,
ol ol,
ol ul {
  margin: 1.5rem 0 1.5rem 3rem;
  font-size: 90%; }
li > p {margin : 0;}
th,
td {
  padding: 12px 15px;
  text-align: left;
  border-bottom: 1px solid #E1E1E1; }
th:first-child,
td:first-child {
  padding-left: 0; }
th:last-child,
td:last-child {
  padding-right: 0; }
button,
.button {
  margin-bottom: 1rem; }
input,
textarea,
select,
fieldset {
  margin-bottom: 1.5rem; }
pre,
blockquote,
dl,
figure,
table,
p,
ul,
ol,
form {
  margin-bottom: 1.0rem; }
.u-full-width {
  width: 100%;
  box-sizing: border-box; }
.u-max-full-width {
  max-width: 100%;
  box-sizing: border-box; }
.u-pull-right {
  float: right; }
.u-pull-left {
  float: left; }
hr {
  margin-top: 3rem;
  margin-bottom: 3.5rem;
  border-width: 0;
  border-top: 1px solid #E1E1E1; }
.container:after,
.row:after,
.u-cf {
  content: "";
  display: table;
  clear: both; }

pre {
  display: block;
  padding: 9.5px;
  margin: 0 0 10px;
  font-size: 13px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre.hljl {
  margin: 0 0 10px;
  display: block;
  background: #f5f5f5;
  border-radius: 4px;
  padding : 5px;
}

pre.output {
  background: #ffffff;
}

pre.code {
  background: #ffffff;
}

pre.julia-error {
  color : red
}

code,
kbd,
pre,
samp {
  font-family: Menlo, Monaco, Consolas, "Courier New", monospace;
  font-size: 13px;
}


@media (min-width: 400px) {}
@media (min-width: 550px) {}
@media (min-width: 750px) {}
@media (min-width: 1000px) {}
@media (min-width: 1200px) {}

h1.title {margin-top : 20px}
img {max-width : 100%}
div.title {text-align: center;}

  </style>
</HEAD>

<BODY>
  <div class ="container">
    <div class = "row">
      <div class = "col-md-12 twelve columns">
        <div class="title">
          <h1 class="title">Using External Sampler</h1>
          
          
        </div>

        <h1>Using External Samplers</h1>
<p><code>Turing</code> provides several wrapped samplers from external sampling libraries, e.g., HMC samplers from <code>AdvancedHMC</code>. These wrappers allow new users to seamlessly sample statistical models without leaving <code>Turing</code> However, these wrappers might only sometimes be complete, missing some functionality from the wrapped sampling library. Moreover, users might want to use samplers currently not wrapped within <code>Turing</code>.</p>
<p>For these reasons, <code>Turing</code> also makes running external samplers on Turing models easy without any necessary modifications or wrapping&#33; Throughout, we will use a 10-dimensional Neal&#39;s funnel as a running example::</p>


<pre class='hljl'>
<span class='hljl-cs'># Import libraries.</span><span class='hljl-t'>
</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>Turing</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Random</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>LinearAlgebra</span><span class='hljl-t'>

</span><span class='hljl-n'>d</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>10</span><span class='hljl-t'>
</span><span class='hljl-nd'>@model</span><span class='hljl-t'> </span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>funnel</span><span class='hljl-p'>()</span><span class='hljl-t'>
    </span><span class='hljl-n'>θ</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Truncated</span><span class='hljl-p'>(</span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(</span><span class='hljl-ni'>0</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-ni'>3</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>z</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>MvNormal</span><span class='hljl-p'>(</span><span class='hljl-nf'>zeros</span><span class='hljl-p'>(</span><span class='hljl-n'>d</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-nf'>exp</span><span class='hljl-p'>(</span><span class='hljl-n'>θ</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-n'>I</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>MvNormal</span><span class='hljl-p'>(</span><span class='hljl-n'>z</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>I</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre>


<pre class="output">
funnel &#40;generic function with 2 methods&#41;
</pre>


<p>Now we sample the model to generate some observations, which we can then condition on.</p>


<pre class='hljl'>
<span class='hljl-p'>(;</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-nf'>funnel</span><span class='hljl-p'>()</span><span class='hljl-t'> </span><span class='hljl-oB'>|</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>θ</span><span class='hljl-oB'>=</span><span class='hljl-ni'>0</span><span class='hljl-p'>,))</span><span class='hljl-t'>
</span><span class='hljl-n'>model</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>funnel</span><span class='hljl-p'>()</span><span class='hljl-t'> </span><span class='hljl-oB'>|</span><span class='hljl-t'> </span><span class='hljl-p'>(;</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-p'>);</span>
</pre>



<p>Users can use any sampler algorithm to sample this model if it follows the <code>AbstractMCMC</code> API. Before discussing how this is done in practice, giving a high-level description of the process is interesting. Imagine that we created an instance of an external sampler that we will call <code>spl</code> such that <code>typeof&#40;spl&#41;&lt;:AbstractMCMC.AbstractSampler</code>. In order to avoid type ambiguity within Turing, at the moment it is necessary to declare <code>spl</code> as an external sampler to Turing <code>espl &#61; externalsampler&#40;spl&#41;</code>, where <code>externalsampler&#40;s::AbstractMCMC.AbstractSampler&#41;</code> is a Turing function that types our external sampler adequately.</p>
<p>An excellent point to start to show how this is done in practice is by looking at the sampling library <code>AdvancedMH</code> &#40;&#40;<code>AdvancedMH</code>&#39;s GitHub&#41;&#91;&#91;https://github.com/TuringLang/AdvancedMH.jl&#93;&#41; for Metropolis-Hastings &#40;MH&#41; methods. Let&#39;s say we want to use a random walk Metropolis-Hastings sampler without specifying the proposal distributions. The code below constructs an MH sampler using a multivariate Gaussian distribution with zero mean and unit variance in <code>d</code> dimensions as a random walk proposal.</p>


<pre class='hljl'>
<span class='hljl-cs'># Importing the sampling library</span><span class='hljl-t'>
</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>AdvancedMH</span><span class='hljl-t'>
</span><span class='hljl-n'>rwmh</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>AdvancedMH</span><span class='hljl-oB'>.</span><span class='hljl-nf'>RWMH</span><span class='hljl-p'>(</span><span class='hljl-n'>d</span><span class='hljl-p'>)</span>
</pre>


<pre class="output">
AdvancedMH.MetropolisHastings&#123;AdvancedMH.RandomWalkProposal&#123;false, Distribu
tions.ZeroMeanIsoNormal&#123;Tuple&#123;Base.OneTo&#123;Int64&#125;&#125;&#125;&#125;&#125;&#40;AdvancedMH.RandomWalkPr
oposal&#123;false, Distributions.ZeroMeanIsoNormal&#123;Tuple&#123;Base.OneTo&#123;Int64&#125;&#125;&#125;&#125;&#40;Ze
roMeanIsoNormal&#40;
dim: 10
μ: Zeros&#40;10&#41;
Σ: &#91;1.0 0.0 … 0.0 0.0; 0.0 1.0 … 0.0 0.0; … ; 0.0 0.0 … 1.0 0.0; 0.0 0.0 … 
0.0 1.0&#93;
&#41;
&#41;&#41;
</pre>


<p>Sampling is then as easy as:</p>


<pre class='hljl'>
<span class='hljl-n'>chain</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sample</span><span class='hljl-p'>(</span><span class='hljl-n'>model</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>externalsampler</span><span class='hljl-p'>(</span><span class='hljl-n'>rwmh</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-ni'>10_000</span><span class='hljl-p'>)</span>
</pre>


<pre class="output">
Chains MCMC chain &#40;10000×11×1 Array&#123;Float64, 3&#125;&#41;:

Iterations        &#61; 1:1:10000
Number of chains  &#61; 1
Samples per chain &#61; 10000
Wall duration     &#61; 8.24 seconds
Compute duration  &#61; 8.24 seconds
parameters        &#61; θ, z&#91;1&#93;, z&#91;2&#93;, z&#91;3&#93;, z&#91;4&#93;, z&#91;5&#93;, z&#91;6&#93;, z&#91;7&#93;, z&#91;8&#93;, z&#91;9&#93;
internals         &#61; lp

Summary Statistics
  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat 
  e ⋯
      Symbol   Float64   Float64   Float64    Float64    Float64   Float64 
    ⋯

           θ   -1.0185    0.7931    0.1419    30.7972    24.3279    1.1201 
    ⋯
        z&#91;1&#93;   -0.2652    0.5327    0.0551    88.8140    94.7614    1.0135 
    ⋯
        z&#91;2&#93;    0.1618    0.5517    0.0842    43.0536    24.7299    1.0455 
    ⋯
        z&#91;3&#93;   -0.3886    0.5554    0.0779    50.2649    64.3106    1.0302 
    ⋯
        z&#91;4&#93;    0.0470    0.5220    0.0562    78.4051   125.4254    1.0175 
    ⋯
        z&#91;5&#93;   -0.2365    0.6335    0.0923    44.8034    67.2749    1.0839 
    ⋯
        z&#91;6&#93;   -0.1268    0.5643    0.0755    59.3979    71.6994    1.1007 
    ⋯
        z&#91;7&#93;   -0.2438    0.6843    0.1072    42.1676    57.0597    1.0186 
    ⋯
        z&#91;8&#93;    0.1856    0.5608    0.0614    83.6141    98.5142    1.0316 
    ⋯
        z&#91;9&#93;    0.1790    0.6141    0.0872    48.2301    89.6808    1.0539 
    ⋯
                                                                1 column om
itted

Quantiles
  parameters      2.5&#37;     25.0&#37;     50.0&#37;     75.0&#37;     97.5&#37;
      Symbol   Float64   Float64   Float64   Float64   Float64

           θ   -2.1708   -1.6813   -1.0739   -0.5716    0.8544
        z&#91;1&#93;   -1.5333   -0.5791   -0.2742    0.0550    0.7063
        z&#91;2&#93;   -0.8175   -0.0832    0.1758    0.3941    1.3518
        z&#91;3&#93;   -1.5904   -0.6791   -0.3401    0.0094    0.5618
        z&#91;4&#93;   -0.9931   -0.3655    0.0853    0.3483    1.1531
        z&#91;5&#93;   -1.5099   -0.6724   -0.1983    0.2138    0.9561
        z&#91;6&#93;   -1.0949   -0.5350   -0.1452    0.2474    1.1039
        z&#91;7&#93;   -1.7884   -0.7254   -0.1617    0.1844    0.8773
        z&#91;8&#93;   -0.7984   -0.2027    0.2078    0.6238    1.3724
        z&#91;9&#93;   -0.8334   -0.2425    0.0305    0.6492    1.2867
</pre>


<h2>Going beyond the Turing API</h2>
<p>As previously mentioned, the Turing wrappers can often limit the capabilities of the sampling libraries they wrap. <code>AdvancedHMC</code><a href="#footnote-1" class="footnote">[1]</a> &#40;&#40;<code>AdvancedHMC</code>&#39;s GitHub&#41;&#91;https://github.com/TuringLang/AdvancedHMC.jl&#93;&#41; is a clear example of this. A common practice when performing HMC is to provide an initial guess for the mass matrix. However, the native HMC sampler within Turing only allows the user to specify the type of the mass matrix despite the two options being possible within <code>AdvancedHMC</code>. Thankfully, we can use Turing&#39;s support for external samplers to define an HMC sampler with a custom mass matrix in <code>AdvancedHMC</code> and then use it to sample our Turing model.</p>
<p>We will use the library <code>Pathfinder</code><a href="#footnote-2" class="footnote">[2]</a> &#40;&#40;<code>Pathfinder</code>&#39;s GitHub&#41;&#91;https://github.com/mlcolab/Pathfinder.jl&#93;&#41; to construct our estimate of mass matrix. <code>Pathfinder</code> is a variational inference algorithm that first finds the maximum a posteriori &#40;MAP&#41; estimate of a target posterior distribution and then uses the trace of the optimization to construct a sequence of multivariate normal approximations to the target distribution. In this process, <code>Pathfinder</code> computes an estimate of the mass matrix the user can access.</p>
<p>The code below shows this can be done in practice.</p>


<pre class='hljl'>
<span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>AdvancedHMC</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Pathfinder</span><span class='hljl-t'>
</span><span class='hljl-cs'># Running pathfinder</span><span class='hljl-t'>
</span><span class='hljl-n'>draws</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1_000</span><span class='hljl-t'>
</span><span class='hljl-n'>result_multi</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>multipathfinder</span><span class='hljl-p'>(</span><span class='hljl-n'>model</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>draws</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>nruns</span><span class='hljl-oB'>=</span><span class='hljl-ni'>8</span><span class='hljl-p'>)</span><span class='hljl-t'>

</span><span class='hljl-cs'># Estimating the metric</span><span class='hljl-t'>
</span><span class='hljl-n'>inv_metric</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>result_multi</span><span class='hljl-oB'>.</span><span class='hljl-n'>pathfinder_results</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-oB'>.</span><span class='hljl-n'>fit_distribution</span><span class='hljl-oB'>.</span><span class='hljl-n'>Σ</span><span class='hljl-t'>
</span><span class='hljl-n'>metric</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>DenseEuclideanMetric</span><span class='hljl-p'>(</span><span class='hljl-nf'>Matrix</span><span class='hljl-p'>(</span><span class='hljl-n'>inv_metric</span><span class='hljl-p'>))</span><span class='hljl-t'>

</span><span class='hljl-cs'># Creating an AdvancedHMC NUTS sampler with the custom metric.</span><span class='hljl-t'>
</span><span class='hljl-n'>n_adapts</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1000</span><span class='hljl-t'> </span><span class='hljl-cs'># Number of adaptation steps</span><span class='hljl-t'>
</span><span class='hljl-n'>tap</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.9</span><span class='hljl-t'> </span><span class='hljl-cs'># Large target acceptance probability to deal with the funnel structure of the posterior</span><span class='hljl-t'>
</span><span class='hljl-n'>nuts</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>AdvancedHMC</span><span class='hljl-oB'>.</span><span class='hljl-nf'>NUTS</span><span class='hljl-p'>(</span><span class='hljl-n'>tap</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>metric</span><span class='hljl-oB'>=</span><span class='hljl-n'>metric</span><span class='hljl-p'>)</span><span class='hljl-t'>

</span><span class='hljl-cs'># Sample</span><span class='hljl-t'>
</span><span class='hljl-n'>chain</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sample</span><span class='hljl-p'>(</span><span class='hljl-n'>model</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>externalsampler</span><span class='hljl-p'>(</span><span class='hljl-n'>nuts</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-ni'>10_000</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>n_adapts</span><span class='hljl-oB'>=</span><span class='hljl-ni'>1_000</span><span class='hljl-p'>)</span>
</pre>


<pre class="output">
Chains MCMC chain &#40;10000×23×1 Array&#123;Float64, 3&#125;&#41;:

Iterations        &#61; 1:1:10000
Number of chains  &#61; 1
Samples per chain &#61; 10000
Wall duration     &#61; 7.88 seconds
Compute duration  &#61; 7.88 seconds
parameters        &#61; θ, z&#91;1&#93;, z&#91;2&#93;, z&#91;3&#93;, z&#91;4&#93;, z&#91;5&#93;, z&#91;6&#93;, z&#91;7&#93;, z&#91;8&#93;, z&#91;9&#93;
internals         &#61; lp, n_steps, is_accept, acceptance_rate, log_density, h
amiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, 
tree_depth, numerical_error, step_size, nom_step_size, is_adapt

Summary Statistics
  parameters      mean       std      mcse     ess_bulk    ess_tail      rh
at  ⋯
      Symbol   Float64   Float64   Float64      Float64     Float64   Float
64  ⋯

           θ   -1.6180    0.8983    0.0302    1040.9326    542.6641    1.00
24  ⋯
        z&#91;1&#93;   -0.1212    0.4368    0.0047    7998.9346   5989.6225    1.00
10  ⋯
        z&#91;2&#93;    0.1959    0.4753    0.0081    3510.1337   5651.8167    1.00
11  ⋯
        z&#91;3&#93;   -0.1345    0.4584    0.0055    7115.1949   5194.8408    1.00
00  ⋯
        z&#91;4&#93;    0.0402    0.4937    0.0269     697.5696    216.7621    1.00
19  ⋯
        z&#91;5&#93;   -0.1976    0.5357    0.0344     611.1404    213.8544    1.00
23  ⋯
        z&#91;6&#93;   -0.0074    0.4583    0.0139    1290.0677    230.5127    1.00
06  ⋯
        z&#91;7&#93;   -0.1719    0.4636    0.0048   10434.9874   4695.5420    0.99
99  ⋯
        z&#91;8&#93;    0.1138    0.4621    0.0185     974.5073    213.9443    1.00
19  ⋯
        z&#91;9&#93;    0.0655    0.4428    0.0040   12621.6943   5849.5861    1.00
00  ⋯
                                                                1 column om
itted

Quantiles
  parameters      2.5&#37;     25.0&#37;     50.0&#37;     75.0&#37;     97.5&#37;
      Symbol   Float64   Float64   Float64   Float64   Float64

           θ   -2.9276   -2.3572   -1.7363   -0.9979    0.3406
        z&#91;1&#93;   -1.0750   -0.3612   -0.0954    0.1522    0.7064
        z&#91;2&#93;   -0.6593   -0.1097    0.1538    0.4535    1.2691
        z&#91;3&#93;   -1.1642   -0.3775   -0.1017    0.1544    0.6878
        z&#91;4&#93;   -1.0672   -0.2104    0.0434    0.3095    0.9951
        z&#91;5&#93;   -1.3485   -0.4606   -0.1731    0.0835    0.7788
        z&#91;6&#93;   -0.9472   -0.2713   -0.0061    0.2541    0.9607
        z&#91;7&#93;   -1.2281   -0.4135   -0.1365    0.1173    0.6656
        z&#91;8&#93;   -0.7223   -0.1677    0.0848    0.3550    1.2924
        z&#91;9&#93;   -0.7980   -0.1943    0.0562    0.3100    1.0187
</pre>


<h2>Using new inference methods</h2>
<p>So far we have used Turing&#39;s support for external samplers to go beyond the capabilities of the wrappers. We want to use this support to employ a sampler not supported within Turing&#39;s ecosystem yet. We will use the recently developed Micro-Cannoncial Hamiltonian Monte Carlo &#40;MCHMC&#41; sampler to showcase this. MCHMC<a href="&#40;MCHMC&#39;s GitHub&#41;&#91;https://github.com/JaimeRZP/MicroCanonicalHMC.jl&#93;">^3,^4</a> is HMC sampler that uses one single Hamiltonian energy level to explore the whole parameter space. This is achieved by simulating the dynamics of a microcanonical Hamiltonian with an additional noise term to ensure ergodicity.</p>
<p>Using this as well as other inference methods outside the Turing ecosystem is as simple as executing the code shown below:</p>


<pre class='hljl'>
<span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>MicroCanonicalHMC</span><span class='hljl-t'>
</span><span class='hljl-cs'># Create MCHMC sampler</span><span class='hljl-t'>
</span><span class='hljl-n'>n_adapts</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1_000</span><span class='hljl-t'> </span><span class='hljl-cs'># adaptation steps</span><span class='hljl-t'>
</span><span class='hljl-n'>tev</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.01</span><span class='hljl-t'> </span><span class='hljl-cs'># target energy variance</span><span class='hljl-t'>
</span><span class='hljl-n'>mchmc</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MCHMC</span><span class='hljl-p'>(</span><span class='hljl-n'>n_adapts</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>tev</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>adaptive</span><span class='hljl-oB'>=</span><span class='hljl-kc'>true</span><span class='hljl-p'>)</span><span class='hljl-t'>

</span><span class='hljl-cs'># Sample</span><span class='hljl-t'>
</span><span class='hljl-n'>chain</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sample</span><span class='hljl-p'>(</span><span class='hljl-n'>model</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>externalsampler</span><span class='hljl-p'>(</span><span class='hljl-n'>mchmc</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-ni'>10_000</span><span class='hljl-p'>)</span>
</pre>


<pre class="output">
Chains MCMC chain &#40;10000×11×1 Array&#123;Float64, 3&#125;&#41;:

Iterations        &#61; 1:1:10000
Number of chains  &#61; 1
Samples per chain &#61; 10000
Wall duration     &#61; 4.43 seconds
Compute duration  &#61; 4.43 seconds
parameters        &#61; θ, z&#91;1&#93;, z&#91;2&#93;, z&#91;3&#93;, z&#91;4&#93;, z&#91;5&#93;, z&#91;6&#93;, z&#91;7&#93;, z&#91;8&#93;, z&#91;9&#93;
internals         &#61; lp

Summary Statistics
  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat 
  e ⋯
      Symbol   Float64   Float64   Float64    Float64    Float64   Float64 
    ⋯

           θ   -1.5825    0.9585    0.0831   123.1988   193.6363    1.0046 
    ⋯
        z&#91;1&#93;   -0.1267    0.4946    0.0480   119.7880   126.8787    1.0235 
    ⋯
        z&#91;2&#93;    0.1433    0.4433    0.0276   286.9000   362.0606    1.0127 
    ⋯
        z&#91;3&#93;   -0.1421    0.4843    0.0399   165.0049   195.9662    1.0017 
    ⋯
        z&#91;4&#93;    0.0253    0.4523    0.0347   189.7938   209.9622    1.0142 
    ⋯
        z&#91;5&#93;   -0.2384    0.4924    0.0325   252.6573   291.3090    1.0016 
    ⋯
        z&#91;6&#93;   -0.0757    0.4514    0.0197   613.0202   495.1510    1.0002 
    ⋯
        z&#91;7&#93;   -0.1876    0.4772    0.0333   248.2186   215.0477    1.0122 
    ⋯
        z&#91;8&#93;    0.0548    0.4424    0.0321   195.4512   201.4631    1.0011 
    ⋯
        z&#91;9&#93;    0.0559    0.5170    0.0441   169.2563   173.5249    1.0022 
    ⋯
                                                                1 column om
itted

Quantiles
  parameters      2.5&#37;     25.0&#37;     50.0&#37;     75.0&#37;     97.5&#37;
      Symbol   Float64   Float64   Float64   Float64   Float64

           θ   -2.9514   -2.3752   -1.7016   -0.9171    0.4871
        z&#91;1&#93;   -1.2104   -0.3890   -0.0958    0.1590    0.8118
        z&#91;2&#93;   -0.6988   -0.1191    0.1192    0.3770    1.1076
        z&#91;3&#93;   -1.2883   -0.3860   -0.1026    0.1482    0.7717
        z&#91;4&#93;   -1.0069   -0.2162    0.0301    0.2810    0.9531
        z&#91;5&#93;   -1.4103   -0.5019   -0.1960    0.0702    0.6405
        z&#91;6&#93;   -1.1084   -0.3196   -0.0394    0.2035    0.7588
        z&#91;7&#93;   -1.3434   -0.4299   -0.1409    0.1167    0.6421
        z&#91;8&#93;   -0.8120   -0.2254    0.0520    0.3197    0.9972
        z&#91;9&#93;   -0.9359   -0.2061    0.0627    0.3308    1.0914
</pre>


<p>The only requirement to work with <code>externalsampler</code> is that the provided <code>sampler</code> must implement the AbstractMCMC.jl-interface &#91;INSERT LINK&#93; for a <code>model</code> of type <code>AbstractMCMC.LogDensityModel</code> &#91;INSERT LINK&#93;.</p>
<p>As previously stated, in order to use external sampling libraries within <code>Turing</code> they must follow the <code>AbstractMCMC</code> API. In this section, we will briefly dwell on what this entails. First and foremost, the sampler should be a subtype of <code>AbstractMCMC.AbstractSampler</code>. Second, the stepping function of the MCMC algorithm must be made defined using <code>AbstractMCMC.step</code> and follow the structure below:</p>
<pre><code># First step
function AbstractMCMC.step&#123;T&lt;:AbstractMCMC.AbstractSampler&#125;&#40;
    rng::Random.AbstractRNG,
    model::AbstractMCMC.LogDensityModel,
    spl::T;
    kwargs...,
&#41;
    &#91;...&#93;
    return transition, sample
end

# N&#43;1 step
function AbstractMCMC.step&#123;T&lt;:AbstractMCMC.AbstractSampler&#125;&#40;
    rng::Random.AbstractRNG,
    model::AbstractMCMC.LogDensityModel,
    sampler::T,
    state;
    kwargs...,
&#41; 
    &#91;...&#93;
    return transition, sample
end</code></pre>
<p>There are several characteristics to note in these functions:</p>
<ul>
<li><p>There must be two <code>step</code> functions:</p>
<ul>
<li><p>A function that performs the first step and initializes the sampler.</p>
</li>
<li><p>A function that performs the following steps and takes an extra input, <code>state</code>, which carries the initialization information.</p>
</li>
</ul>
</li>
<li><p>The functions must follow the displayed signatures.</p>
</li>
<li><p>The output of the functions must be a transition, the current state of the sampler, and a sample, what is saved to the MCMC chain.</p>
</li>
</ul>
<p>The last requirement is that the transition must be structured with a field <code>θ</code> which contains the values of the parameters of the model for said transition. This allows <code>Turing</code> to seamlessly extract the parameter values at each step of the chain when bundling the chains. Note that if the external sampler produces transitions that Turing cannot parse the bundling of the samples will be different or fail.</p>
<p>For practical examples of how to adapt a sampling library to the <code>AbstractMCMC</code> interface, the readers can consult the following libraries:</p>
<ul>
<li><p>&#40;AdvancedMH&#41;&#91;https://github.com/TuringLang/AdvancedMH.jl/blob/458a602ac32a8514a117d4c671396a9ba8acbdab/src/mh-core.jl#L73-L115&#93;</p>
</li>
<li><p>&#40;AdvancedHMC&#41;&#91;https://github.com/TuringLang/AdvancedHMC.jl/blob/762e55f894d142495a41a6eba0eed9201da0a600/src/abstractmcmc.jl#L102-L170&#93;</p>
</li>
<li><p>&#40;MicroCanonicalHMC&#41;&#91;https://github.com/JaimeRZP/MicroCanonicalHMC.jl/blob/master/src/abstractmcmc.jl&#93; within <code>MicroCanonicalHMC</code>.</p>
</li>
</ul>
<h1>Refences</h1>
<div class="footnote" id="footnote-1"><p class="footnote-title">1</p><p>Xu et al, &#40;AdvancedHMC.jl: A robust, modular and efficient implementation of advanced HMC algorithms&#41;&#91;http://proceedings.mlr.press/v118/xu20a/xu20a.pdf&#93;, 2019</p>
</div>
<div class="footnote" id="footnote-2"><p class="footnote-title">2</p><p>Zhang et al, &#40;Pathfinder: Parallel quasi-Newton variational inference&#41;&#91;https://arxiv.org/abs/2108.03782&#93;, 2021</p>
</div>
<div class="footnote" id="footnote-3"><p class="footnote-title">3</p><p>Robnik et al, &#40;Microcanonical Hamiltonian Monte Carlo&#41;&#91;https://arxiv.org/abs/2212.08549&#93;, 2022</p>
</div>
<div class="footnote" id="footnote-4"><p class="footnote-title">4</p><p>Robnik and Seljak, &#40;Langevine Hamiltonian Monte Carlo&#41;&#91;https://arxiv.org/abs/2303.18221&#93;, 2023</p>
</div>


        <HR/>
        <div class="footer">
          <p>
            Published from <a href="external-samplers.jmd">external-samplers.jmd</a>
            using <a href="http://github.com/JunoLab/Weave.jl">Weave.jl</a> v0.10.12 on 2023-10-19.
          </p>
        </div>
      </div>
    </div>
  </div>
</BODY>

</HTML>
