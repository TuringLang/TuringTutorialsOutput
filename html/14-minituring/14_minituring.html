<!DOCTYPE html>
<HTML lang = "en">
<HEAD>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>MiniTuring</title>
  

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      TeX: { equationNumbers: { autoNumber: "AMS" } }
    });
  </script>

  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>

  
<style>
pre.hljl {
    border: 1px solid #ccc;
    margin: 5px;
    padding: 5px;
    overflow-x: auto;
    color: rgb(68,68,68); background-color: rgb(251,251,251); }
pre.hljl > span.hljl-t { }
pre.hljl > span.hljl-w { }
pre.hljl > span.hljl-e { }
pre.hljl > span.hljl-eB { }
pre.hljl > span.hljl-o { }
pre.hljl > span.hljl-k { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kc { color: rgb(59,151,46); font-style: italic; }
pre.hljl > span.hljl-kd { color: rgb(214,102,97); font-style: italic; }
pre.hljl > span.hljl-kn { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kp { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kr { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kt { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-n { }
pre.hljl > span.hljl-na { }
pre.hljl > span.hljl-nb { }
pre.hljl > span.hljl-nbp { }
pre.hljl > span.hljl-nc { }
pre.hljl > span.hljl-ncB { }
pre.hljl > span.hljl-nd { color: rgb(214,102,97); }
pre.hljl > span.hljl-ne { }
pre.hljl > span.hljl-neB { }
pre.hljl > span.hljl-nf { color: rgb(66,102,213); }
pre.hljl > span.hljl-nfm { color: rgb(66,102,213); }
pre.hljl > span.hljl-np { }
pre.hljl > span.hljl-nl { }
pre.hljl > span.hljl-nn { }
pre.hljl > span.hljl-no { }
pre.hljl > span.hljl-nt { }
pre.hljl > span.hljl-nv { }
pre.hljl > span.hljl-nvc { }
pre.hljl > span.hljl-nvg { }
pre.hljl > span.hljl-nvi { }
pre.hljl > span.hljl-nvm { }
pre.hljl > span.hljl-l { }
pre.hljl > span.hljl-ld { color: rgb(148,91,176); font-style: italic; }
pre.hljl > span.hljl-s { color: rgb(201,61,57); }
pre.hljl > span.hljl-sa { color: rgb(201,61,57); }
pre.hljl > span.hljl-sb { color: rgb(201,61,57); }
pre.hljl > span.hljl-sc { color: rgb(201,61,57); }
pre.hljl > span.hljl-sd { color: rgb(201,61,57); }
pre.hljl > span.hljl-sdB { color: rgb(201,61,57); }
pre.hljl > span.hljl-sdC { color: rgb(201,61,57); }
pre.hljl > span.hljl-se { color: rgb(59,151,46); }
pre.hljl > span.hljl-sh { color: rgb(201,61,57); }
pre.hljl > span.hljl-si { }
pre.hljl > span.hljl-so { color: rgb(201,61,57); }
pre.hljl > span.hljl-sr { color: rgb(201,61,57); }
pre.hljl > span.hljl-ss { color: rgb(201,61,57); }
pre.hljl > span.hljl-ssB { color: rgb(201,61,57); }
pre.hljl > span.hljl-nB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nbB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nfB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nh { color: rgb(59,151,46); }
pre.hljl > span.hljl-ni { color: rgb(59,151,46); }
pre.hljl > span.hljl-nil { color: rgb(59,151,46); }
pre.hljl > span.hljl-noB { color: rgb(59,151,46); }
pre.hljl > span.hljl-oB { color: rgb(102,102,102); font-weight: bold; }
pre.hljl > span.hljl-ow { color: rgb(102,102,102); font-weight: bold; }
pre.hljl > span.hljl-p { }
pre.hljl > span.hljl-c { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-ch { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cm { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cp { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cpB { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cs { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-csB { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-g { }
pre.hljl > span.hljl-gd { }
pre.hljl > span.hljl-ge { }
pre.hljl > span.hljl-geB { }
pre.hljl > span.hljl-gh { }
pre.hljl > span.hljl-gi { }
pre.hljl > span.hljl-go { }
pre.hljl > span.hljl-gp { }
pre.hljl > span.hljl-gs { }
pre.hljl > span.hljl-gsB { }
pre.hljl > span.hljl-gt { }
</style>



  <style type="text/css">
  @font-face {
  font-style: normal;
  font-weight: 300;
}
@font-face {
  font-style: normal;
  font-weight: 400;
}
@font-face {
  font-style: normal;
  font-weight: 600;
}
html {
  font-family: sans-serif; /* 1 */
  -ms-text-size-adjust: 100%; /* 2 */
  -webkit-text-size-adjust: 100%; /* 2 */
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block; /* 1 */
  vertical-align: baseline; /* 2 */
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 70%;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit; /* 1 */
  font: inherit; /* 2 */
  margin: 0; /* 3 */
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button; /* 2 */
  cursor: pointer; /* 3 */
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box; /* 1 */
  padding: 0; /* 2 */
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield; /* 1 */
  -moz-box-sizing: content-box;
  -webkit-box-sizing: content-box; /* 2 */
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0; /* 1 */
  padding: 0; /* 2 */
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  font-family: monospace, monospace;
  font-size : 0.8em;
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
thead th {
    border-bottom: 1px solid black;
    background-color: white;
}
tr:nth-child(odd){
  background-color: rgb(248,248,248);
}


/*
* Skeleton V2.0.4
* Copyright 2014, Dave Gamache
* www.getskeleton.com
* Free to use under the MIT license.
* http://www.opensource.org/licenses/mit-license.php
* 12/29/2014
*/
.container {
  position: relative;
  width: 100%;
  max-width: 960px;
  margin: 0 auto;
  padding: 0 20px;
  box-sizing: border-box; }
.column,
.columns {
  width: 100%;
  float: left;
  box-sizing: border-box; }
@media (min-width: 400px) {
  .container {
    width: 85%;
    padding: 0; }
}
@media (min-width: 550px) {
  .container {
    width: 80%; }
  .column,
  .columns {
    margin-left: 4%; }
  .column:first-child,
  .columns:first-child {
    margin-left: 0; }

  .one.column,
  .one.columns                    { width: 4.66666666667%; }
  .two.columns                    { width: 13.3333333333%; }
  .three.columns                  { width: 22%;            }
  .four.columns                   { width: 30.6666666667%; }
  .five.columns                   { width: 39.3333333333%; }
  .six.columns                    { width: 48%;            }
  .seven.columns                  { width: 56.6666666667%; }
  .eight.columns                  { width: 65.3333333333%; }
  .nine.columns                   { width: 74.0%;          }
  .ten.columns                    { width: 82.6666666667%; }
  .eleven.columns                 { width: 91.3333333333%; }
  .twelve.columns                 { width: 100%; margin-left: 0; }

  .one-third.column               { width: 30.6666666667%; }
  .two-thirds.column              { width: 65.3333333333%; }

  .one-half.column                { width: 48%; }

  /* Offsets */
  .offset-by-one.column,
  .offset-by-one.columns          { margin-left: 8.66666666667%; }
  .offset-by-two.column,
  .offset-by-two.columns          { margin-left: 17.3333333333%; }
  .offset-by-three.column,
  .offset-by-three.columns        { margin-left: 26%;            }
  .offset-by-four.column,
  .offset-by-four.columns         { margin-left: 34.6666666667%; }
  .offset-by-five.column,
  .offset-by-five.columns         { margin-left: 43.3333333333%; }
  .offset-by-six.column,
  .offset-by-six.columns          { margin-left: 52%;            }
  .offset-by-seven.column,
  .offset-by-seven.columns        { margin-left: 60.6666666667%; }
  .offset-by-eight.column,
  .offset-by-eight.columns        { margin-left: 69.3333333333%; }
  .offset-by-nine.column,
  .offset-by-nine.columns         { margin-left: 78.0%;          }
  .offset-by-ten.column,
  .offset-by-ten.columns          { margin-left: 86.6666666667%; }
  .offset-by-eleven.column,
  .offset-by-eleven.columns       { margin-left: 95.3333333333%; }

  .offset-by-one-third.column,
  .offset-by-one-third.columns    { margin-left: 34.6666666667%; }
  .offset-by-two-thirds.column,
  .offset-by-two-thirds.columns   { margin-left: 69.3333333333%; }

  .offset-by-one-half.column,
  .offset-by-one-half.columns     { margin-left: 52%; }

}
html {
  font-size: 62.5%; }
body {
  font-size: 1.5em; /* currently ems cause chrome bug misinterpreting rems on body element */
  line-height: 1.6;
  font-weight: 400;
  font-family: "Raleway", "HelveticaNeue", "Helvetica Neue", Helvetica, Arial, sans-serif;
  color: #222; }
h1, h2, h3, h4, h5, h6 {
  margin-top: 0;
  margin-bottom: 2rem;
  font-weight: 300; }
h1 { font-size: 3.6rem; line-height: 1.2;  letter-spacing: -.1rem;}
h2 { font-size: 3.4rem; line-height: 1.25; letter-spacing: -.1rem; }
h3 { font-size: 3.2rem; line-height: 1.3;  letter-spacing: -.1rem; }
h4 { font-size: 2.8rem; line-height: 1.35; letter-spacing: -.08rem; }
h5 { font-size: 2.4rem; line-height: 1.5;  letter-spacing: -.05rem; }
h6 { font-size: 1.5rem; line-height: 1.6;  letter-spacing: 0; }

p {
  margin-top: 0; }
a {
  color: #1EAEDB; }
a:hover {
  color: #0FA0CE; }
.button,
button,
input[type="submit"],
input[type="reset"],
input[type="button"] {
  display: inline-block;
  height: 38px;
  padding: 0 30px;
  color: #555;
  text-align: center;
  font-size: 11px;
  font-weight: 600;
  line-height: 38px;
  letter-spacing: .1rem;
  text-transform: uppercase;
  text-decoration: none;
  white-space: nowrap;
  background-color: transparent;
  border-radius: 4px;
  border: 1px solid #bbb;
  cursor: pointer;
  box-sizing: border-box; }
.button:hover,
button:hover,
input[type="submit"]:hover,
input[type="reset"]:hover,
input[type="button"]:hover,
.button:focus,
button:focus,
input[type="submit"]:focus,
input[type="reset"]:focus,
input[type="button"]:focus {
  color: #333;
  border-color: #888;
  outline: 0; }
.button.button-primary,
button.button-primary,
input[type="submit"].button-primary,
input[type="reset"].button-primary,
input[type="button"].button-primary {
  color: #FFF;
  background-color: #33C3F0;
  border-color: #33C3F0; }
.button.button-primary:hover,
button.button-primary:hover,
input[type="submit"].button-primary:hover,
input[type="reset"].button-primary:hover,
input[type="button"].button-primary:hover,
.button.button-primary:focus,
button.button-primary:focus,
input[type="submit"].button-primary:focus,
input[type="reset"].button-primary:focus,
input[type="button"].button-primary:focus {
  color: #FFF;
  background-color: #1EAEDB;
  border-color: #1EAEDB; }
input[type="email"],
input[type="number"],
input[type="search"],
input[type="text"],
input[type="tel"],
input[type="url"],
input[type="password"],
textarea,
select {
  height: 38px;
  padding: 6px 10px; /* The 6px vertically centers text on FF, ignored by Webkit */
  background-color: #fff;
  border: 1px solid #D1D1D1;
  border-radius: 4px;
  box-shadow: none;
  box-sizing: border-box; }
/* Removes awkward default styles on some inputs for iOS */
input[type="email"],
input[type="number"],
input[type="search"],
input[type="text"],
input[type="tel"],
input[type="url"],
input[type="password"],
textarea {
  -webkit-appearance: none;
     -moz-appearance: none;
          appearance: none; }
textarea {
  min-height: 65px;
  padding-top: 6px;
  padding-bottom: 6px; }
input[type="email"]:focus,
input[type="number"]:focus,
input[type="search"]:focus,
input[type="text"]:focus,
input[type="tel"]:focus,
input[type="url"]:focus,
input[type="password"]:focus,
textarea:focus,
select:focus {
  border: 1px solid #33C3F0;
  outline: 0; }
label,
legend {
  display: block;
  margin-bottom: .5rem;
  font-weight: 600; }
fieldset {
  padding: 0;
  border-width: 0; }
input[type="checkbox"],
input[type="radio"] {
  display: inline; }
label > .label-body {
  display: inline-block;
  margin-left: .5rem;
  font-weight: normal; }
ul {
  list-style: circle; }
ol {
  list-style: decimal; }
ul ul,
ul ol,
ol ol,
ol ul {
  margin: 1.5rem 0 1.5rem 3rem;
  font-size: 90%; }
li > p {margin : 0;}
th,
td {
  padding: 12px 15px;
  text-align: left;
  border-bottom: 1px solid #E1E1E1; }
th:first-child,
td:first-child {
  padding-left: 0; }
th:last-child,
td:last-child {
  padding-right: 0; }
button,
.button {
  margin-bottom: 1rem; }
input,
textarea,
select,
fieldset {
  margin-bottom: 1.5rem; }
pre,
blockquote,
dl,
figure,
table,
p,
ul,
ol,
form {
  margin-bottom: 1.0rem; }
.u-full-width {
  width: 100%;
  box-sizing: border-box; }
.u-max-full-width {
  max-width: 100%;
  box-sizing: border-box; }
.u-pull-right {
  float: right; }
.u-pull-left {
  float: left; }
hr {
  margin-top: 3rem;
  margin-bottom: 3.5rem;
  border-width: 0;
  border-top: 1px solid #E1E1E1; }
.container:after,
.row:after,
.u-cf {
  content: "";
  display: table;
  clear: both; }

pre {
  display: block;
  padding: 9.5px;
  margin: 0 0 10px;
  font-size: 13px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre.hljl {
  margin: 0 0 10px;
  display: block;
  background: #f5f5f5;
  border-radius: 4px;
  padding : 5px;
}

pre.output {
  background: #ffffff;
}

pre.code {
  background: #ffffff;
}

pre.julia-error {
  color : red
}

code,
kbd,
pre,
samp {
  font-family: Menlo, Monaco, Consolas, "Courier New", monospace;
  font-size: 13px;
}


@media (min-width: 400px) {}
@media (min-width: 550px) {}
@media (min-width: 750px) {}
@media (min-width: 1000px) {}
@media (min-width: 1200px) {}

h1.title {margin-top : 20px}
img {max-width : 100%}
div.title {text-align: center;}

  </style>
</HEAD>

<BODY>
  <div class ="container">
    <div class = "row">
      <div class = "col-md-12 twelve columns">
        <div class="title">
          <h1 class="title">MiniTuring</h1>
          
          
        </div>

        <p>In this tutorial we develop a very simple probabilistic programming language. The implementation is similar to <a href="https://github.com/TuringLang/DynamicPPL.jl">DynamicPPL</a>. This is intentional as we want to demonstrate some key ideas from Turing&#39;s internal implementation.</p>
<p>To make things easy to understand and to implement we restrict our language to a very simple subset of the language that Turing actually supports. Defining an accurate syntax description is not our goal here, instead, we give a simple example and all similar programs should work.</p>
<p>Consider a probabilistic model defined by</p>
<p class="math">\[
\begin{aligned}
a &\sim \operatorname{Normal}(0.5, 1^2) \\
b &\sim \operatorname{Normal}(a, 2^2) \\
x &\sim \operatorname{Normal}(b, 0.5^2)
\end{aligned}
\]</p>
<p>We assume that <code>x</code> is data, i.e., an observed variable. In our small language this model will be defined as</p>


<pre class='hljl'>
<span class='hljl-nd'>@mini_model</span><span class='hljl-t'> </span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>m</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(</span><span class='hljl-nfB'>0.5</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>b</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.5</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>nothing</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre>


<p>Specifically, we demand that</p>
<ul>
<li><p>all observed variables are arguments of the program,</p>
</li>
<li><p>the model definition does not contain any control flow,</p>
</li>
<li><p>all variables are scalars, and</p>
</li>
<li><p>the function returns <code>nothing</code>.</p>
</li>
</ul>
<p>First, we import some required packages:</p>


<pre class='hljl'>
<span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>MacroTools</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Distributions</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Random</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>AbstractMCMC</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>MCMCChains</span>
</pre>



<p>Before getting to the actual &quot;compiler&quot;, we first build the data structure for the program trace. A program trace for a probabilistic programming language needs to at least record the values of stochastic variables and their log-probabilities.</p>


<pre class='hljl'>
<span class='hljl-k'>struct</span><span class='hljl-t'> </span><span class='hljl-nf'>VarInfo</span><span class='hljl-p'>{</span><span class='hljl-n'>V</span><span class='hljl-p'>,</span><span class='hljl-n'>L</span><span class='hljl-p'>}</span><span class='hljl-t'>
    </span><span class='hljl-n'>values</span><span class='hljl-oB'>::</span><span class='hljl-n'>V</span><span class='hljl-t'>
    </span><span class='hljl-n'>logps</span><span class='hljl-oB'>::</span><span class='hljl-n'>L</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>

</span><span class='hljl-nf'>VarInfo</span><span class='hljl-p'>()</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>VarInfo</span><span class='hljl-p'>(</span><span class='hljl-nf'>Dict</span><span class='hljl-p'>{</span><span class='hljl-n'>Symbol</span><span class='hljl-p'>,</span><span class='hljl-n'>Float64</span><span class='hljl-p'>}(),</span><span class='hljl-t'> </span><span class='hljl-nf'>Dict</span><span class='hljl-p'>{</span><span class='hljl-n'>Symbol</span><span class='hljl-p'>,</span><span class='hljl-n'>Float64</span><span class='hljl-p'>}())</span><span class='hljl-t'>

</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-n'>Base</span><span class='hljl-oB'>.</span><span class='hljl-nf'>setindex!</span><span class='hljl-p'>(</span><span class='hljl-n'>varinfo</span><span class='hljl-oB'>::</span><span class='hljl-n'>VarInfo</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>value</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>logp</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>var_id</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>varinfo</span><span class='hljl-oB'>.</span><span class='hljl-n'>values</span><span class='hljl-p'>[</span><span class='hljl-n'>var_id</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>value</span><span class='hljl-t'>
    </span><span class='hljl-n'>varinfo</span><span class='hljl-oB'>.</span><span class='hljl-n'>logps</span><span class='hljl-p'>[</span><span class='hljl-n'>var_id</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>logp</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>varinfo</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre>



<p>Internally, our probabilistic programming language works with two main functions:</p>
<ul>
<li><p><code>assume</code> for sampling unobserved variables and computing their log-probabilities, and</p>
</li>
<li><p><code>observe</code> for computing log-probabilities of observed variables &#40;but not sampling them&#41;.</p>
</li>
</ul>
<p>For different inference algorithms we may have to use different sampling procedures and different log-probability computations. For instance, in some cases we might want to sample all variables from their prior distributions and in other cases we might only want to compute the log-likelihood of the observations based on a given set of values for the unobserved variables. Thus depending on the inference algorithm we want to use different <code>assume</code> and <code>observe</code> implementations. We can achieve this by providing this <code>context</code> information as a function argument to <code>assume</code> and <code>observe</code>.</p>
<p><strong>Note:</strong> <em>Although the context system in this tutorial is inspired by DynamicPPL, Turing&#39;s context system is much more complicated for flexibility and efficiency reasons. Thus readers are advised to refer to the documentation of DynamicPPL and Turing for more detailed information about their context system.</em></p>
<p>Here we can see the implementation of a sampler that draws values of unobserved variables from the prior and computes the log-probability for every variable.</p>


<pre class='hljl'>
<span class='hljl-k'>struct</span><span class='hljl-t'> </span><span class='hljl-nf'>SamplingContext</span><span class='hljl-p'>{</span><span class='hljl-n'>S</span><span class='hljl-oB'>&lt;:</span><span class='hljl-n'>AbstractMCMC</span><span class='hljl-oB'>.</span><span class='hljl-n'>AbstractSampler</span><span class='hljl-p'>,</span><span class='hljl-n'>R</span><span class='hljl-oB'>&lt;:</span><span class='hljl-n'>Random</span><span class='hljl-oB'>.</span><span class='hljl-n'>AbstractRNG</span><span class='hljl-p'>}</span><span class='hljl-t'>
    </span><span class='hljl-n'>rng</span><span class='hljl-oB'>::</span><span class='hljl-n'>R</span><span class='hljl-t'>
    </span><span class='hljl-n'>sampler</span><span class='hljl-oB'>::</span><span class='hljl-n'>S</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>

</span><span class='hljl-k'>struct</span><span class='hljl-t'> </span><span class='hljl-n'>PriorSampler</span><span class='hljl-t'> </span><span class='hljl-oB'>&lt;:</span><span class='hljl-t'> </span><span class='hljl-n'>AbstractMCMC</span><span class='hljl-oB'>.</span><span class='hljl-n'>AbstractSampler</span><span class='hljl-t'> </span><span class='hljl-k'>end</span><span class='hljl-t'>

</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>observe</span><span class='hljl-p'>(</span><span class='hljl-n'>context</span><span class='hljl-oB'>::</span><span class='hljl-n'>SamplingContext</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>varinfo</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>dist</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>var_id</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>var_value</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>logp</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>logpdf</span><span class='hljl-p'>(</span><span class='hljl-n'>dist</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>var_value</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>varinfo</span><span class='hljl-p'>[</span><span class='hljl-n'>var_id</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>var_value</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>logp</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>nothing</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>

</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>assume</span><span class='hljl-p'>(</span><span class='hljl-n'>context</span><span class='hljl-oB'>::</span><span class='hljl-nf'>SamplingContext</span><span class='hljl-p'>{</span><span class='hljl-n'>PriorSampler</span><span class='hljl-p'>},</span><span class='hljl-t'> </span><span class='hljl-n'>varinfo</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>dist</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>var_id</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>sample</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>Random</span><span class='hljl-oB'>.</span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>context</span><span class='hljl-oB'>.</span><span class='hljl-n'>rng</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>dist</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>logp</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>logpdf</span><span class='hljl-p'>(</span><span class='hljl-n'>dist</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>sample</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>varinfo</span><span class='hljl-p'>[</span><span class='hljl-n'>var_id</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>sample</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>logp</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>sample</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-p'>;</span>
</pre>



<p>Next we define the &quot;compiler&quot; for our simple programming language. The term compiler is actually a bit misleading here since its only purpose is to transform the function definition in the <code>@mini_model</code> macro by</p>
<ul>
<li><p>adding the context information &#40;<code>context</code>&#41; and the tracing data structure &#40;<code>varinfo</code>&#41; as additional arguments, and</p>
</li>
<li><p>replacing tildes with calls to <code>assume</code> and <code>observe</code>.</p>
</li>
</ul>
<p>Afterwards, as usual the Julia compiler will just-in-time compile the model function when it is called.</p>
<p>The manipulation of Julia expressions is an advanced part of the Julia language. The <a href="https://docs.julialang.org/en/v1/manual/metaprogramming/">Julia documentation</a> provides an introduction to and more details about this so-called metaprogramming.</p>


<pre class='hljl'>
<span class='hljl-k'>macro</span><span class='hljl-t'> </span><span class='hljl-nf'>mini_model</span><span class='hljl-p'>(</span><span class='hljl-n'>expr</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-nf'>esc</span><span class='hljl-p'>(</span><span class='hljl-nf'>mini_model</span><span class='hljl-p'>(</span><span class='hljl-n'>expr</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>

</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>mini_model</span><span class='hljl-p'>(</span><span class='hljl-n'>expr</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-cs'># Split the function definition into a dictionary with its name, arguments, body etc.</span><span class='hljl-t'>
    </span><span class='hljl-n'>def</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>MacroTools</span><span class='hljl-oB'>.</span><span class='hljl-nf'>splitdef</span><span class='hljl-p'>(</span><span class='hljl-n'>expr</span><span class='hljl-p'>)</span><span class='hljl-t'>

    </span><span class='hljl-cs'># Replace tildes in the function body with calls to `assume` or `observe`</span><span class='hljl-t'>
    </span><span class='hljl-n'>def</span><span class='hljl-p'>[</span><span class='hljl-sc'>:body</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>MacroTools</span><span class='hljl-oB'>.</span><span class='hljl-nf'>postwalk</span><span class='hljl-p'>(</span><span class='hljl-n'>def</span><span class='hljl-p'>[</span><span class='hljl-sc'>:body</span><span class='hljl-p'>])</span><span class='hljl-t'> </span><span class='hljl-k'>do</span><span class='hljl-t'> </span><span class='hljl-n'>sub_expr</span><span class='hljl-t'>
        </span><span class='hljl-k'>if</span><span class='hljl-t'> </span><span class='hljl-n'>MacroTools</span><span class='hljl-oB'>.</span><span class='hljl-nd'>@capture</span><span class='hljl-p'>(</span><span class='hljl-n'>sub_expr</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>var_</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-n'>dist_</span><span class='hljl-p'>)</span><span class='hljl-t'>
            </span><span class='hljl-k'>if</span><span class='hljl-t'> </span><span class='hljl-n'>var</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-n'>def</span><span class='hljl-p'>[</span><span class='hljl-sc'>:args</span><span class='hljl-p'>]</span><span class='hljl-t'>
                </span><span class='hljl-cs'># If the variable is an argument of the model function, it is observed</span><span class='hljl-t'>
                </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-oB'>:</span><span class='hljl-p'>(</span><span class='hljl-oB'>$</span><span class='hljl-p'>(</span><span class='hljl-n'>observe</span><span class='hljl-p'>)(</span><span class='hljl-n'>context</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>varinfo</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>$</span><span class='hljl-n'>dist</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>$</span><span class='hljl-p'>(</span><span class='hljl-n'>Meta</span><span class='hljl-oB'>.</span><span class='hljl-nf'>quot</span><span class='hljl-p'>(</span><span class='hljl-n'>var</span><span class='hljl-p'>)),</span><span class='hljl-t'> </span><span class='hljl-oB'>$</span><span class='hljl-n'>var</span><span class='hljl-p'>))</span><span class='hljl-t'>
            </span><span class='hljl-k'>else</span><span class='hljl-t'>
                </span><span class='hljl-cs'># Otherwise it is unobserved</span><span class='hljl-t'>
                </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-oB'>:</span><span class='hljl-p'>(</span><span class='hljl-oB'>$</span><span class='hljl-n'>var</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-oB'>$</span><span class='hljl-p'>(</span><span class='hljl-n'>assume</span><span class='hljl-p'>)(</span><span class='hljl-n'>context</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>varinfo</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>$</span><span class='hljl-n'>dist</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>$</span><span class='hljl-p'>(</span><span class='hljl-n'>Meta</span><span class='hljl-oB'>.</span><span class='hljl-nf'>quot</span><span class='hljl-p'>(</span><span class='hljl-n'>var</span><span class='hljl-p'>))))</span><span class='hljl-t'>
            </span><span class='hljl-k'>end</span><span class='hljl-t'>
        </span><span class='hljl-k'>else</span><span class='hljl-t'>
            </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>sub_expr</span><span class='hljl-t'>
        </span><span class='hljl-k'>end</span><span class='hljl-t'>
    </span><span class='hljl-k'>end</span><span class='hljl-t'>

    </span><span class='hljl-cs'># Add `context` and `varinfo` arguments to the model function</span><span class='hljl-t'>
    </span><span class='hljl-n'>def</span><span class='hljl-p'>[</span><span class='hljl-sc'>:args</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>vcat</span><span class='hljl-p'>(</span><span class='hljl-sc'>:varinfo</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:context</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>def</span><span class='hljl-p'>[</span><span class='hljl-sc'>:args</span><span class='hljl-p'>])</span><span class='hljl-t'>

    </span><span class='hljl-cs'># Reassemble the function definition from its name, arguments, body etc.</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>MacroTools</span><span class='hljl-oB'>.</span><span class='hljl-nf'>combinedef</span><span class='hljl-p'>(</span><span class='hljl-n'>def</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-p'>;</span>
</pre>



<p>For inference, we make use of the <a href="https://turinglang.github.io/AbstractMCMC.jl/dev/">AbstractMCMC interface</a>. It provides a default implementation of a <code>sample</code> function for sampling a Markov chain. The default implementation already supports e.g. sampling of multiple chains in parallel, thinning of samples, or discarding initial samples.</p>
<p>The AbstractMCMC interface requires us to at least</p>
<ul>
<li><p>define a model that is a subtype of <code>AbstractMCMC.AbstractModel</code>,</p>
</li>
<li><p>define a sampler that is a subtype of <code>AbstractMCMC.AbstractSampler</code>,</p>
</li>
<li><p>implement <code>AbstractMCMC.step</code> for our model and sampler.</p>
</li>
</ul>
<p>Thus here we define a <code>MiniModel</code> model. In this model we store the model function and the observed data.</p>


<pre class='hljl'>
<span class='hljl-k'>struct</span><span class='hljl-t'> </span><span class='hljl-nf'>MiniModel</span><span class='hljl-p'>{</span><span class='hljl-n'>F</span><span class='hljl-p'>,</span><span class='hljl-n'>D</span><span class='hljl-p'>}</span><span class='hljl-t'> </span><span class='hljl-oB'>&lt;:</span><span class='hljl-t'> </span><span class='hljl-n'>AbstractMCMC</span><span class='hljl-oB'>.</span><span class='hljl-n'>AbstractModel</span><span class='hljl-t'>
    </span><span class='hljl-n'>f</span><span class='hljl-oB'>::</span><span class='hljl-n'>F</span><span class='hljl-t'>
    </span><span class='hljl-n'>data</span><span class='hljl-oB'>::</span><span class='hljl-n'>D</span><span class='hljl-t'> </span><span class='hljl-cs'># a NamedTuple of all the data</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre>



<p>In the Turing compiler, the model-specific <code>DynamicPPL.Model</code> is constructed automatically when calling the model function. But for the sake of simplicity here we construct the model manually.</p>
<p>To illustrate probabilistic inference with our mini language we implement an extremely simplistic Random-Walk Metropolis-Hastings sampler. We hard-code the proposal step as part of the sampler and only allow normal distributions with zero mean and fixed standard deviation. The Metropolis-Hastings sampler in Turing is more flexible.</p>


<pre class='hljl'>
<span class='hljl-k'>struct</span><span class='hljl-t'> </span><span class='hljl-nf'>MHSampler</span><span class='hljl-p'>{</span><span class='hljl-n'>T</span><span class='hljl-oB'>&lt;:</span><span class='hljl-n'>Real</span><span class='hljl-p'>}</span><span class='hljl-t'> </span><span class='hljl-oB'>&lt;:</span><span class='hljl-t'> </span><span class='hljl-n'>AbstractMCMC</span><span class='hljl-oB'>.</span><span class='hljl-n'>AbstractSampler</span><span class='hljl-t'>
    </span><span class='hljl-n'>sigma</span><span class='hljl-oB'>::</span><span class='hljl-n'>T</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>

</span><span class='hljl-nf'>MHSampler</span><span class='hljl-p'>()</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MHSampler</span><span class='hljl-p'>(</span><span class='hljl-ni'>1</span><span class='hljl-p'>)</span><span class='hljl-t'>

</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>assume</span><span class='hljl-p'>(</span><span class='hljl-n'>context</span><span class='hljl-oB'>::</span><span class='hljl-nf'>SamplingContext</span><span class='hljl-p'>{</span><span class='hljl-oB'>&lt;:</span><span class='hljl-n'>MHSampler</span><span class='hljl-p'>},</span><span class='hljl-t'> </span><span class='hljl-n'>varinfo</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>dist</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>var_id</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>sampler</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>context</span><span class='hljl-oB'>.</span><span class='hljl-n'>sampler</span><span class='hljl-t'>
    </span><span class='hljl-n'>old_value</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>varinfo</span><span class='hljl-oB'>.</span><span class='hljl-n'>values</span><span class='hljl-p'>[</span><span class='hljl-n'>var_id</span><span class='hljl-p'>]</span><span class='hljl-t'>

    </span><span class='hljl-cs'># propose a random-walk step, i.e, add the current value to a random </span><span class='hljl-t'>
    </span><span class='hljl-cs'># value sampled from a Normal distribution centered at 0</span><span class='hljl-t'>
    </span><span class='hljl-n'>value</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>context</span><span class='hljl-oB'>.</span><span class='hljl-n'>rng</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(</span><span class='hljl-n'>old_value</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>sampler</span><span class='hljl-oB'>.</span><span class='hljl-n'>sigma</span><span class='hljl-p'>))</span><span class='hljl-t'>
    </span><span class='hljl-n'>logp</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>Distributions</span><span class='hljl-oB'>.</span><span class='hljl-nf'>logpdf</span><span class='hljl-p'>(</span><span class='hljl-n'>dist</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>value</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>varinfo</span><span class='hljl-p'>[</span><span class='hljl-n'>var_id</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>value</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>logp</span><span class='hljl-p'>)</span><span class='hljl-t'>

    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>value</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-p'>;</span>
</pre>



<p>We need to define two <code>step</code> functions, one for the first step and the other for the following steps. In the first step we sample values from the prior distributions and in the following steps we sample with the random-walk proposal. The two functions are identified by the different arguments they take.</p>


<pre class='hljl'>
<span class='hljl-cs'># The fist step: Sampling from the prior distributions</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-n'>AbstractMCMC</span><span class='hljl-oB'>.</span><span class='hljl-nf'>step</span><span class='hljl-p'>(</span><span class='hljl-t'>
    </span><span class='hljl-n'>rng</span><span class='hljl-oB'>::</span><span class='hljl-n'>Random</span><span class='hljl-oB'>.</span><span class='hljl-n'>AbstractRNG</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>model</span><span class='hljl-oB'>::</span><span class='hljl-n'>MiniModel</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>sampler</span><span class='hljl-oB'>::</span><span class='hljl-n'>MHSampler</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>kwargs</span><span class='hljl-oB'>...</span><span class='hljl-t'>
</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>vi</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>VarInfo</span><span class='hljl-p'>()</span><span class='hljl-t'>
    </span><span class='hljl-n'>ctx</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>SamplingContext</span><span class='hljl-p'>(</span><span class='hljl-n'>rng</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>PriorSampler</span><span class='hljl-p'>())</span><span class='hljl-t'>
    </span><span class='hljl-n'>model</span><span class='hljl-oB'>.</span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>vi</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>ctx</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>values</span><span class='hljl-p'>(</span><span class='hljl-n'>model</span><span class='hljl-oB'>.</span><span class='hljl-n'>data</span><span class='hljl-p'>)</span><span class='hljl-oB'>...</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>vi</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>vi</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>

</span><span class='hljl-cs'># The following steps: Sampling with random-walk proposal</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-n'>AbstractMCMC</span><span class='hljl-oB'>.</span><span class='hljl-nf'>step</span><span class='hljl-p'>(</span><span class='hljl-t'>
    </span><span class='hljl-n'>rng</span><span class='hljl-oB'>::</span><span class='hljl-n'>Random</span><span class='hljl-oB'>.</span><span class='hljl-n'>AbstractRNG</span><span class='hljl-p'>,</span><span class='hljl-t'>
    </span><span class='hljl-n'>model</span><span class='hljl-oB'>::</span><span class='hljl-n'>MiniModel</span><span class='hljl-p'>,</span><span class='hljl-t'>
    </span><span class='hljl-n'>sampler</span><span class='hljl-oB'>::</span><span class='hljl-n'>MHSampler</span><span class='hljl-p'>,</span><span class='hljl-t'>
    </span><span class='hljl-n'>prev_state</span><span class='hljl-oB'>::</span><span class='hljl-n'>VarInfo</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-cs'># is just the old trace</span><span class='hljl-t'>
    </span><span class='hljl-n'>kwargs</span><span class='hljl-oB'>...</span><span class='hljl-p'>,</span><span class='hljl-t'>
</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>vi</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>prev_state</span><span class='hljl-t'>
    </span><span class='hljl-n'>new_vi</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>deepcopy</span><span class='hljl-p'>(</span><span class='hljl-n'>vi</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>ctx</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>SamplingContext</span><span class='hljl-p'>(</span><span class='hljl-n'>rng</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>sampler</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>model</span><span class='hljl-oB'>.</span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>new_vi</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>ctx</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>values</span><span class='hljl-p'>(</span><span class='hljl-n'>model</span><span class='hljl-oB'>.</span><span class='hljl-n'>data</span><span class='hljl-p'>)</span><span class='hljl-oB'>...</span><span class='hljl-p'>)</span><span class='hljl-t'>

    </span><span class='hljl-cs'># Compute log acceptance probability</span><span class='hljl-t'>
    </span><span class='hljl-cs'># Since the proposal is symmetric the computation can be simplified</span><span class='hljl-t'>
    </span><span class='hljl-n'>logα</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sum</span><span class='hljl-p'>(</span><span class='hljl-nf'>values</span><span class='hljl-p'>(</span><span class='hljl-n'>new_vi</span><span class='hljl-oB'>.</span><span class='hljl-n'>logps</span><span class='hljl-p'>))</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-t'> </span><span class='hljl-nf'>sum</span><span class='hljl-p'>(</span><span class='hljl-nf'>values</span><span class='hljl-p'>(</span><span class='hljl-n'>vi</span><span class='hljl-oB'>.</span><span class='hljl-n'>logps</span><span class='hljl-p'>))</span><span class='hljl-t'>

    </span><span class='hljl-cs'># Accept proposal with computed acceptance probability</span><span class='hljl-t'>
    </span><span class='hljl-k'>if</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-nf'>randexp</span><span class='hljl-p'>(</span><span class='hljl-n'>rng</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>&lt;</span><span class='hljl-t'> </span><span class='hljl-n'>logα</span><span class='hljl-t'>
        </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>new_vi</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>new_vi</span><span class='hljl-t'>
    </span><span class='hljl-k'>else</span><span class='hljl-t'>
        </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>prev_state</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>prev_state</span><span class='hljl-t'>
    </span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-p'>;</span>
</pre>



<p>To make it easier to analyze the samples and compare them with results from Turing, additionally we define a version of <code>AbstractMCMC.bundle_samples</code> for our model and sampler that returns a <code>MCMCChains.Chains</code> object of samples.</p>


<pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-n'>AbstractMCMC</span><span class='hljl-oB'>.</span><span class='hljl-nf'>bundle_samples</span><span class='hljl-p'>(</span><span class='hljl-t'>
    </span><span class='hljl-n'>samples</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>model</span><span class='hljl-oB'>::</span><span class='hljl-n'>MiniModel</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>::</span><span class='hljl-n'>MHSampler</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>::</span><span class='hljl-n'>Any</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>::</span><span class='hljl-nf'>Type</span><span class='hljl-p'>{</span><span class='hljl-n'>Chains</span><span class='hljl-p'>};</span><span class='hljl-t'> </span><span class='hljl-n'>kwargs</span><span class='hljl-oB'>...</span><span class='hljl-t'>
</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-cs'># We get a vector of traces</span><span class='hljl-t'>
    </span><span class='hljl-n'>values</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-n'>sample</span><span class='hljl-oB'>.</span><span class='hljl-n'>values</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>sample</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-n'>samples</span><span class='hljl-p'>]</span><span class='hljl-t'>
    </span><span class='hljl-n'>params</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-n'>key</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>key</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-nf'>keys</span><span class='hljl-p'>(</span><span class='hljl-n'>values</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>])</span><span class='hljl-t'> </span><span class='hljl-k'>if</span><span class='hljl-t'> </span><span class='hljl-n'>key</span><span class='hljl-t'> </span><span class='hljl-oB'>∉</span><span class='hljl-t'> </span><span class='hljl-nf'>keys</span><span class='hljl-p'>(</span><span class='hljl-n'>model</span><span class='hljl-oB'>.</span><span class='hljl-n'>data</span><span class='hljl-p'>)]</span><span class='hljl-t'>
    </span><span class='hljl-n'>vals</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>reduce</span><span class='hljl-p'>(</span><span class='hljl-n'>hcat</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-n'>value</span><span class='hljl-p'>[</span><span class='hljl-n'>p</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>value</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-n'>values</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>p</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-n'>params</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-cs'># Composing the `Chains` data-structure, of which analyzing infrastructure is provided</span><span class='hljl-t'>
    </span><span class='hljl-n'>chains</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Chains</span><span class='hljl-p'>(</span><span class='hljl-n'>vals</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>params</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>chains</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-p'>;</span>
</pre>



<p>Let us check how our mini probabilistic programming language works. We define the probabilistic model:</p>


<pre class='hljl'>
<span class='hljl-nd'>@mini_model</span><span class='hljl-t'> </span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>m</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(</span><span class='hljl-nfB'>0.5</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>b</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.5</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>nothing</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-p'>;</span>
</pre>



<p>We perform inference with data <code>x &#61; 3.0</code>:</p>


<pre class='hljl'>
<span class='hljl-nf'>sample</span><span class='hljl-p'>(</span><span class='hljl-nf'>MiniModel</span><span class='hljl-p'>(</span><span class='hljl-n'>m</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-oB'>=</span><span class='hljl-nfB'>3.0</span><span class='hljl-p'>,)),</span><span class='hljl-t'> </span><span class='hljl-nf'>MHSampler</span><span class='hljl-p'>(),</span><span class='hljl-t'> </span><span class='hljl-ni'>1_000_000</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>chain_type</span><span class='hljl-oB'>=</span><span class='hljl-n'>Chains</span><span class='hljl-p'>)</span>
</pre>


<pre class="output">
Chains MCMC chain &#40;1000000×2×1 Array&#123;Float64, 3&#125;&#41;:

Iterations        &#61; 1:1:1000000
Number of chains  &#61; 1
Samples per chain &#61; 1000000
parameters        &#61; a, b

Summary Statistics
  parameters      mean       std      mcse      ess_bulk      ess_tail     
 rh ⋯
      Symbol   Float64   Float64   Float64       Float64       Float64   Fl
oat ⋯

           a    0.9790    0.8991    0.0031    82461.6393   123062.3658    1
.00 ⋯
           b    2.8825    0.4865    0.0012   175653.9333   213631.1226    1
.00 ⋯
                                                               2 columns om
itted

Quantiles
  parameters      2.5&#37;     25.0&#37;     50.0&#37;     75.0&#37;     97.5&#37;
      Symbol   Float64   Float64   Float64   Float64   Float64

           a   -0.7770    0.3717    0.9810    1.5854    2.7379
           b    1.9254    2.5537    2.8849    3.2108    3.8334
</pre>


<p>We compare these results with Turing.</p>


<pre class='hljl'>
<span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>Turing</span><span class='hljl-t'>
</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>PDMats</span><span class='hljl-t'>

</span><span class='hljl-nd'>@model</span><span class='hljl-t'> </span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>turing_m</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(</span><span class='hljl-nfB'>0.5</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>b</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Normal</span><span class='hljl-p'>(</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.5</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>nothing</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>

</span><span class='hljl-nf'>sample</span><span class='hljl-p'>(</span><span class='hljl-nf'>turing_m</span><span class='hljl-p'>(</span><span class='hljl-nfB'>3.0</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-nf'>MH</span><span class='hljl-p'>(</span><span class='hljl-nf'>ScalMat</span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>)),</span><span class='hljl-t'> </span><span class='hljl-ni'>1_000_000</span><span class='hljl-p'>)</span>
</pre>


<pre class="output">
Chains MCMC chain &#40;1000000×3×1 Array&#123;Float64, 3&#125;&#41;:

Iterations        &#61; 1:1:1000000
Number of chains  &#61; 1
Samples per chain &#61; 1000000
Wall duration     &#61; 8.31 seconds
Compute duration  &#61; 8.31 seconds
parameters        &#61; a, b
internals         &#61; lp

Summary Statistics
  parameters      mean       std      mcse      ess_bulk      ess_tail     
 rh ⋯
      Symbol   Float64   Float64   Float64       Float64       Float64   Fl
oat ⋯

           a    0.9759    0.9008    0.0031    82617.6537   120978.6243    1
.00 ⋯
           b    2.8789    0.4880    0.0012   168341.8798   213071.4406    1
.00 ⋯
                                                               2 columns om
itted

Quantiles
  parameters      2.5&#37;     25.0&#37;     50.0&#37;     75.0&#37;     97.5&#37;
      Symbol   Float64   Float64   Float64   Float64   Float64

           a   -0.7865    0.3672    0.9745    1.5834    2.7405
           b    1.9219    2.5502    2.8777    3.2075    3.8330
</pre>


<p>As you can see, with our simple probabilistic programming language and custom samplers we get similar results as Turing.</p>


<div class="markdown"><h2>Appendix</h2>
<p>These tutorials are a part of the TuringTutorials repository, found at: <a href="https://github.com/TuringLang/TuringTutorials">https://github.com/TuringLang/TuringTutorials</a>.</p>
</div>
<div class="markdown"><p>To locally run this tutorial, do the following commands:</p>
<pre><code>using TuringTutorials
TuringTutorials.weave&#40;&quot;14-minituring&quot;, &quot;14_minituring.jmd&quot;&#41;</code></pre>
</div>
<div class="markdown"><p>Computer Information:</p>
</div>
<div class="markdown"><pre><code>Julia Version 1.9.2
Commit e4ee485e909 &#40;2023-07-05 09:39 UTC&#41;
Platform Info:
  OS: Linux &#40;x86_64-linux-gnu&#41;
  CPU: 128 × AMD EPYC 7502 32-Core Processor
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-14.0.6 &#40;ORCJIT, znver2&#41;
  Threads: 1 on 16 virtual cores
Environment:
  JULIA_CPU_THREADS &#61; 16
  JULIA_DEPOT_PATH &#61; /cache/julia-buildkite-plugin/depots/7aa0085e-79a4-45f3-a5bd-9743c91cf3da
</code></pre>
</div>
<div class="markdown"><p>Package Information:</p>
</div>
<div class="markdown"><pre><code>Status &#96;/cache/build/default-amdci4-2/julialang/turingtutorials/tutorials/14-minituring/Project.toml&#96;
  &#91;80f14c24&#93; AbstractMCMC v4.4.2
  &#91;31c24e10&#93; Distributions v0.25.99
  &#91;c7f686f2&#93; MCMCChains v6.0.3
  &#91;1914dd2f&#93; MacroTools v0.5.10
  &#91;90014a1f&#93; PDMats v0.11.17
  &#91;fce5fe82&#93; Turing v0.28.1
  &#91;9a3f8284&#93; Random</code></pre>
<p>And the full manifest:</p>
<pre><code>Status &#96;/cache/build/default-amdci4-2/julialang/turingtutorials/tutorials/14-minituring/Manifest.toml&#96;
  &#91;47edcb42&#93; ADTypes v0.1.6
  &#91;621f4979&#93; AbstractFFTs v1.5.0
  &#91;80f14c24&#93; AbstractMCMC v4.4.2
⌅ &#91;7a57a42e&#93; AbstractPPL v0.5.4
  &#91;1520ce14&#93; AbstractTrees v0.4.4
  &#91;79e6a3ab&#93; Adapt v3.6.2
  &#91;0bf59076&#93; AdvancedHMC v0.5.3
  &#91;5b7e9947&#93; AdvancedMH v0.7.5
  &#91;576499cb&#93; AdvancedPS v0.4.3
  &#91;b5ca4192&#93; AdvancedVI v0.2.4
  &#91;dce04be8&#93; ArgCheck v2.3.0
  &#91;4fba245c&#93; ArrayInterface v7.4.11
  &#91;a9b6321e&#93; Atomix v0.1.0
  &#91;13072b0f&#93; AxisAlgorithms v1.0.1
  &#91;39de3d68&#93; AxisArrays v0.4.7
  &#91;198e06fe&#93; BangBang v0.3.39
  &#91;9718e550&#93; Baselet v0.1.1
⌅ &#91;76274a88&#93; Bijectors v0.12.8
  &#91;fa961155&#93; CEnum v0.4.2
  &#91;49dc2e85&#93; Calculus v0.5.1
  &#91;082447d4&#93; ChainRules v1.53.0
  &#91;d360d2e6&#93; ChainRulesCore v1.16.0
  &#91;9e997f8a&#93; ChangesOfVariables v0.1.8
  &#91;861a8166&#93; Combinatorics v1.0.2
  &#91;38540f10&#93; CommonSolve v0.2.4
  &#91;bbf7d656&#93; CommonSubexpressions v0.3.0
  &#91;34da2185&#93; Compat v4.9.0
  &#91;a33af91c&#93; CompositionsBase v0.1.2
  &#91;88cd18e8&#93; ConsoleProgressMonitor v0.1.2
  &#91;187b0558&#93; ConstructionBase v1.5.3
  &#91;a8cc5b0e&#93; Crayons v4.1.1
  &#91;9a962f9c&#93; DataAPI v1.15.0
  &#91;864edb3b&#93; DataStructures v0.18.15
  &#91;e2d170a0&#93; DataValueInterfaces v1.0.0
  &#91;244e2a9f&#93; DefineSingletons v0.1.2
  &#91;8bb1440f&#93; DelimitedFiles v1.9.1
  &#91;b429d917&#93; DensityInterface v0.4.0
  &#91;163ba53b&#93; DiffResults v1.1.0
  &#91;b552c78f&#93; DiffRules v1.15.1
  &#91;31c24e10&#93; Distributions v0.25.99
  &#91;ced4e74d&#93; DistributionsAD v0.6.52
  &#91;ffbed154&#93; DocStringExtensions v0.9.3
  &#91;fa6b7ba4&#93; DualNumbers v0.6.8
⌃ &#91;366bfd00&#93; DynamicPPL v0.23.0
  &#91;cad2338a&#93; EllipticalSliceSampling v1.1.0
  &#91;4e289a0a&#93; EnumX v1.0.4
  &#91;e2ba6199&#93; ExprTools v0.1.10
  &#91;7a1cc6ca&#93; FFTW v1.7.1
  &#91;1a297f60&#93; FillArrays v1.5.0
  &#91;59287772&#93; Formatting v0.4.2
  &#91;f6369f11&#93; ForwardDiff v0.10.35
  &#91;069b7b12&#93; FunctionWrappers v1.1.3
  &#91;77dc65aa&#93; FunctionWrappersWrappers v0.1.3
  &#91;d9f16b24&#93; Functors v0.4.5
  &#91;46192b85&#93; GPUArraysCore v0.1.5
  &#91;34004b35&#93; HypergeometricFunctions v0.3.23
  &#91;22cec73e&#93; InitialValues v0.3.1
  &#91;505f98c9&#93; InplaceOps v0.3.0
  &#91;a98d9a8b&#93; Interpolations v0.14.7
  &#91;8197267c&#93; IntervalSets v0.7.7
  &#91;3587e190&#93; InverseFunctions v0.1.12
  &#91;41ab1584&#93; InvertedIndices v1.3.0
  &#91;92d709cd&#93; IrrationalConstants v0.2.2
  &#91;c8e1da08&#93; IterTools v1.8.0
  &#91;82899510&#93; IteratorInterfaceExtensions v1.0.0
  &#91;692b3bcd&#93; JLLWrappers v1.4.1
  &#91;63c18a36&#93; KernelAbstractions v0.9.8
  &#91;5ab0869b&#93; KernelDensity v0.6.7
  &#91;929cbde3&#93; LLVM v6.1.0
  &#91;8ac3fa9e&#93; LRUCache v1.4.1
  &#91;b964fa9f&#93; LaTeXStrings v1.3.0
  &#91;50d2b5c4&#93; Lazy v0.15.1
  &#91;1d6d02ad&#93; LeftChildRightSiblingTrees v0.2.0
  &#91;6f1fad26&#93; Libtask v0.8.6
  &#91;6fdf6af0&#93; LogDensityProblems v2.1.1
  &#91;996a588d&#93; LogDensityProblemsAD v1.6.1
  &#91;2ab3a3ac&#93; LogExpFunctions v0.3.24
  &#91;e6f89c97&#93; LoggingExtras v1.0.0
  &#91;c7f686f2&#93; MCMCChains v6.0.3
  &#91;be115224&#93; MCMCDiagnosticTools v0.3.5
  &#91;e80e1ace&#93; MLJModelInterface v1.8.0
  &#91;1914dd2f&#93; MacroTools v0.5.10
  &#91;dbb5928d&#93; MappedArrays v0.4.2
  &#91;128add7d&#93; MicroCollections v0.1.4
  &#91;e1d29d7a&#93; Missings v1.1.0
  &#91;872c559c&#93; NNlib v0.9.4
  &#91;77ba4419&#93; NaNMath v1.0.2
  &#91;86f7a689&#93; NamedArrays v0.9.8
  &#91;c020b1a1&#93; NaturalSort v1.0.0
  &#91;6fe1bfb0&#93; OffsetArrays v1.12.10
  &#91;3bd65402&#93; Optimisers v0.2.19
  &#91;bac558e1&#93; OrderedCollections v1.6.2
  &#91;90014a1f&#93; PDMats v0.11.17
  &#91;aea7be01&#93; PrecompileTools v1.1.2
  &#91;21216c6a&#93; Preferences v1.4.0
  &#91;08abe8d2&#93; PrettyTables v2.2.7
  &#91;33c8b6b6&#93; ProgressLogging v0.1.4
  &#91;92933f4c&#93; ProgressMeter v1.7.2
  &#91;1fd47b50&#93; QuadGK v2.8.2
  &#91;74087812&#93; Random123 v1.6.1
  &#91;e6cf234a&#93; RandomNumbers v1.5.3
  &#91;b3c3ace0&#93; RangeArrays v0.3.2
  &#91;c84ed2f1&#93; Ratios v0.4.5
  &#91;c1ae055f&#93; RealDot v0.1.0
  &#91;3cdcf5f2&#93; RecipesBase v1.3.4
  &#91;731186ca&#93; RecursiveArrayTools v2.38.7
  &#91;189a3867&#93; Reexport v1.2.2
  &#91;ae029012&#93; Requires v1.3.0
  &#91;79098fc4&#93; Rmath v0.7.1
  &#91;f2b01f46&#93; Roots v2.0.17
  &#91;7e49a35a&#93; RuntimeGeneratedFunctions v0.5.11
  &#91;0bca4576&#93; SciMLBase v1.94.0
  &#91;c0aeaf25&#93; SciMLOperators v0.3.6
  &#91;30f210dd&#93; ScientificTypesBase v3.0.0
  &#91;efcf1570&#93; Setfield v1.1.1
  &#91;ce78b400&#93; SimpleUnPack v1.1.0
  &#91;a2af1166&#93; SortingAlgorithms v1.1.1
  &#91;276daf66&#93; SpecialFunctions v2.3.0
  &#91;171d559e&#93; SplittablesBase v0.1.15
  &#91;90137ffa&#93; StaticArrays v1.6.2
  &#91;1e83bf80&#93; StaticArraysCore v1.4.2
  &#91;64bff920&#93; StatisticalTraits v3.2.0
  &#91;82ae8749&#93; StatsAPI v1.6.0
  &#91;2913bbd2&#93; StatsBase v0.34.0
  &#91;4c63d2b9&#93; StatsFuns v1.3.0
  &#91;892a3eda&#93; StringManipulation v0.3.0
  &#91;09ab397b&#93; StructArrays v0.6.15
  &#91;2efcf032&#93; SymbolicIndexingInterface v0.2.2
  &#91;3783bdb8&#93; TableTraits v1.0.1
  &#91;bd369af6&#93; Tables v1.10.1
  &#91;5d786b92&#93; TerminalLoggers v0.1.7
  &#91;9f7883ad&#93; Tracker v0.2.26
  &#91;28d57a85&#93; Transducers v0.4.78
  &#91;410a4b4d&#93; Tricks v0.1.7
  &#91;781d530d&#93; TruncatedStacktraces v1.4.0
  &#91;fce5fe82&#93; Turing v0.28.1
  &#91;013be700&#93; UnsafeAtomics v0.2.1
  &#91;d80eeb9a&#93; UnsafeAtomicsLLVM v0.1.3
  &#91;efce3f68&#93; WoodburyMatrices v0.5.5
  &#91;700de1a5&#93; ZygoteRules v0.2.3
  &#91;f5851436&#93; FFTW_jll v3.3.10&#43;0
  &#91;1d5cc7b8&#93; IntelOpenMP_jll v2023.1.0&#43;0
  &#91;dad2f222&#93; LLVMExtra_jll v0.0.23&#43;0
  &#91;856f044c&#93; MKL_jll v2023.1.0&#43;0
  &#91;efe28fd5&#93; OpenSpecFun_jll v0.5.5&#43;0
  &#91;f50d1b31&#93; Rmath_jll v0.4.0&#43;0
  &#91;0dad84c5&#93; ArgTools v1.1.1
  &#91;56f22d72&#93; Artifacts
  &#91;2a0f44e3&#93; Base64
  &#91;ade2ca70&#93; Dates
  &#91;8ba89e20&#93; Distributed
  &#91;f43a241f&#93; Downloads v1.6.0
  &#91;7b1f6079&#93; FileWatching
  &#91;9fa8497b&#93; Future
  &#91;b77e0a4c&#93; InteractiveUtils
  &#91;4af54fe1&#93; LazyArtifacts
  &#91;b27032c2&#93; LibCURL v0.6.3
  &#91;76f85450&#93; LibGit2
  &#91;8f399da3&#93; Libdl
  &#91;37e2e46d&#93; LinearAlgebra
  &#91;56ddb016&#93; Logging
  &#91;d6f4376e&#93; Markdown
  &#91;a63ad114&#93; Mmap
  &#91;ca575930&#93; NetworkOptions v1.2.0
  &#91;44cfe95a&#93; Pkg v1.9.2
  &#91;de0858da&#93; Printf
  &#91;3fa0cd96&#93; REPL
  &#91;9a3f8284&#93; Random
  &#91;ea8e919c&#93; SHA v0.7.0
  &#91;9e88b42a&#93; Serialization
  &#91;1a1011a3&#93; SharedArrays
  &#91;6462fe0b&#93; Sockets
  &#91;2f01184e&#93; SparseArrays
  &#91;10745b16&#93; Statistics v1.9.0
  &#91;4607b0f0&#93; SuiteSparse
  &#91;fa267f1f&#93; TOML v1.0.3
  &#91;a4e569a6&#93; Tar v1.10.0
  &#91;8dfed614&#93; Test
  &#91;cf7118a7&#93; UUIDs
  &#91;4ec0a83e&#93; Unicode
  &#91;e66e0078&#93; CompilerSupportLibraries_jll v1.0.5&#43;0
  &#91;deac9b47&#93; LibCURL_jll v7.84.0&#43;0
  &#91;29816b5a&#93; LibSSH2_jll v1.10.2&#43;0
  &#91;c8ffd9c3&#93; MbedTLS_jll v2.28.2&#43;0
  &#91;14a3606d&#93; MozillaCACerts_jll v2022.10.11
  &#91;4536629a&#93; OpenBLAS_jll v0.3.21&#43;4
  &#91;05823500&#93; OpenLibm_jll v0.8.1&#43;0
  &#91;bea87d4a&#93; SuiteSparse_jll v5.10.1&#43;6
  &#91;83775a58&#93; Zlib_jll v1.2.13&#43;0
  &#91;8e850b90&#93; libblastrampoline_jll v5.8.0&#43;0
  &#91;8e850ede&#93; nghttp2_jll v1.48.0&#43;0
  &#91;3f19e933&#93; p7zip_jll v17.4.0&#43;0
Info Packages marked with ⌃ and ⌅ have new versions available, but those with ⌅ are restricted by compatibility constraints from upgrading. To see why use &#96;status --outdated -m&#96;</code></pre>
</div>


        <HR/>
        <div class="footer">
          <p>
            Published from <a href="14_minituring.jmd">14_minituring.jmd</a>
            using <a href="http://github.com/JunoLab/Weave.jl">Weave.jl</a> v0.10.12 on 2023-08-05.
          </p>
        </div>
      </div>
    </div>
  </div>
</BODY>

</HTML>
